import logging
from datetime import datetime
from langchain_core.documents import Document

# C·∫•u h√¨nh Log ƒë·ªÉ d·ªÖ debug tr√™n Render
logger = logging.getLogger("MEMORY_CORE")

# --- K·∫æT N·ªêI V√ÄO B·ªò N√ÉO CH√çNH (SAFE IMPORT) ---
# Thay v√¨ t·ª± t·∫°o DB m·ªõi, ta "m∆∞·ª£n" DB ƒë√£ fix SQLite t·ª´ main.py
# D√πng try/except ƒë·ªÉ tr√°nh l·ªói v√≤ng l·∫∑p (Circular Import)
try:
    from main import vector_db, LLM_GPT4, AIMessage, SystemMessage, HumanMessage
    CORE_AVAILABLE = True
    logger.info("‚úÖ MEMORY CORE: ƒê√£ k·∫øt n·ªëi v·ªõi B·ªô n√£o trung t√¢m.")
except ImportError:
    CORE_AVAILABLE = False
    vector_db = None
    LLM_GPT4 = None
    logger.warning("‚ö†Ô∏è MEMORY CORE: Kh√¥ng th·ªÉ k·∫øt n·ªëi Main Brain (Ch·∫°y ch·∫ø ƒë·ªô Offline).")

def recall_relevant_memories(query: str, k=3):
    """
    H·ªìi t∆∞·ªüng: T√¨m ki·∫øm k√Ω ·ª©c li√™n quan ƒë·∫øn c√¢u n√≥i hi·ªán t·∫°i.
    """
    if not CORE_AVAILABLE or not vector_db:
        return "" # Tr·∫£ v·ªÅ r·ªóng n·∫øu h·ªá th·ªëng ch∆∞a s·∫µn s√†ng

    try:
        print(f"üß† [MEMORY] ƒêang l·ª•c l·ªçi k√Ω ·ª©c v·ªÅ: '{query}'...")
        # T√¨m ki·∫øm t∆∞∆°ng ƒë·ªìng
        results = vector_db.similarity_search_with_score(query, k=k)
        
        memories = []
        for doc, score in results:
            # Score c·ªßa Chroma (L2): C√†ng th·∫•p c√†ng gi·ªëng (0 l√† gi·ªëng h·ªát)
            # Ng∆∞·ª°ng 1.2 l√† kh√° r·ªông, c√≥ th·ªÉ h·∫° xu·ªëng 0.8 n·∫øu mu·ªën ch√≠nh x√°c h∆°n
            if score < 1.2: 
                time_str = doc.metadata.get('timestamp', 'Unknown Time')
                memories.append(f"- {doc.page_content} (Ghi l√∫c: {time_str})")
        
        return "\n".join(memories) if memories else ""
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói h·ªìi t∆∞·ªüng: {e}")
        return ""

def extract_and_save_memory(user_input: str, ai_response: str):
    """
    Ghi nh·ªõ ch·ªß ƒë·ªông: D√πng AI l·ªçc th√¥ng tin quan tr·ªçng ƒë·ªÉ l∆∞u.
    """
    if not CORE_AVAILABLE or not vector_db or not LLM_GPT4:
        return False

    # Prompt t·ªëi ∆∞u h√≥a ƒë·ªÉ ti·∫øt ki·ªám Token v√† tƒÉng ƒë·ªô ch√≠nh x√°c
    prompt = f"""
    B·∫°n l√† Th∆∞ k√Ω Ghi nh·ªõ c·ªßa h·ªá th·ªëng J.A.R.V.I.S.
    
    H·ªôi tho·∫°i:
    User: {user_input}
    AI: {ai_response}

    NHI·ªÜM V·ª§:
    1. Ch·ªâ tr√≠ch xu·∫•t th√¥ng tin C·ªêT L√ïI mang t√≠nh l√¢u d√†i (S·ªü th√≠ch, T√™n tu·ªïi, D·ª± √°n, L·ªãch h·∫πn, Quan ƒëi·ªÉm).
    2. B·ªè qua c√°c c√¢u ch√†o h·ªèi, l·ªánh code, ho·∫∑c h·ªôi tho·∫°i t√°n g·∫´u v√¥ th∆∞·ªüng v√¥ ph·∫°t.
    3. N·∫øu kh√¥ng c√≥ g√¨ ƒë√°ng nh·ªõ, tr·∫£ v·ªÅ ƒë√∫ng 1 t·ª´: NONE

    ƒê·ªãnh d·∫°ng ƒë·∫ßu ra (n·∫øu c√≥): [Th√¥ng tin ƒë√£ c√¥ ƒë·ªçng th√†nh 1 c√¢u kh·∫≥ng ƒë·ªãnh]
    """
    
    try:
        # G·ªçi LLM (D√πng invoke ƒë·ªÉ an to√†n)
        analysis_msg = LLM_GPT4.invoke([
            SystemMessage(content="Nhi·ªám v·ª•: Tr√≠ch xu·∫•t k√Ω ·ª©c."), 
            HumanMessage(content=prompt)
        ])
        analysis = analysis_msg.content.strip()
        
        # Logic l·ªçc r√°c
        if "NONE" not in analysis and len(analysis) > 5:
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            print(f"üíæ [MEMORY SAVE] ƒêang ghi v√†o n√£o b·ªô: {analysis}")
            
            # L∆∞u v√†o Vector DB (D√πng l·∫°i vector_db c·ªßa main)
            doc = Document(
                page_content=analysis,
                metadata={"timestamp": timestamp, "source": "conversation"}
            )
            # Ch·∫°y h√†m add_documents (ChromaDB t·ª± x·ª≠ l√Ω embedding)
            vector_db.add_documents([doc])
            return True
            
    except Exception as e:
        logger.error(f"‚ö†Ô∏è L·ªói qu√° tr√¨nh ghi nh·ªõ: {e}")
    
    return False