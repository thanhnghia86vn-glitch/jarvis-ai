import glob
import os
import pandas as pd
import sqlite3
import uuid
import time
import io  # <--- TH√äM C√ÅI N√ÄY
import shutil
import random
import logging
import aiofiles
import json  # <--- ƒê√É TH√äM
import base64
from typing import Optional, List, Dict, Any
from datetime import datetime
from contextlib import asynccontextmanager
from termcolor import colored
from gtts import gTTS
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# --- C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN: pip install fastapi uvicorn python-multipart jinja2 aiofiles ---
from fastapi import FastAPI, HTTPException, Header, Depends, UploadFile, File, Request, status, WebSocket, WebSocketDisconnect, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
# [QUAN TR·ªåNG]: ƒê√£ th√™m LLM_SUPERVISOR v√† log_training_data
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("JARVIS_BACKEND")
# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
ADMIN_SECRET = os.environ.get("ADMIN_SECRET", "ai_corp_secret_123")
UPLOAD_DIR = "uploads"
DB_PATH = "ai_corp_projects.db"

AI_AVAILABLE = False
MEMORY_AVAILABLE = False
VOICE_AVAILABLE = False

try:
    from main import (
        ai_app,                 # B·ªô n√£o LangGraph (Graph ƒë√£ compile)
        log_training_data,      # H√†m t·ª± h·ªçc
        learn_knowledge,        # H√†m h·ªçc ki·∫øn th·ª©c m·ªõi
        ingest_docs_to_memory,  # H√†m ƒë·ªçc PDF
        vector_db,              #Database Vector (Cho Cronjob)
        LLM_GPT4,               # Model GPT-4
        LLM_PERPLEXITY,         # Model Search
        LLM_GEMINI,             # Model Google
        LLM_SUPERVISOR,          # [M·ªöI] T·ªïng qu·∫£n ƒë·ªÉ chia vi·ªác d·ª± √°n l·ªõn
        CODER_PRIMARY
    
    ) 

    AI_AVAILABLE = True
    logger.info("‚úÖ CORE AI MODULES: LOADED")
except ImportError as e:
    logger.error(f"‚ö†Ô∏è CORE AI FAILED TO LOAD: {e}")
    ai_app = None
    vector_db = None
    LLM_GPT4 = None
    LLM_PERPLEXITY = None
    LLM_GEMINI = None
    LLM_SUPERVISOR = None
    CODER_PRIMARY = None

# --- IMPORT MODULES N·ªòI B·ªò KH√ÅC ---
try:
    from memory_core import recall_relevant_memories, extract_and_save_memory
    MEMORY_AVAILABLE = True
    logger.info("‚úÖ MEMORY CORE: LOADED")
except ImportError:
    logger.warning("‚ö†Ô∏è memory_core.py not found. Memory features disabled.")
  
 
try:
    from voice_engine import client
    VOICE_AVAILABLE = True
except ImportError:
    VOICE_AVAILABLE = False
    logger.warning("‚ö†Ô∏è Voice Engine not found.")
    client = None

CURRICULUM = {
    "[FINANCE]": [
        "Ph√¢n t√≠ch xu h∆∞·ªõng gi√° v√†ng SJC v√† th·∫ø gi·ªõi h√¥m nay",
        "D·ª± b√°o t·ª∑ gi√° USD/VND tu·∫ßn n√†y",
        "Bi·∫øn ƒë·ªông th·ªã tr∆∞·ªùng Crypto (Bitcoin/ETH) 24h qua",
        "Ch·ªâ s·ªë VN-Index v√† t√°c ƒë·ªông vƒ© m√¥"
    ],
    "[CODER]": [
        "Top Python libraries for AI Agents ",
        "FastAPI advanced patterns and performance tuning",
        "LangChain vs LangGraph architecture comparison",
        "Optimizing Docker containers for Python apps"
    ],
    "[MARKETING]": [
        "Xu h∆∞·ªõng TikTok viral t·∫°i Vi·ªát Nam tu·∫ßn n√†y",
        "Chi·∫øn l∆∞·ª£c SEO m·ªõi nh·∫•t c·ªßa Google Update",
        "Content marketing trends for Tech products 2026",
        "Ph√¢n t√≠ch qu·∫£ng c√°o Facebook hi·ªáu qu·∫£ ng√†nh c√¥ng ngh·ªá"
    ],
    "[LEGAL]": [
        "Lu·∫≠t Giao d·ªãch ƒëi·ªán t·ª≠ m·ªõi nh·∫•t t·∫°i Vi·ªát Nam",
        "Quy ƒë·ªãnh v·ªÅ b·∫£o v·ªá d·ªØ li·ªáu c√° nh√¢n (Ngh·ªã ƒë·ªãnh 13)",
        "B·∫£n quy·ªÅn trong k·ª∑ nguy√™n AI (Intellectual Property & AI)"
    ],
    "[HARDWARE]": [
        "ESP32-S3 pinout and datasheet updates",
        "C√°c lo·∫°i c·∫£m bi·∫øn IoT gi√° r·∫ª m·ªõi nh·∫•t tr√™n th·ªã tr∆∞·ªùng",
        "K·ªπ thu·∫≠t thi·∫øt k·∫ø m·∫°ch PCB ch·ªëng nhi·ªÖu (Anti-interference)"
    ],
    "[ARTIST]": [
        "Phong c√°ch v·∫Ω Digital Art ƒë∆∞∆°ng ƒë·∫°i",
        "Xu h∆∞·ªõng m√†u s·∫Øc (Color Trends) nƒÉm 2026",
        "K·ªπ thu·∫≠t Prompting cho DALL-E 3 v√† Midjourney"
    ],
    "[IOT]": [
        "Giao th·ª©c MQTT v√† b·∫£o m·∫≠t thi·∫øt b·ªã IoT",
        "Nh√† th√¥ng minh (Smart Home) integration trends",
        "Zigbee vs WiFi vs LoRaWAN comparison"
    ]
}

# ==========================================
# 2. CLASS QU·∫¢N L√ù K·∫æT N·ªêI (WEBSOCKET)
# ==========================================
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def send_json(self, data: dict, websocket: WebSocket):
        """G·ª≠i d·ªØ li·ªáu JSON (Quan tr·ªçng cho Dashboard hi·ªÉn th·ªã ·∫£nh/agent)"""
        await websocket.send_json(data)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

class DatabaseManager:
    """Qu·∫£n l√Ω k·∫øt n·ªëi Database cho Server"""
    def __init__(self, db_path=DB_PATH):
        self.db_path = db_path

    def get_connection(self):
        """T·∫°o k·∫øt n·ªëi cho l·ªánh 'with'"""
        return sqlite3.connect(self.db_path, check_same_thread=False)

# Kh·ªüi t·∫°o bi·∫øn to√†n c·ª•c (S·ª≠a l·ªói g·∫°ch ch√¢n ch·ªØ 'db_manager')
db_manager = DatabaseManager()
# ==========================================
# 3. KH·ªûI T·∫†O APP & DATABASE
# ==========================================

def init_db():
    conn = sqlite3.connect(DB_PATH)
    
    # 1. C√°c b·∫£ng c≈© (Gi·ªØ nguy√™n)
    conn.execute("CREATE TABLE IF NOT EXISTS products (id INTEGER PRIMARY KEY, name TEXT, price REAL)")
    conn.execute("CREATE TABLE IF NOT EXISTS finance_logs (id INTEGER PRIMARY KEY, type TEXT, amount REAL)")
    
    # 2. --- B·∫¢NG M·ªöI: TR·∫†NG TH√ÅI NH√ÇN S·ª∞ AI (AGENT STATUS) ---
    # role_tag: M√£ ƒë·ªãnh danh (VD: [ARTIST], [CODER]...) -> L√†m kh√≥a ch√≠nh (Primary Key)
    # xp: ƒêi·ªÉm kinh nghi·ªám t√≠ch l≈©y (M·∫∑c ƒë·ªãnh l√† 0)
    # current_topic: Ch·ªß ƒë·ªÅ v·ª´a h·ªçc g·∫ßn nh·∫•t
    # last_updated: Th·ªùi gian c·∫≠p nh·∫≠t
    conn.execute('''CREATE TABLE IF NOT EXISTS agent_status 
                    (role_tag TEXT PRIMARY KEY, 
                     xp INTEGER DEFAULT 0, 
                     current_topic TEXT, 
                     last_updated DATETIME)''')
    
    conn.commit() # L∆∞u c√°c thay ƒë·ªïi c·∫•u tr√∫c b·∫£ng
    conn.close()

async def morning_briefing_job():
    """
    J.A.R.V.I.S t·ª± ƒë·ªông th·ª©c d·∫≠y l√∫c 7:00 s√°ng ƒë·ªÉ h·ªçc tin t·ª©c.
    """
    print(colored("\n‚è∞ [CRON JOB] ƒêang th·ª±c hi·ªán qu√©t tin t·ª©c bu·ªïi s√°ng...", "cyan", attrs=["bold"]))
    
    if not AI_AVAILABLE or not LLM_PERPLEXITY:
        print(colored("‚ö†Ô∏è B·ªè qua Cron Job v√¨ AI Module ch∆∞a s·∫µn s√†ng.", "yellow"))
        return

    # 1. C√°c ch·ªß ƒë·ªÅ c·∫ßn t·ª± h·ªçc (CEO c√≥ th·ªÉ t√πy ch·ªânh)
    topics = [
        "Nh·ªØng xu h∆∞·ªõng c√¥ng ngh·ªá m·ªõi nh·∫•t trong 24h qua",
        "Bi·∫øn ƒë·ªông th·ªã tr∆∞·ªùng t√†i ch√≠nh, ch·ª©ng kho√°n v√† crypto h√¥m nay",
        "C√°c th∆∞ vi·ªán Python m·ªõi n·ªïi tu·∫ßn n√†y"
        
    ]
    
    report_buffer = []
    
    for topic in topics:
        try:
            # T√¨m ki·∫øm th√¥ng tin m·ªõi nh·∫•t
            print(colored(f"--> ƒêang t√¨m hi·ªÉu: {topic}...", "white"))
            res = await LLM_PERPLEXITY.ainvoke(topic)
            content = res.content
            
            # T·ª± ƒë·ªông ghi nh·ªõ v√†o ƒë·∫ßu n√£o
            if MEMORY_AVAILABLE:
                # L∆∞u v√†o ChromaDB v·ªõi nh√£n "Auto-Learning"
                await run_in_threadpool(lambda: vector_db.add_texts(
                    texts=[content],
                    metadatas=[{
                        "source": "Morning_Briefing", 
                        "topic": topic,
                        "timestamp": datetime.now().isoformat()
                    }]
                ))
            
            report_buffer.append(f"### {topic}\n{content[:500]}...") # L∆∞u t√≥m t·∫Øt
            
        except Exception as e:
            print(colored(f"‚ùå L·ªói t·ª± h·ªçc ch·ªß ƒë·ªÅ '{topic}': {e}", "red"))

    # 2. T·∫°o b√°o c√°o t√≥m t·∫Øt ƒë·ªÉ CEO ƒë·ªçc khi th·ª©c d·∫≠y
    final_report = "\n".join(report_buffer)
    today = datetime.now().strftime("%Y-%m-%d")
    
    # L∆∞u th√†nh file Markdown trong th∆∞ m·ª•c projects
    report_path = f"projects/Morning_Briefing_{today}.md"
    async with aiofiles.open(report_path, "w", encoding="utf-8") as f:
        await f.write(f"# üåÖ B·∫¢N TIN S√ÅNG {today}\n\n{final_report}")
        
    print(colored(f"‚úÖ [DONE] ƒê√£ ho√†n th√†nh t·ª± h·ªçc v√† l∆∞u b√°o c√°o t·∫°i: {report_path}", "green"))
# --- API M·ªöI: CHO PH√âP T·∫¢I D·ªÆ LI·ªÜU V·ªÄ M√ÅY ---


@asynccontextmanager
async def lifespan(app: FastAPI):
    # --- PH·∫¶N STARTUP (Ch·∫°y khi Server b·∫≠t) ---
    init_db()
    for d in [UPLOAD_DIR, "static", "templates","projects"]:
        if not os.path.exists(d): os.makedirs(d)
    logger.info(f"‚úÖ J.A.R.V.I.S SYSTEM ONLINE. Database connected at {DB_PATH}")
    
    # --- K√çCH HO·∫†T L·ªäCH TR√åNH T·ª∞ ƒê·ªòNG ---
    scheduler = AsyncIOScheduler()
    # Ch·∫°y m·ªói ng√†y v√†o l√∫c 7:00 s√°ng
    scheduler.add_job(morning_briefing_job, 'cron', hour=7, minute=0)
    # Ho·∫∑c ch·∫°y th·ª≠ nghi·ªám: m·ªói 1 ti·∫øng ch·∫°y 1 l·∫ßn
    # scheduler.add_job(morning_briefing_job, 'interval', hours=1) 
    
    scheduler.start()
    logger.info("‚è∞ SCHEDULER ACTIVATED: Ch·∫ø ƒë·ªô t·ª± h·ªçc ƒë√£ b·∫≠t.")
    yield # ƒêi·ªÉm ph√¢n c√°ch gi·ªØa B·∫≠t v√† T·∫Øt
    
    # --- PH·∫¶N SHUTDOWN (Ch·∫°y khi Server t·∫Øt - N·∫øu c·∫ßn d·ªçn d·∫πp) ---
    scheduler.shutdown()
    logger.info("üí§ J.A.R.V.I.S SYSTEM SHUTTING DOWN...")

# --- KH·ªûI T·∫†O APP ---
app = FastAPI(
    title="J.A.R.V.I.S Neural Backend",
    description="H·ªá ƒëi·ªÅu h√†nh AI Corporation - Enterprise Edition",
    version="3.0", # Version updated
    lifespan=lifespan
)

# C·∫•u h√¨nh CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- THI·∫æT L·∫¨P TH∆Ø M·ª§C Tƒ®NH ---
base_dir = os.path.abspath(os.path.dirname(__file__))
static_dir = os.path.join(base_dir, 'static')
templates_dir = os.path.join(base_dir, 'templates')

# T·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c n·∫øu thi·∫øu (Tr√°nh l·ªói Crash)
for d in [UPLOAD_DIR, static_dir, templates_dir]:
    if not os.path.exists(d):
        os.makedirs(d)

app.mount("/static", StaticFiles(directory=static_dir), name="static")
templates = Jinja2Templates(directory=templates_dir)

# --- DATA MODELS (Pydantic) ---
class ChatRequest(BaseModel):
    message: str
    thread_id: str = "ceo_session"

class SpeakRequest(BaseModel):
    text: str

class LearnRequest(BaseModel):
    text: str

class BuyRequest(BaseModel):
    product_id: int

class TTSRequest(BaseModel):
    text: str

# --- DEPENDENCIES ---
async def verify_api_key(x_api_key: Optional[str] = Header(None)):
    """Middleware ki·ªÉm tra b·∫£o m·∫≠t"""
    # Logic: N·∫øu c√≥ g·ª≠i key th√¨ check, n·∫øu kh√¥ng g·ª≠i (Dev mode) th√¨ b·ªè qua ho·∫∑c ch·∫∑n t√πy CEO
    if x_api_key and x_api_key != ADMIN_SECRET:
        raise HTTPException(status_code=403, detail="‚õî SAI M·∫¨T M√É QU√ÇN S·ª∞ (WRONG API KEY)")
    return x_api_key

async def heavy_project_executor(project_request: str, thread_id: str):
    """
    H√†m x·ª≠ l√Ω d·ª± √°n l·ªõn (ERP, CRM) ch·∫°y n·ªÅn h√†ng gi·ªù ƒë·ªìng h·ªì.
    """
    import asyncio
    print(colored(f"üèóÔ∏è [HEAVY PROJECT] B·∫Øt ƒë·∫ßu: {project_request}", "magenta", attrs=["bold"]))
    
    log_file = f"projects/{thread_id}_log.txt"
    blueprint_path = f"projects/{thread_id}_BLUEPRINT.md"

    try:
        if not LLM_SUPERVISOR:
             raise Exception("LLM_SUPERVISOR ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Ki·ªÉm tra l·∫°i main.py")
        # Giai ƒëo·∫°n 1: L·∫≠p k·∫ø ho·∫°ch (D√πng Supervisor)
        plan_prompt = f"L√† ki·∫øn tr√∫c s∆∞ ph·∫ßn m·ªÅm, h√£y chia d·ª± √°n '{project_request}' th√†nh danh s√°ch c√°c b∆∞·ªõc (modules) k·ªπ thu·∫≠t c·ª• th·ªÉ ƒë·ªÉ code l·∫ßn l∆∞·ª£t. Tr·∫£ v·ªÅ d·∫°ng g·∫°ch ƒë·∫ßu d√≤ng."
        # L∆∞u √Ω: C·∫ßn import LLM_SUPERVISOR t·ª´ main
        plan_res = await run_in_threadpool(lambda: LLM_SUPERVISOR.invoke(plan_prompt))
        steps = [s.strip() for s in plan_res.content.split('\n') if '-' in s or '*' in s]
        
        with open(log_file, "w", encoding="utf-8") as f:
            f.write(f"PROJECT PLAN:\n{plan_res.content}\n{'='*50}\n")
            
        # Giai ƒëo·∫°n 2: Code t·ª´ng ph·∫ßn (Loop)
        for idx, step in enumerate(steps):
            print(colored(f"‚è≥ Doing Step {idx+1}/{len(steps)}: {step}", "yellow"))
            
            # G·ªçi AI Brain (ai_app) ƒë·ªÉ th·ª±c hi·ªán b∆∞·ªõc n√†y
            # Truy·ªÅn ng·ªØ c·∫£nh l√† c√°c file ƒë√£ l√†m xong (ƒë·ªçc t·ª´ log ho·∫∑c vector db n·∫øu c·∫ßn)
            step_input = f"Th·ª±c hi·ªán b∆∞·ªõc {idx+1}: {step}. H√£y vi·∫øt code ho√†n ch·ªânh cho module n√†y."
            
            # G·ªçi v√†o LangGraph
            state_res = await ai_app.ainvoke(
                {"messages": [HumanMessage(content=step_input)]},
                config={"configurable": {"thread_id": thread_id}}
            )
            
            ai_output = state_res['messages'][-1].content
            
            # L∆∞u k·∫øt qu·∫£ v√†o file
            with open(log_file, "a", encoding="utf-8") as f:
                f.write(f"\n\n--- STEP {idx+1}: {step} ---\n{ai_output}\n")
            
            # Ngh·ªâ 2 gi√¢y ƒë·ªÉ tr√°nh spam API
            await asyncio.sleep(2)

        print(colored(f"‚úÖ [DONE] D·ª± √°n {thread_id} ƒë√£ ho√†n t·∫•t!", "green"))

    except Exception as e:
        print(colored(f"‚ùå [FAILED] D·ª± √°n b·ªã l·ªói: {e}", "red"))
        with open(log_file, "a", encoding="utf-8") as f:
            f.write(f"\n‚ùå ERROR: {str(e)}")

# 2. API Endpoint ƒë·ªÉ k√≠ch ho·∫°t
@app.post("/api/heavy_project")
async def start_heavy_project(request: ChatRequest, background_tasks: BackgroundTasks):
    """
    API ƒë·ªÉ CEO k√≠ch ho·∫°t ch·∫ø ƒë·ªô l√†m d·ª± √°n l·ªõn.
    """
    # T·∫°o Thread ID ri√™ng cho d·ª± √°n n·∫øu ch∆∞a c√≥
    pid = request.thread_id or f"proj_{int(time.time())}"
    
    # ƒê·∫©y v√†o ch·∫°y n·ªÅn (Fire and Forget)
    background_tasks.add_task(heavy_project_executor, request.message, pid)
    
    return {
        "status": "PROCESSING",
        "project_id": pid,
        "message": "ƒê√£ ti·∫øp nh·∫≠n d·ª± √°n ERP. H·ªá th·ªëng s·∫Ω ch·∫°y ng·∫ßm.",
        "log_path": f"projects/{pid}_log.txt"
    }

@app.get("/api/sync/download_db")
async def download_database():
    db_path = "ai_corp_projects.db" # T√™n file Database c·ªßa ng√†i
    if os.path.exists(db_path):
        # Tr·∫£ v·ªÅ file cho Client t·∫£i
        return FileResponse(path=db_path, filename="ai_corp_projects_cloud.db", media_type='application/octet-stream')
    return {"error": "Ch∆∞a c√≥ d·ªØ li·ªáu n√†o ƒë∆∞·ª£c t·∫°o ra."}

# ==========================================
# üöÄ SYSTEM ROUTES
# ==========================================

@app.get("/health")
async def health_check():
    """
    Ki·ªÉm tra t√¨nh tr·∫°ng s·ª©c kh·ªèe to√†n di·ªán c·ªßa h·ªá th·ªëng.
    """
    # Ki·ªÉm tra k·∫øt n·ªëi Database v·∫≠t l√Ω
    db_status = "CONNECTED" if os.path.exists(DB_PATH) else "MISSING"
    
    return {
        "status": "OPERATIONAL",
        "timestamp": datetime.now().isoformat(),
        "modules": {
            "ai_brain": "ONLINE" if AI_AVAILABLE else "OFFLINE",
            "voice_core": "ONLINE" if VOICE_AVAILABLE else "OFFLINE",
            "memory_core": "ONLINE" if MEMORY_AVAILABLE else "OFFLINE",
            "knowledge_db": db_status,
        }
    }

@app.get("/api/stats")
async def get_system_stats():
    conn = sqlite3.connect(DB_PATH)
    try:
        cursor = conn.cursor()
        # D√πng try-except ƒë·ªÉ tr√°nh l·ªói n·∫øu b·∫£ng ch∆∞a t·ªìn t·∫°i
        try:
            prod_count = cursor.execute("SELECT count(*) FROM products").fetchone()[0]
            income = cursor.execute("SELECT SUM(amount) FROM finance_logs WHERE type='income'").fetchone()[0] or 0
            expense = cursor.execute("SELECT SUM(amount) FROM finance_logs WHERE type='expense'").fetchone()[0] or 0
        except sqlite3.OperationalError:
            return {"products": 0, "revenue": 0, "expense": 0, "balance": 0}
        return {
            "products": prod_count,
            "balance": income - expense,
            "revenue": income,
            "expense": expense
        }
    finally:
        conn.close()

# ==========================================
# ü§ñ AI ROUTES (ASYNC MODE)
# ==========================================
def get_latest_audit_report():
    try:
        list_of_files = glob.glob('Project_Audit_*.md')
        if not list_of_files:
            return "Th∆∞a CEO, hi·ªán t·∫°i h·ªá th·ªëng ch∆∞a ghi nh·∫≠n b√°o c√°o n√†o. Ng√†i c√≥ mu·ªën kh·ªüi ƒë·ªông m·ªôt d·ª± √°n m·ªõi?"
        latest_file = max(list_of_files, key=os.path.getctime)
        with open(latest_file, "r", encoding="utf-8") as f:
            content = f.read()
        # Tr·∫£ v·ªÅ ƒë·ªãnh d·∫°ng t√≥m t·∫Øt ƒë·ªÉ Gemini/J.A.R.V.I.S d·ªÖ "ƒë·ªçc"
        return f"### üìä B√ÅO C√ÅO C·∫¨P NH·∫¨T T·ª™ {latest_file}\n\n{content}"

    except Exception as e:
        logger.error(f"üö® [REPORT ERROR]: {str(e)}")
        # Tr·∫£ v·ªÅ chu·ªói th√¥ng b√°o l·ªói thay v√¨ Dict
        return f"‚ö†Ô∏è Th∆∞a CEO, t√¥i g·∫∑p kh√≥ khƒÉn khi truy xu·∫•t h·ªì s∆°: {str(e)}. C√≥ v·∫ª nh∆∞ t·ªáp tin ƒëang b·ªã kh√≥a ho·∫∑c ƒë√£ b·ªã di chuy·ªÉn."
# --- C·∫¨P NH·∫¨T H√ÄM CHAT ---

@app.post("/api/chat")
async def chat(request: ChatRequest, background_tasks: BackgroundTasks):
    """
    SMART CHAT V3: MEMORY INTEGRATED + OPTIMIZED ROUTING
    """
    if not AI_AVAILABLE:
        return {"reply": "‚ö†Ô∏è H·ªá th·ªëng AI ƒëang kh·ªüi ƒë·ªông l·∫°i. Vui l√≤ng ƒë·ª£i."}
    
    try:
        user_msg = str(request.message).strip()
        user_msg_lower = user_msg.lower()
        
        # --- 1. INTERCEPTOR (X√£ giao & B√°o c√°o - Gi·ªØ nguy√™n cho nhanh) ---
        greetings = ["ch√†o", "hi", "hello", "alo", "c√≥ ƒë√≥ kh√¥ng"]
        if any(k == user_msg_lower for k in greetings) and len(user_msg.split()) < 5:
            hour = datetime.now().hour
            time_greet = "bu·ªïi s√°ng" if 5 <= hour < 12 else "bu·ªïi chi·ªÅu" if 12 <= hour < 18 else "bu·ªïi t·ªëi"
            return {"reply": f"Ch√†o CEO! Ch√∫c ng√†i m·ªôt {time_greet} t·ªët l√†nh. T√¥i ƒëang ch·ªù l·ªánh."}

        if any(k in user_msg_lower for k in ["t·ªïng k·∫øt", "b√°o c√°o audit", "ki·ªÉm to√°n"]):
            return {"reply": get_latest_audit_report()}

        # --- 2. MEMORY RECALL (H·ªíI T∆Ø·ªûNG K√ù ·ª®C) ---
        memory_context = ""
        if MEMORY_AVAILABLE:
            print(colored(f"üß† ƒêang l·ª•c l·ªçi k√Ω ·ª©c cho: '{user_msg}'...", "magenta"))
            # Ch·∫°y trong threadpool ƒë·ªÉ kh√¥ng ch·∫∑n
            memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_msg))
        # --- 3. FAST TRACK (H·ªèi nhanh ƒë√°p g·ªçn) ---
        fast_keywords = ["gi√° v√†ng", "th·ªùi ti·∫øt", "m·∫•y gi·ªù", "ng√†y m·∫•y", "t·ª∑ gi√°", "k·∫øt qu·∫£", "b√≥ng ƒë√°", "ai l√†", "d√¢n s·ªë", "gi√° coin"]
        is_fast_query = any(k in user_msg_lower for k in fast_keywords)

        if is_fast_query:
            # ∆Øu ti√™n 1: Perplexity (N·∫øu h·ªèi tin t·ª©c/d·ªØ li·ªáu realtime)
            if LLM_PERPLEXITY:
                try:
                    fast_response = await LLM_PERPLEXITY.ainvoke(user_msg)
                    return {"reply": fast_response.content, "agent": "‚ö° Perplexity Search", "timestamp": datetime.now().isoformat()}
                except: pass 
            
            # ∆Øu ti√™n 2: Gemini (N·∫øu c·∫ßn t·ªëc ƒë·ªô suy lu·∫≠n nhanh)
            if LLM_GEMINI:
                try:
                    # Inject Memory nh·∫π v√†o Fast Track ƒë·ªÉ AI th√¥ng minh h∆°n (VD: Th·ªùi ti·∫øt -> nh·ªõ v·ªã tr√≠ Phan Thi·∫øt)
                    fast_prompt = f"Th√¥ng tin b·ªï tr·ª£ (K√Ω ·ª©c): {memory_context}\nC√¢u h·ªèi: {user_msg}"
                    direct_response = await LLM_GEMINI.ainvoke([
                        {"role": "system", "content": "B·∫°n l√† AI Search Engine. Tr·∫£ l·ªùi Ng·∫Øn g·ªçn, Ch√≠nh x√°c. Kh√¥ng ph√¢n t√≠ch d√†i d√≤ng."},
                        {"role": "user", "content": fast_prompt}
                    ])
                    return {"reply": direct_response.content, "agent": "‚ö° Gemini Speed", "timestamp": datetime.now().isoformat()}
                except: pass

        # --- 4. DEEP THINKING (G·ªçi LangGraph - B·ªô n√£o ch√≠nh) ---
        # B∆°m K√Ω ·ª©c (Memory) v√†o ng·ªØ c·∫£nh h·ªá th·ªëng
        current_context = f"[SYSTEM INFO: Time={datetime.now().strftime('%H:%M')}, Location=Phan Thiet]"
        full_prompt = (
            f"{current_context}\n"
            f"[ACTIVE MEMORY - K√ù ·ª®C LI√äN QUAN]:\n{memory_context}\n\n"
            f"[USER REQUEST]: {user_msg}"
        )
        
        from langchain_core.messages import HumanMessage
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # G·ªçi LangGraph x·ª≠ l√Ω
        final_state = await ai_app.ainvoke(
            {"messages": [HumanMessage(content=full_prompt)]}, 
            config=config
        )
        
        last_message = final_state['messages'][-1]
        ai_reply = last_message.content if hasattr(last_message, 'content') else str(last_message)
        current_agent = final_state.get("current_agent", "J.A.R.V.I.S")

        # --- 5. MEMORY SAVE (BACKGROUND TASK) ---
        # L∆∞u k√Ω ·ª©c CH·ª¶ ƒê·ªòNG m√† kh√¥ng b·∫Øt CEO ph·∫£i ch·ªù
        if MEMORY_AVAILABLE:
            background_tasks.add_task(extract_and_save_memory, user_msg, ai_reply)
        background_tasks.add_task(log_training_data, user_msg, ai_reply, success=True)
        
        return {
            "reply": ai_reply,
            "agent": current_agent,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Chat Error: {e}")
        return {"reply": f"üí• L·ªói x·ª≠ l√Ω logic: {str(e)}"}
@app.post("/api/speak")
async def api_speak(request: SpeakRequest):
    """
    API T·∫°o gi·ªçng n√≥i (ƒê√£ t·ªëi ∆∞u h√≥a Non-blocking & Fail-safe).
    """
    # 1. Ki·ªÉm tra an to√†n: N·∫øu module voice ch∆∞a load ho·∫∑c client ch∆∞a c√≥ -> B·ªè qua nh·∫π nh√†ng
    if not VOICE_AVAILABLE or 'client' not in globals() or client is None:
        # Tr·∫£ v·ªÅ 204 (No Content) ƒë·ªÉ Dashboard bi·∫øt m√† im l·∫∑ng, kh√¥ng b√°o l·ªói ƒë·ªè
        return Response(status_code=204)
    
    try:
        # 2. T·ªëi ∆∞u chi ph√≠ & T·ªëc ƒë·ªô: Ch·ªâ ƒë·ªçc 500 k√Ω t·ª± ƒë·∫ßu
        # (J.A.R.V.I.S kh√¥ng n√™n ƒë·ªçc c·∫£ b√†i vƒÉn d√†i, t·ªën ti·ªÅn v√† l√¢u)
        safe_text = request.text[:1000] 

        # 3. K·ªπ thu·∫≠t Non-blocking (QUAN TR·ªåNG NH·∫§T)
        # ƒê·∫©y vi·ªác g·ªçi OpenAI sang lu·ªìng kh√°c ƒë·ªÉ Server v·∫´n nh·∫≠n chat c·ªßa ng∆∞·ªùi kh√°c ƒë∆∞·ª£c
        def _generate_audio():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx", 
                input=safe_text
            )
        
        # D√πng await ƒë·ªÉ ƒë·ª£i lu·ªìng ph·ª• x·ª≠ l√Ω xong
        response = await run_in_threadpool(_generate_audio)
        return Response(content=response.content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [VOICE ERROR]: {str(e)}")
        # N·∫øu l·ªói (h·∫øt ti·ªÅn, m·∫•t m·∫°ng...), tr·∫£ v·ªÅ 204 ƒë·ªÉ Dashboard v·∫´n ch·∫°y ti·∫øp m∆∞·ª£t m√†
        return Response(status_code=204)

@app.post("/api/tts")
async def text_to_speech_api(request: TTSRequest):
    """
    API TTS: S·ª¨ D·ª§NG GOOGLE TRANSLATE (MI·ªÑN PH√ç)
    """
    try:
        # 1. L·∫•y vƒÉn b·∫£n (C·∫Øt ng·∫Øn ƒë·ªÉ tr√°nh l·ªói Google n·∫øu qu√° d√†i)
        speak_text = request.text[:500]
        logger.info(f"ü§ñ Google TTS Request: {speak_text[:50]}...")

        # 2. H√†m t·∫°o √¢m thanh Google (Ch·∫°y trong lu·ªìng ri√™ng ƒë·ªÉ kh√¥ng ch·∫∑n Server)
        def _generate_google_audio():
            # lang='vi': Ti·∫øng Vi·ªát
            # tld='com.vn': Gi·ªçng Vi·ªát Nam chu·∫©n h∆°n
            tts = gTTS(text=speak_text, lang='vi', tld='com.vn')
            
            # L∆∞u v√†o b·ªô nh·ªõ ƒë·ªám (RAM) thay v√¨ ·ªï c·ª©ng -> Nhanh h∆°n
            buffer = io.BytesIO()
            tts.write_to_fp(buffer)
            buffer.seek(0)
            return buffer.read()

        # 3. Th·ª±c thi
        audio_content = await run_in_threadpool(_generate_google_audio)
        
        # 4. Tr·∫£ v·ªÅ file √¢m thanh
        return Response(content=audio_content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [GOOGLE TTS ERROR]: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/api/voice_chat")
async def voice_chat(file: UploadFile = File(...), api_key: str = Depends(verify_api_key)):
    """
    T∆Ø∆†NG T√ÅC B·∫∞NG GI·ªåNG N√ìI (Voice-to-Voice)
    1. Nghe (Whisper) -> 2. Hi·ªÉu & L√†m (Smart Chat) -> 3. N√≥i l·∫°i (TTS)
    """
    if not AI_AVAILABLE or 'client' not in globals():
        return JSONResponse(status_code=503, content={"error": "AI/Voice Module ch∆∞a s·∫µn s√†ng"})

    # 1. L∆ØU FILE T·∫†M
    temp_filename = f"temp_{uuid.uuid4()}.webm"
    temp_path = os.path.join(UPLOAD_DIR, temp_filename)
    
    try:
        async with aiofiles.open(temp_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)

        # 2. D·ªäCH GI·ªåNG N√ìI SANG CH·ªÆ (WHISPER - TAI NGHE)
        # Ch·∫°y trong lu·ªìng ph·ª• ƒë·ªÉ kh√¥ng treo server
        def _transcribe():
            with open(temp_path, "rb") as audio_file:
                return client.audio.transcriptions.create(
                    model="whisper-1", 
                    file=audio_file,
                    language="vi" # ∆Øu ti√™n ti·∫øng Vi·ªát
                )
        
        transcript = await run_in_threadpool(_transcribe)
        user_text = transcript.text
        print(f"üé§ [VOICE INPUT]: {user_text}")
        
        # 2. Smart Chat
        chat_req = ChatRequest(message=user_text, thread_id="voice_session")
        
        # --- Logic Chat t·ªëi gi·∫£n cho Voice (ƒê·ªÉ tr√°nh l·ªói BackgroundTasks) ---
        memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_text)) if MEMORY_AVAILABLE else ""
        fast_keywords = ["gi√° v√†ng", "th·ªùi ti·∫øt", "m·∫•y gi·ªù", "ng√†y m·∫•y"]
        if any(k in user_text.lower() for k in fast_keywords) and LLM_GEMINI:
             ai_res = await LLM_GEMINI.ainvoke(f"K√Ω ·ª©c: {memory_context}. H·ªèi: {user_text}")
             ai_text = ai_res.content
             agent_name = "Gemini Voice"
        else:
             # Deep Thinking
             full_prompt = f"K√Ω ·ª©c: {memory_context}\nUser: {user_text}"
             from langchain_core.messages import HumanMessage
             final_state = await ai_app.ainvoke({"messages": [HumanMessage(content=full_prompt)]}, config={"configurable": {"thread_id": "voice"}})
             last_message = final_state['messages'][-1]
             ai_text = last_message.content
             agent_name = final_state.get("current_agent", "J.A.R.V.I.S")
        
        speak_text = ai_text[:500] 
        def _speak():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx",
                input=speak_text
            )
        audio_res = await run_in_threadpool(_speak)

        # 5. TR·∫¢ V·ªÄ K·∫æT QU·∫¢ K√âP (TEXT + AUDIO BLOB)
        # Ta tr·∫£ v·ªÅ JSON ch·ª©a text, c√≤n Audio s·∫Ω ƒë∆∞·ª£c Frontend x·ª≠ l√Ω ri√™ng ho·∫∑c d√πng base64
        
        audio_b64 = base64.b64encode(audio_res.content).decode('utf-8')

        return {
            "text_reply": ai_text,
            "audio_base64": audio_b64,
            "transcript": user_text,
            "agent": agent_name
        }

    except Exception as e:
        logger.error(f"Voice Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        # D·ªçn d·∫πp file r√°c
        if os.path.exists(temp_path):
            os.remove(temp_path)

# Th√™m h√†m h·ªó tr·ª£ t√≠nh Level t·ª´ XP
def calculate_level(xp: int) -> int:
    # C√¥ng th·ª©c ƒë∆°n gi·∫£n: C·ª© 100 XP l√† l√™n 1 Level. Level kh·ªüi ƒë·∫ßu l√† 1.
    return int(xp / 100) + 1

# C·∫≠p nh·∫≠t h√†m ƒë√†o t·∫°o
async def specialized_training_job(role_tag: str):
    print(colored(f"üéì [TRAINING] B·∫Øt ƒë·∫ßu ƒë√†o t·∫°o chuy√™n s√¢u cho {role_tag}...", "cyan"))
    
    # 1. L·∫•y ch·ªß ƒë·ªÅ (Nh∆∞ c≈©)
    topics = CURRICULUM.get(role_tag, [])
    if not topics: return
    current_topic_learned = topics[0] # L·∫•y ch·ªß ƒë·ªÅ ƒë·∫ßu ti√™n l√†m v√≠ d·ª•

    # ... (Ph·∫ßn code ƒëi search v√† l∆∞u ki·∫øn th·ª©c c≈© gi·ªØ nguy√™n) ...
    # Gi·∫£ s·ª≠ ng√†i ƒë√£ search v√† c√≥ n·ªôi dung trong bi·∫øn 'full_knowledge'
    
    # --- ƒêO·∫†N M·ªöI: C·∫¨P NH·∫¨T TR·∫†NG TH√ÅI V√ÄO DB ---
    try:
        with db_manager.get_connection() as conn:
            c = conn.cursor()
            
            # a. L·∫•y XP hi·ªán t·∫°i
            c.execute("SELECT xp FROM agent_status WHERE role_tag = ?", (role_tag,))
            row = c.fetchone()
            current_xp = row['xp'] if row else 0
            
            # b. C·ªông th√™m XP (VD: M·ªói l·∫ßn h·ªçc xong c·ªông 50 XP)
            new_xp = current_xp + 50
            
            # c. L∆∞u v√†o DB
            c.execute("""
                INSERT OR REPLACE INTO agent_status (role_tag, xp, current_topic, last_updated)
                VALUES (?, ?, ?, ?)
            """, (role_tag, new_xp, current_topic_learned, datetime.datetime.now()))
            conn.commit()
            
        new_level = calculate_level(new_xp)
        print(colored(f"‚úÖ [UPGRADE] {role_tag} ƒë√£ h·ªçc xong '{current_topic_learned}'. XP: {new_xp} -> Level {new_level}", "green"))
        
    except Exception as e:
        print(colored(f"‚ùå L·ªói c·∫≠p nh·∫≠t tr·∫°ng th√°i Agent: {e}", "red"))

# Trong server.py, ph·∫ßn khai b√°o API
@app.get("/api/agents/status")
async def get_agents_status_endpoint():
    """Tr·∫£ v·ªÅ danh s√°ch tr·∫°ng th√°i c·ªßa t·∫•t c·∫£ Agents"""
    try:
        with db_manager.get_connection() as conn:
             # L·∫•y d·ªØ li·ªáu v√† t√≠nh lu√¥n Level
            df = pd.read_sql_query("SELECT *, (xp / 100) + 1 as level FROM agent_status", conn)
            return df.to_dict(orient="records")
    except Exception as e:
        return {"error": str(e)}
# ==========================================
# ‚ö° WEBSOCKET REAL-TIME (THE NEXUS)
# ==========================================
async def architect_planner(project_request: str, thread_id: str):
    """
    Ch·ªâ l·∫≠p k·∫ø ho·∫°ch chi ti·∫øt, KH√îNG vi·∫øt code.
    M·ª•c ti√™u: ƒê·ªÉ CEO duy·ªát tr∆∞·ªõc logic.
    """
    print(colored(f"üìê [ARCHITECT] ƒêang ph√°c th·∫£o d·ª± √°n: {project_request}", "cyan"))
    
    # Prompt chuy√™n d·ª•ng cho Ki·∫øn tr√∫c s∆∞
    architect_prompt = (
        f"B·∫°n l√† Chief Software Architect (CSA). C√≥ m·ªôt y√™u c·∫ßu d·ª± √°n ERP: '{project_request}'.\n"
        "H√£y l·∫≠p m·ªôt B·∫¢N THI·∫æT K·∫æ K·ª∏ THU·∫¨T (Technical Blueprint) chi ti·∫øt g·ªìm:\n"
        "1. [MODULES]: Danh s√°ch c√°c ch·ª©c nƒÉng chi ti·∫øt.\n"
        "2. [DATABASE]: S∆° ƒë·ªì b·∫£ng (Table Schema) cho SQLite/PostgreSQL.\n"
        "3. [TECH STACK]: C√¥ng ngh·ªá s·ª≠ d·ª•ng (Frontend/Backend/Libs).\n"
        "4. [FLOW]: Quy tr√¨nh nghi·ªáp v·ª• (V√≠ d·ª•: Nh·∫≠p kho -> C·∫≠p nh·∫≠t t·ªìn -> B√°o c√°o).\n"
        "5. [FILE STRUCTURE]: C·∫•u tr√∫c th∆∞ m·ª•c d·ª± ki·∫øn.\n\n"
        "Y√äU C·∫¶U: Tr√¨nh b√†y d·∫°ng Markdown r√µ r√†ng ƒë·ªÉ CEO duy·ªát."
    )
    
    # D√πng Supervisor (Gemini 1.5 Pro) v√¨ context window l·ªõn, t∆∞ duy t·ªët
    plan_res = await run_in_threadpool(lambda: LLM_SUPERVISOR.invoke(architect_prompt))
    
    # L∆∞u b·∫£n v·∫Ω ra file ƒë·ªÉ CEO xem
    plan_path = f"projects/{thread_id}_BLUEPRINT.md"
    with open(plan_path, "w", encoding="utf-8") as f:
        f.write(plan_res.content)
        
    print(colored(f"‚úÖ [PLAN READY] B·∫£n v·∫Ω ƒë√£ xong: {plan_path}", "green"))
    return plan_res.content, plan_path

@app.post("/api/plan_project")
async def plan_project_endpoint(request: ChatRequest):
    """
    B∆∞·ªõc 1: CEO y√™u c·∫ßu l·∫≠p k·∫ø ho·∫°ch.
    """
    if not AI_AVAILABLE: return {"status": "ERROR", "message": "AI Offline"}
    
    pid = request.thread_id or f"proj_{int(time.time())}"
    
    # G·ªçi h√†m architect (Ch·ªù k·∫øt qu·∫£ lu√¥n ƒë·ªÉ tr·∫£ v·ªÅ cho CEO xem ngay)
    plan_content, plan_path = await architect_planner(request.message, pid)
    
    return {
        "status": "PLAN_CREATED",
        "project_id": pid,
        "message": "ƒê√£ l·∫≠p xong b·∫£n thi·∫øt k·∫ø. Vui l√≤ng xem x√©t.",
        "blueprint_content": plan_content, # Tr·∫£ v·ªÅ n·ªôi dung ƒë·ªÉ hi·ªán l√™n Dashboard
        "blueprint_path": plan_path,
        "next_action": "N·∫øu ƒë·ªìng √Ω, h√£y g·ªçi /api/heavy_project v·ªõi n·ªôi dung 'EXECUTE_BLUEPRINT'"
    }

@app.websocket("/ws/nexus")
async def websocket_nexus(websocket: WebSocket):
    await manager.connect(websocket)
    try:
        # G·ª≠i l·ªùi ch√†o (D·∫°ng JSON cho Dashboard)
        await manager.send_json({
            "sender": "J.A.R.V.I.S",
            "content": "H·ªá th·ªëng tr·ª±c tuy·∫øn. ƒêang ƒë·ªìng b·ªô th·ªùi gian th·ª±c...",
            "agent": "System"
        }, websocket)
        
        while True:
            data = await websocket.receive_text()
            print(colored(f"‚ö° [INPUT]: {data}", "cyan"))
            
            # ============================================================
            # PH·∫¶N 1: KH√îI PH·ª§C C√ÅC T√çNH NƒÇNG C≈® (C·ª¶A NG√ÄI)
            # ============================================================
            
            # 1. L·∫§Y TH√îNG TIN H·ªÜ TH·ªêNG (Th·ªùi gian th·ª±c)
            current_time = datetime.now().strftime("%H:%M, Th·ª© %w, ng√†y %d/%m/%Y")
            system_context = f"Hi·ªán t·∫°i l√† {current_time}. V·ªã tr√≠: Phan Thi·∫øt, Vi·ªát Nam."
            
            # 2. H·ªíI T∆Ø·ªûNG K√ù ·ª®C
            mem_ctx = ""
            if MEMORY_AVAILABLE:
                mem_ctx = await run_in_threadpool(lambda: recall_relevant_memories(data))
                if mem_ctx: print(colored(f"üß† [K√ù ·ª®C]: {mem_ctx[:100]}...", "magenta"))

            # ============================================================
            # PH·∫¶N 2: X·ª¨ L√ù TH√îNG MINH (K·∫æT H·ª¢P LANGGRAPH)
            # ============================================================
            
            # T·∫°o Prompt ch·ª©a ƒë·∫ßy ƒë·ªß th√¥ng tin: Th·ªùi gian + K√Ω ·ª©c + C√¢u h·ªèi
            # ƒêi·ªÅu n√†y gi√∫p Agent (H·ªça sƒ©/Coder) c≈©ng bi·∫øt b√¢y gi·ªù l√† m·∫•y gi·ªù
            full_prompt = f"""
            [SYSTEM CONTEXT]: {system_context}
            [MEMORY]: {mem_ctx}
            [USER REQUEST]: {data}
            """
            
            reply_content = ""
            active_agent = "J.A.R.V.I.S"

            # A. FAST TRACK (Gi·ªØ l·∫°i logic c≈© cho c√°c c√¢u h·ªèi ƒë∆°n gi·∫£n ƒë·ªÉ ti·∫øt ki·ªám)
            # N·∫øu ch·ªâ h·ªèi ng√†y gi·ªù, gi√° c·∫£ -> D√πng Gemini/GPT tr·ª±c ti·∫øp cho nhanh
            fast_keywords = ["bao nhi√™u ng√†y", "t·∫øt", "th·ª© m·∫•y", "ng√†y m·∫•y", "m·∫•y gi·ªù", "th·ªùi ti·∫øt", "gi√°"]
            is_simple = any(k in data.lower() for k in fast_keywords) and not any(k in data.lower() for k in ["v·∫Ω", "code", "l·∫≠p tr√¨nh"])

            if is_simple and LLM_GEMINI:
                print(colored("üöÄ K√≠ch ho·∫°t Fast Track (Real-time Context)...", "yellow"))
                try:
                    # G·ªçi Gemini tr·∫£ l·ªùi nhanh c√¢u h·ªèi ng√†y gi·ªù
                    ai_msg = await LLM_GEMINI.ainvoke(full_prompt)
                    reply_content = ai_msg.content
                    active_agent = "J.A.R.V.I.S"
                except: pass
            
            # B. DEEP THINKING (N·∫øu Fast Track b·ªè qua HO·∫∂C l√† l·ªánh V·∫Ω/Code)
            if not reply_content and AI_AVAILABLE:
                # G·ªçi b·ªô n√£o LangGraph (Supervisor -> Designer/Coder...)
                print(colored("üß© Chuy·ªÉn giao cho B·ªô N√£o Trung T√¢m (LangGraph)...", "blue"))
                
                input_message = HumanMessage(content=full_prompt)
                
                final_state = await ai_app.ainvoke(
                    {"messages": [input_message]},
                    config={"configurable": {"thread_id": "ws_live_session"}}
                )
                
                # L·∫•y k·∫øt qu·∫£ t·ª´ Agent cu·ªëi c√πng
                last_message = final_state['messages'][-1]
                reply_content = last_message.content
                
                # X√°c ƒë·ªãnh ai v·ª´a l√†m vi·ªác (ƒê·ªÉ Dashboard s√°ng ƒë√®n)
                active_agent = final_state.get("current_agent", "J.A.R.V.I.S")

            # ============================================================
            # PH·∫¶N 3: PH·∫¢N H·ªíI (D·∫†NG JSON CHO DASHBOARD)
            # ============================================================
            print(colored(f"ü§ñ [{active_agent}]: {reply_content}", "magenta"))
            
            # G·ª≠i JSON xu·ªëng Client
            response_data = {
                "sender": active_agent,
                "content": reply_content,
                "agent": active_agent # Dashboard d√πng c√°i n√†y ƒë·ªÉ highlight icon
            }
            
            await manager.send_json(response_data, websocket)

            # 4. GHI NH·ªö L·∫†I
            if MEMORY_AVAILABLE:
                await run_in_threadpool(lambda: extract_and_save_memory(data, reply_content))

    except WebSocketDisconnect:
        manager.disconnect(websocket)
    except Exception as e:
        logger.error(f"WS Error: {e}")
        manager.disconnect(websocket)
        
@app.post("/api/learn")
async def api_learn(request: LearnRequest, api_key: str = Depends(verify_api_key)):
    if not AI_AVAILABLE: return {"status": "error", "message": "AI Module Offline"}
    result = learn_knowledge(request.text)
    return {"status": "success", "message": result}

@app.post("/api/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    safe_filename = f"{uuid.uuid4().hex[:8]}_{file.filename}"
    file_path = os.path.join(UPLOAD_DIR, safe_filename)
    
    try:
        # Ghi file b·∫•t ƒë·ªìng b·ªô (Non-blocking I/O)
        async with aiofiles.open(file_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)
            
        if AI_AVAILABLE:
            result = ingest_docs_to_memory(file_path)
            return {"status": "success", "message": result, "path": file_path}
        return {"status": "saved", "message": "File saved but AI ingestion skipped (Offline)."}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Upload failed: {str(e)}")

# ==========================================
# üõí STORE ROUTES
# ==========================================

@app.get("/api/products")
async def get_products():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    try:
        products = conn.execute("SELECT * FROM products").fetchall()
        return [dict(row) for row in products]
    except:
        return []
    finally:
        conn.close()

@app.post("/api/buy")
async def buy_product(req: BuyRequest):
    conn = sqlite3.connect(DB_PATH)
    try:
        product = conn.execute("SELECT price, name FROM products WHERE id=?", (req.product_id,)).fetchone()
        if not product:
            raise HTTPException(status_code=404, detail="Product not found")
            
        price, name = product[0], product[1]
        license_key = str(uuid.uuid4()).upper()[:19]
        
        # X·ª≠ l√Ω t√†i ch√≠nh (Dynamic Import ƒë·ªÉ tr√°nh l·ªói v√≤ng l·∫∑p)
        try:
            from finance_manager import process_order_revenue
            process_order_revenue(order_id=int(time.time()), total_amount=price)
        except ImportError:
            pass 
            
        return {
            "status": "success",
            "msg": f"ƒê√£ mua th√†nh c√¥ng: {name}",
            "license_key": license_key
        }
    finally:
        conn.close()

# ==========================================
# üñ•Ô∏è FRONTEND ROUTES
# ==========================================

@app.get("/")
async def home_page(request: Request):
    # N·∫øu ng√†i c√≥ file index.html ho·∫∑c products.html th√¨ ƒë·ªÉ nguy√™n
    # N·∫øu mu·ªën m·∫∑c ƒë·ªãnh v√†o Dashboard th√¨ ƒë·ªïi th√†nh "dashboard.html"
    return templates.TemplateResponse("store.html", {"request": request}) 
    # L∆∞u √Ω: ƒê·∫£m b·∫£o file index.html n√†y t·ªìn t·∫°i trong th∆∞ m·ª•c templates

# 2. Trang Dashboard (Giao di·ªán Chat & V·∫Ω tranh - J.A.R.V.I.S COMMAND CENTER)
@app.get("/dashboard")
async def dashboard_page(request: Request):
    return templates.TemplateResponse("dashboard.html", {"request": request})

# 3. Trang Admin (Qu·∫£n tr·ªã & N·∫°p ki·∫øn th·ª©c)
@app.get("/admin")
async def admin_page(request: Request):
    # Truy·ªÅn th√™m bi·∫øn api_key sang giao di·ªán HTML
    return templates.TemplateResponse("admin.html", {
        "request": request, 
        "api_key": ADMIN_SECRET # <--- QUAN TR·ªåNG: D√≤ng n√†y gi√∫p hi·ªÉn th·ªã Key
    })
# --- ENTRY POINT (CH·∫†Y SERVER) ---

if __name__ == "__main__":
    import uvicorn
    # S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng PORT ƒë·ªÉ t∆∞∆°ng th√≠ch Cloud Run sau n√†y
    port = int(os.environ.get("PORT", 8080))
    
    print("="*50)
    print(f"üöÄ J.A.R.V.I.S SYSTEM STARTING ON PORT {port}")
    print(f"üìÑ API Documentation: http://localhost:{port}/docs")
    print("="*50)
    
    # Reload=True gi√∫p server t·ª± kh·ªüi ƒë·ªông l·∫°i khi s·ª≠a code (Dev mode)
    uvicorn.run("server:app", host="0.0.0.0", port=port, reload=True)
