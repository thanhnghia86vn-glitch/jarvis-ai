import glob
import os
import pandas as pd
import sqlite3
import uuid
import time
import io  
import shutil
import random
import logging
import aiofiles
import json  
import base64
import asyncio
import re
from typing import Optional, List, Dict, Any
from datetime import datetime
from contextlib import asynccontextmanager
from termcolor import colored
from gtts import gTTS
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# --- C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN: pip install fastapi uvicorn python-multipart jinja2 aiofiles ---
from fastapi import FastAPI, HTTPException, Header, Depends, UploadFile, File, Request, status, WebSocket, WebSocketDisconnect, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
# [QUAN TR·ªåNG]: ƒê√£ th√™m LLM_SUPERVISOR v√† log_training_data
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("JARVIS_BACKEND")
# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
ADMIN_SECRET = os.environ.get("ADMIN_SECRET", "ai_corp_secret_123")
UPLOAD_DIR = "uploads"
DB_PATH = "ai_corp_projects.db"

AI_AVAILABLE = False
MEMORY_AVAILABLE = False
VOICE_AVAILABLE = False

try:
    from main import (
        ai_app,                 # B·ªô n√£o LangGraph (Graph ƒë√£ compile)
        log_training_data,      # H√†m t·ª± h·ªçc
        learn_knowledge,        # H√†m h·ªçc ki·∫øn th·ª©c m·ªõi
        ingest_docs_to_memory,  # H√†m ƒë·ªçc PDF
        vector_db,              #Database Vector (Cho Cronjob)
        LLM_GPT4,               # Model GPT-4
        LLM_PERPLEXITY,         # Model Search
        LLM_GEMINI,             # Model Google
        LLM_SUPERVISOR,          # [M·ªöI] T·ªïng qu·∫£n ƒë·ªÉ chia vi·ªác d·ª± √°n l·ªõn
        CODER_PRIMARY
    
    ) 

    AI_AVAILABLE = True
    logger.info("‚úÖ CORE AI MODULES: LOADED")
except ImportError as e:
    logger.error(f"‚ö†Ô∏è CORE AI FAILED TO LOAD: {e}")
    ai_app = None
    vector_db = None
    LLM_GPT4 = None
    LLM_PERPLEXITY = None
    LLM_GEMINI = None
    LLM_SUPERVISOR = None
    CODER_PRIMARY = None

# --- IMPORT MODULES N·ªòI B·ªò KH√ÅC ---
try:
    from memory_core import recall_relevant_memories, extract_and_save_memory
    MEMORY_AVAILABLE = True
    logger.info("‚úÖ MEMORY CORE: LOADED")
except ImportError:
    logger.warning("‚ö†Ô∏è memory_core.py not found. Memory features disabled.")
  
 
try:
    from voice_engine import client
    VOICE_AVAILABLE = True
except ImportError:
    VOICE_AVAILABLE = False
    client = None

CURRICULUM = {
    "[FINANCE]": [
        "Ph√¢n t√≠ch xu h∆∞·ªõng gi√° v√†ng SJC v√† th·∫ø gi·ªõi h√¥m nay",
        "D·ª± b√°o t·ª∑ gi√° USD/VND tu·∫ßn n√†y",
        "Bi·∫øn ƒë·ªông th·ªã tr∆∞·ªùng Crypto (Bitcoin/ETH) 24h qua",
        "Ch·ªâ s·ªë VN-Index v√† t√°c ƒë·ªông vƒ© m√¥"
    ],
    "[CODER]": [
        "Top Python libraries for AI Agents ",
        "FastAPI advanced patterns and performance tuning",
        "LangChain vs LangGraph architecture comparison",
        "Optimizing Docker containers for Python apps"
    ],
    "[MARKETING]": [
        "Xu h∆∞·ªõng TikTok viral t·∫°i Vi·ªát Nam tu·∫ßn n√†y",
        "Chi·∫øn l∆∞·ª£c SEO m·ªõi nh·∫•t c·ªßa Google Update",
        "Content marketing trends for Tech products 2026",
        "Ph√¢n t√≠ch qu·∫£ng c√°o Facebook hi·ªáu qu·∫£ ng√†nh c√¥ng ngh·ªá"
    ],
    "[LEGAL]": [
        "Lu·∫≠t Giao d·ªãch ƒëi·ªán t·ª≠ m·ªõi nh·∫•t t·∫°i Vi·ªát Nam",
        "Quy ƒë·ªãnh v·ªÅ b·∫£o v·ªá d·ªØ li·ªáu c√° nh√¢n (Ngh·ªã ƒë·ªãnh 13)",
        "B·∫£n quy·ªÅn trong k·ª∑ nguy√™n AI (Intellectual Property & AI)"
    ],
    "[HARDWARE]": [
        "ESP32-S3 pinout and datasheet updates",
        "C√°c lo·∫°i c·∫£m bi·∫øn IoT gi√° r·∫ª m·ªõi nh·∫•t tr√™n th·ªã tr∆∞·ªùng",
        "K·ªπ thu·∫≠t thi·∫øt k·∫ø m·∫°ch PCB ch·ªëng nhi·ªÖu (Anti-interference)"
    ],
    "[ARTIST]": [
        "Phong c√°ch v·∫Ω Digital Art ƒë∆∞∆°ng ƒë·∫°i",
        "Xu h∆∞·ªõng m√†u s·∫Øc (Color Trends) nƒÉm 2026",
        "K·ªπ thu·∫≠t Prompting cho DALL-E 3 v√† Midjourney"
    ],
    "[IOT]": [
        "Giao th·ª©c MQTT v√† b·∫£o m·∫≠t thi·∫øt b·ªã IoT",
        "Nh√† th√¥ng minh (Smart Home) integration trends",
        "Zigbee vs WiFi vs LoRaWAN comparison"
    ],
    "[ORCHESTRATOR]": [
        "Tin t·ª©c c√¥ng ngh·ªá th·∫ø gi·ªõi 24h qua", "Qu·∫£n l√Ω d·ª± √°n Agile hi·ªáu qu·∫£"
    ],
    "[RESEARCH]": [
        "B√°o c√°o th·ªã tr∆∞·ªùng c√¥ng ngh·ªá Vi·ªát Nam 2026", "Xu h∆∞·ªõng ti√™u d√πng Gen Z"
    ]

}

# ==========================================
# 1. DATABASE MANAGER
# ==========================================
class DatabaseManager:
    """Qu·∫£n l√Ω k·∫øt n·ªëi Database cho Server"""
    def __init__(self, db_path=DB_PATH):
        self.db_path = db_path

    def get_connection(self):
        """T·∫°o k·∫øt n·ªëi cho l·ªánh 'with'"""
        return sqlite3.connect(self.db_path, check_same_thread=False)
    
    def init_db(self):
        """Kh·ªüi t·∫°o c·∫•u tr√∫c b·∫£ng"""
        with self.get_connection() as conn:
            # B·∫£ng s·∫£n ph·∫©m & t√†i ch√≠nh c≈©
            conn.execute("CREATE TABLE IF NOT EXISTS products (id INTEGER PRIMARY KEY, name TEXT, price REAL)")
            conn.execute("CREATE TABLE IF NOT EXISTS finance_logs (id INTEGER PRIMARY KEY, type TEXT, amount REAL)")
            
            # B·∫£ng Agent Status (QUAN TR·ªåNG CHO ADMIN)
            conn.execute('''CREATE TABLE IF NOT EXISTS agent_status 
                            (role_tag TEXT PRIMARY KEY, 
                             xp INTEGER DEFAULT 0, 
                             current_topic TEXT, 
                             last_updated DATETIME)''')
            conn.commit()
        logger.info("‚úÖ DATABASE INITIALIZED")

db_manager = DatabaseManager()

# ==========================================
# 2. WEBSOCKET MANAGER
# ==========================================
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def send_json(self, data: dict, websocket: WebSocket):
        """G·ª≠i d·ªØ li·ªáu JSON (Quan tr·ªçng cho Dashboard hi·ªÉn th·ªã ·∫£nh/agent)"""
        await websocket.send_json(data)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

# ==========================================
# 3. BACKGROUND JOBS (AI TRAINING & CRON)
# ==========================================
def calculate_level(xp: int) -> int:
    # C√¥ng th·ª©c ƒë∆°n gi·∫£n: C·ª© 100 XP l√† l√™n 1 Level. Level kh·ªüi ƒë·∫ßu l√† 1.
    return int(xp / 100) + 1

# C·∫≠p nh·∫≠t h√†m ƒë√†o t·∫°o
async def specialized_training_job(role_tag: str):
    """H√†m ƒë√†o t·∫°o chuy√™n s√¢u cho t·ª´ng Agent"""
    print(colored(f"üéì [TRAINING] B·∫Øt ƒë·∫ßu ƒë√†o t·∫°o cho {role_tag}...", "cyan"))
    
    topics = CURRICULUM.get(role_tag, [])
    if not topics: return
    
    # Ch·ªçn ng·∫´u nhi√™n 1 ch·ªß ƒë·ªÅ ƒë·ªÉ h·ªçc cho ƒë·ª° t·ªën t√†i nguy√™n
    current_topic = random.choice(topics)
    
    try:
        # 1. Gi·∫£ l·∫≠p h·ªçc (Ho·∫∑c g·ªçi Perplexity th·∫≠t n·∫øu c√≥)
        learned_content = f"N·ªôi dung chi ti·∫øt v·ªÅ {current_topic} c·∫≠p nh·∫≠t l√∫c {datetime.now()}"
        if LLM_PERPLEXITY:
            try:
                res = await LLM_PERPLEXITY.ainvoke(current_topic)
                learned_content = res.content
            except: pass

        # 2. L∆∞u v√†o Vector DB (K√Ω ·ª©c d√†i h·∫°n)
        if MEMORY_AVAILABLE and vector_db:
            await run_in_threadpool(lambda: vector_db.add_texts(
                texts=[learned_content],
                metadatas=[{"source": "Auto-Training", "agent": role_tag, "topic": current_topic}]
            ))

        # 3. C·∫≠p nh·∫≠t XP v√† Level v√†o Database (Cho Admin Panel)
        with db_manager.get_connection() as conn:
            c = conn.cursor()
            # L·∫•y XP c≈©
            row = c.execute("SELECT xp FROM agent_status WHERE role_tag = ?", (role_tag,)).fetchone()
            current_xp = row[0] if row else 0
            
            # C·ªông XP (50 ƒëi·ªÉm m·ªói l·∫ßn h·ªçc)
            new_xp = current_xp + 50
            
            # L∆∞u
            c.execute("""
                INSERT OR REPLACE INTO agent_status (role_tag, xp, current_topic, last_updated)
                VALUES (?, ?, ?, ?)
            """, (role_tag, new_xp, current_topic, datetime.now()))
            conn.commit()
            
        print(colored(f"‚úÖ [UPGRADE] {role_tag} h·ªçc xong '{current_topic}'. XP: {new_xp} (Lv.{calculate_level(new_xp)})", "green"))

    except Exception as e:
        print(colored(f"‚ùå L·ªói ƒë√†o t·∫°o {role_tag}: {e}", "red"))
# Trong server.py, ph·∫ßn khai b√°o API

async def morning_briefing_job():
    """
    PHI√äN B·∫¢N 2.0: T·ª± ƒë·ªông h·ªçc tin t·ª©c + C·ªông XP cho [ORCHESTRATOR] + T·∫°o file b√°o c√°o
    """
    role_tag = "[ORCHESTRATOR]"
    print(colored(f"\n‚è∞ [CRON JOB] {role_tag} ƒëang th·ª±c hi·ªán qu√©t tin t·ª©c bu·ªïi s√°ng...", "cyan", attrs=["bold"]))
    
    if not AI_AVAILABLE or not LLM_PERPLEXITY:
        print(colored("‚ö†Ô∏è B·ªè qua Cron Job v√¨ AI Module ch∆∞a s·∫µn s√†ng.", "yellow"))
        return

    # L·∫•y ch·ªß ƒë·ªÅ t·ª´ Gi√°o Tr√¨nh chung
    topics = CURRICULUM.get(role_tag, ["Tin t·ª©c c√¥ng ngh·ªá n·ªïi b·∫≠t", "Th·ªã tr∆∞·ªùng t√†i ch√≠nh"])
    report_buffer = []
    
    for topic in topics:
        try:
            print(colored(f"--> {role_tag} ƒëang ƒë·ªçc: {topic}...", "white"))
            res = await LLM_PERPLEXITY.ainvoke(topic)
            content = res.content
            
            if MEMORY_AVAILABLE and vector_db:
                await run_in_threadpool(lambda: vector_db.add_texts(
                    texts=[content],
                    metadatas=[{"source": "Morning_Briefing", "agent": role_tag, "topic": topic}]
                ))
            report_buffer.append(f"### {topic}\n{content[:800]}...") 
        except: pass

    # T·∫°o b√°o c√°o & C·ªông XP
    if report_buffer:
        today = datetime.now().strftime("%Y-%m-%d")
        report_path = f"projects/Morning_Briefing_{today}.md"
        try:
            async with aiofiles.open(report_path, "w", encoding="utf-8") as f:
                await f.write(f"# üåÖ B·∫¢N TIN S√ÅNG {today}\n\n" + "\n\n".join(report_buffer))
            print(colored(f"‚úÖ [DONE] ƒê√£ l∆∞u b√°o c√°o: {report_path}", "green"))
            
            # C·ªông 100 XP
            with db_manager.get_connection() as conn:
                c = conn.cursor()
                row = c.execute("SELECT xp FROM agent_status WHERE role_tag = ?", (role_tag,)).fetchone()
                new_xp = (row[0] if row else 0) + 100
                c.execute("INSERT OR REPLACE INTO agent_status (role_tag, xp, current_topic, last_updated) VALUES (?, ?, ?, ?)", 
                          (role_tag, new_xp, "T·ªïng h·ª£p tin t·ª©c s√°ng", datetime.now()))
                conn.commit()
        except Exception as e:
            print(colored(f"‚ùå L·ªói Job S√°ng: {e}", "red"))

@asynccontextmanager
async def lifespan(app: FastAPI):
    # --- STARTUP ---
    db_manager.init_db()
    
    # T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
    for d in [UPLOAD_DIR, "static", "templates", "projects"]:
        if not os.path.exists(d): os.makedirs(d)
        
    # --- SCHEDULER SETUP (QUAN TR·ªåNG) ---
    scheduler = AsyncIOScheduler()
    
    # 1. Briefing s√°ng (7:00)
    scheduler.add_job(morning_briefing_job, 'cron', hour=7, minute=0)
    
    # 2. L√™n l·ªãch ƒë√†o t·∫°o cho t·ª´ng Agent (R·∫£i r√°c trong ng√†y ƒë·ªÉ kh√¥ng ngh·∫Ωn m·∫°ng)
    # V√≠ d·ª•: M·ªói 2-4 ti·∫øng c√°c Agent s·∫Ω t·ª± ƒëi h·ªçc 1 l·∫ßn
    for idx, role in enumerate(CURRICULUM.keys()):
        # Hack nh·ªè: C·ªông th√™m ph√∫t ƒë·ªÉ c√°c job kh√¥ng ch·∫°y c√πng l√∫c
        scheduler.add_job(
            specialized_training_job, 
            'interval', 
            hours=4, 
            minutes=idx * 5, # M·ªói √¥ng c√°ch nhau 5 ph√∫t
            args=[role]
        )
        
    scheduler.start()
    logger.info(f"‚è∞ SCHEDULER ACTIVATED: ƒê√£ l√™n l·ªãch ƒë√†o t·∫°o cho {len(CURRICULUM)} Agents.")
    
    yield # Server ch·∫°y t·∫°i ƒë√¢y
    
    # --- SHUTDOWN ---
    scheduler.shutdown()
    logger.info("üí§ SYSTEM SHUTDOWN.")

app = FastAPI(
    title="J.A.R.V.I.S Neural Backend",
    version="3.0",
    lifespan=lifespan
)

# C·∫•u h√¨nh CORS & Static
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])
base_dir = os.path.abspath(os.path.dirname(__file__))
app.mount("/static", StaticFiles(directory=os.path.join(base_dir, 'static')), name="static")
templates = Jinja2Templates(directory=os.path.join(base_dir, 'templates'))
# C·∫•u h√¨nh CORS

# --- DATA MODELS (Pydantic) ---
class ChatRequest(BaseModel):
    message: str
    thread_id: str = "ceo_session"

class SpeakRequest(BaseModel):
    text: str

class LearnRequest(BaseModel):
    text: str

class BuyRequest(BaseModel):
    product_id: int

class TTSRequest(BaseModel):
    text: str

# ==========================================
# 5. API ENDPOINTS
# ==========================================
@app.get("/admin")
async def admin_page(request: Request):
    # Truy·ªÅn th√™m bi·∫øn api_key sang giao di·ªán HTML
    return templates.TemplateResponse("admin.html", {
        "request": request, 
        "api_key": ADMIN_SECRET # <--- QUAN TR·ªåNG: D√≤ng n√†y gi√∫p hi·ªÉn th·ªã Key
    })


@app.get("/")
async def home_page(request: Request):
    # N·∫øu ng√†i c√≥ file index.html ho·∫∑c products.html th√¨ ƒë·ªÉ nguy√™n
    # N·∫øu mu·ªën m·∫∑c ƒë·ªãnh v√†o Dashboard th√¨ ƒë·ªïi th√†nh "dashboard.html"
    return templates.TemplateResponse("store.html", {"request": request}) 
    # L∆∞u √Ω: ƒê·∫£m b·∫£o file index.html n√†y t·ªìn t·∫°i trong th∆∞ m·ª•c templates

# 2. Trang Dashboard (Giao di·ªán Chat & V·∫Ω tranh - J.A.R.V.I.S COMMAND CENTER)
@app.get("/dashboard")
async def dashboard_page(request: Request):
    return templates.TemplateResponse("dashboard.html", {"request": request})

@app.get("/index")
async def dashboard_page(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})


async def verify_api_key(x_api_key: Optional[str] = Header(None)):
    """Middleware ki·ªÉm tra b·∫£o m·∫≠t"""
    # Logic: N·∫øu c√≥ g·ª≠i key th√¨ check, n·∫øu kh√¥ng g·ª≠i (Dev mode) th√¨ b·ªè qua ho·∫∑c ch·∫∑n t√πy CEO
    if x_api_key and x_api_key != ADMIN_SECRET:
        raise HTTPException(status_code=403, detail="‚õî SAI M·∫¨T M√É QU√ÇN S·ª∞ (WRONG API KEY)")
    return x_api_key

@app.get("/api/agents/status")
async def get_agents_status_endpoint():
    """API tr·∫£ v·ªÅ Level & XP c·ªßa Agent cho giao di·ªán Admin"""
    try:
        with db_manager.get_connection() as conn:
            # L·∫•y d·ªØ li·ªáu v√† t√≠nh Level
            df = pd.read_sql_query("SELECT *, (xp / 100) + 1 as level FROM agent_status ORDER BY xp DESC", conn)
            # Chuy·ªÉn ƒë·ªïi timestamp th√†nh chu·ªói ƒë·ªÉ JSON kh√¥ng l·ªói
            df['last_updated'] = df['last_updated'].astype(str)
            return df.to_dict(orient="records")
    except Exception as e:
        logger.error(f"Agent Status Error: {e}")
        return []

@app.get("/api/stats")
async def get_system_stats():
    """Th·ªëng k√™ t√†i ch√≠nh"""
    try:
        with db_manager.get_connection() as conn:
            prod_count = conn.execute("SELECT count(*) FROM products").fetchone()[0]
            income = conn.execute("SELECT SUM(amount) FROM finance_logs WHERE type='income'").fetchone()[0] or 0
            expense = conn.execute("SELECT SUM(amount) FROM finance_logs WHERE type='expense'").fetchone()[0] or 0
            return {
                "products": prod_count,
                "revenue": income,
                "expense": expense,
                "balance": income - expense
            }
    except:
        return {"products": 0, "revenue": 0, "expense": 0}

@app.get("/api/products")
async def get_products_api():
    try:
        with db_manager.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            rows = conn.execute("SELECT * FROM products").fetchall()
            return [dict(r) for r in rows]
    except: return []

@app.post("/api/buy")
async def buy_product(req: BuyRequest):
    conn = sqlite3.connect(DB_PATH)
    try:
        product = conn.execute("SELECT price, name FROM products WHERE id=?", (req.product_id,)).fetchone()
        if not product:
            raise HTTPException(status_code=404, detail="Product not found")
            
        price, name = product[0], product[1]
        license_key = str(uuid.uuid4()).upper()[:19]
        
        # X·ª≠ l√Ω t√†i ch√≠nh (Dynamic Import ƒë·ªÉ tr√°nh l·ªói v√≤ng l·∫∑p)
        try:
            from finance_manager import process_order_revenue
            process_order_revenue(order_id=int(time.time()), total_amount=price)
        except ImportError:
            pass 
            
        return {
            "status": "success",
            "msg": f"ƒê√£ mua th√†nh c√¥ng: {name}",
            "license_key": license_key
        }
    finally:
        conn.close()

# --- API ƒê·ªíNG B·ªò D·ªÆ LI·ªÜU ---
@app.get("/api/sync/download_db")
async def download_database():
    if os.path.exists(DB_PATH):
        return FileResponse(path=DB_PATH, filename="ai_corp_data.db", media_type='application/octet-stream')
    return {"error": "Database not found"}


@app.post("/api/chat")
async def chat(request: ChatRequest, background_tasks: BackgroundTasks):
    """
    SMART CHAT V3: MEMORY INTEGRATED + OPTIMIZED ROUTING
    """
    if not AI_AVAILABLE:
        return {"reply": "‚ö†Ô∏è H·ªá th·ªëng AI ƒëang kh·ªüi ƒë·ªông l·∫°i. Vui l√≤ng ƒë·ª£i."}
    
    try:
        user_msg = str(request.message).strip()
        user_msg_lower = user_msg.lower()
        
        # --- 1. INTERCEPTOR (X√£ giao & B√°o c√°o - Gi·ªØ nguy√™n cho nhanh) ---
        greetings = ["ch√†o", "hi", "hello", "alo", "c√≥ ƒë√≥ kh√¥ng"]
        if any(k == user_msg_lower for k in greetings) and len(user_msg.split()) < 5:
            hour = datetime.now().hour
            time_greet = "bu·ªïi s√°ng" if 5 <= hour < 12 else "bu·ªïi chi·ªÅu" if 12 <= hour < 18 else "bu·ªïi t·ªëi"
            return {"reply": f"Ch√†o CEO! Ch√∫c ng√†i m·ªôt {time_greet} t·ªët l√†nh. T√¥i ƒëang ch·ªù l·ªánh."}

        if any(k in user_msg_lower for k in ["t·ªïng k·∫øt", "b√°o c√°o audit", "ki·ªÉm to√°n"]):
            return {"reply": get_latest_audit_report()}

        # --- 2. MEMORY RECALL (H·ªíI T∆Ø·ªûNG K√ù ·ª®C) ---
        memory_context = ""
        if MEMORY_AVAILABLE:
            print(colored(f"üß† ƒêang l·ª•c l·ªçi k√Ω ·ª©c cho: '{user_msg}'...", "magenta"))
            # Ch·∫°y trong threadpool ƒë·ªÉ kh√¥ng ch·∫∑n
            memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_msg))
        # --- 3. FAST TRACK (H·ªèi nhanh ƒë√°p g·ªçn) ---
        fast_keywords = ["gi√° v√†ng", "th·ªùi ti·∫øt", "m·∫•y gi·ªù", "ng√†y m·∫•y", "t·ª∑ gi√°", "k·∫øt qu·∫£", "b√≥ng ƒë√°", "ai l√†", "d√¢n s·ªë", "gi√° coin"]
        is_fast_query = any(k in user_msg_lower for k in fast_keywords)

        if is_fast_query:
            # ∆Øu ti√™n 1: Perplexity (N·∫øu h·ªèi tin t·ª©c/d·ªØ li·ªáu realtime)
            if LLM_PERPLEXITY:
                try:
                    fast_response = await LLM_PERPLEXITY.ainvoke(user_msg)
                    return {"reply": fast_response.content, "agent": "‚ö° Perplexity Search", "timestamp": datetime.now().isoformat()}
                except: pass 
            
            # ∆Øu ti√™n 2: Gemini (N·∫øu c·∫ßn t·ªëc ƒë·ªô suy lu·∫≠n nhanh)
            if LLM_GEMINI:
                try:
                    # Inject Memory nh·∫π v√†o Fast Track ƒë·ªÉ AI th√¥ng minh h∆°n (VD: Th·ªùi ti·∫øt -> nh·ªõ v·ªã tr√≠ Phan Thi·∫øt)
                    fast_prompt = f"Th√¥ng tin b·ªï tr·ª£ (K√Ω ·ª©c): {memory_context}\nC√¢u h·ªèi: {user_msg}"
                    direct_response = await LLM_GEMINI.ainvoke([
                        {"role": "system", "content": "B·∫°n l√† AI Search Engine. Tr·∫£ l·ªùi Ng·∫Øn g·ªçn, Ch√≠nh x√°c. Kh√¥ng ph√¢n t√≠ch d√†i d√≤ng."},
                        {"role": "user", "content": fast_prompt}
                    ])
                    return {"reply": direct_response.content, "agent": "‚ö° Gemini Speed", "timestamp": datetime.now().isoformat()}
                except: pass

        # --- 4. DEEP THINKING (G·ªçi LangGraph - B·ªô n√£o ch√≠nh) ---
        # B∆°m K√Ω ·ª©c (Memory) v√†o ng·ªØ c·∫£nh h·ªá th·ªëng
        current_context = f"[SYSTEM INFO: Time={datetime.now().strftime('%H:%M')}, Location=Phan Thiet]"
        full_prompt = (
            f"{current_context}\n"
            f"[ACTIVE MEMORY - K√ù ·ª®C LI√äN QUAN]:\n{memory_context}\n\n"
            f"[USER REQUEST]: {user_msg}"
        )
        
        from langchain_core.messages import HumanMessage
        config = {"configurable": {"thread_id": request.thread_id}}
        
        # G·ªçi LangGraph x·ª≠ l√Ω
        final_state = await ai_app.ainvoke(
            {"messages": [HumanMessage(content=full_prompt)]}, 
            config=config
        )
        
        last_message = final_state['messages'][-1]
        ai_reply = last_message.content if hasattr(last_message, 'content') else str(last_message)
        current_agent = final_state.get("current_agent", "J.A.R.V.I.S")

        # --- 5. MEMORY SAVE (BACKGROUND TASK) ---
        # L∆∞u k√Ω ·ª©c CH·ª¶ ƒê·ªòNG m√† kh√¥ng b·∫Øt CEO ph·∫£i ch·ªù
        if MEMORY_AVAILABLE:
            background_tasks.add_task(extract_and_save_memory, user_msg, ai_reply)
            
        # B. L∆∞u v√†o d·ªØ li·ªáu hu·∫•n luy·ªán (Training Data) - Ki·ªÉm tra an to√†n
        if 'log_training_data' in globals() and log_training_data:
             background_tasks.add_task(log_training_data, request.message, ai_reply, success=True)
        return {
            "reply": ai_reply,
            "agent": current_agent,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Chat Error: {e}")
        return {"reply": f"üí• L·ªói x·ª≠ l√Ω logic: {str(e)}"}

@app.post("/api/speak")
async def api_speak(request: SpeakRequest):
    """
    API T·∫°o gi·ªçng n√≥i (ƒê√£ t·ªëi ∆∞u h√≥a Non-blocking & Fail-safe).
    """
    # 1. Ki·ªÉm tra an to√†n: N·∫øu module voice ch∆∞a load ho·∫∑c client ch∆∞a c√≥ -> B·ªè qua nh·∫π nh√†ng
    if not VOICE_AVAILABLE or 'client' not in globals() or client is None:
        # Tr·∫£ v·ªÅ 204 (No Content) ƒë·ªÉ Dashboard bi·∫øt m√† im l·∫∑ng, kh√¥ng b√°o l·ªói ƒë·ªè
        return Response(status_code=204)
    
    try:
        # 2. T·ªëi ∆∞u chi ph√≠ & T·ªëc ƒë·ªô: Ch·ªâ ƒë·ªçc 500 k√Ω t·ª± ƒë·∫ßu
        # (J.A.R.V.I.S kh√¥ng n√™n ƒë·ªçc c·∫£ b√†i vƒÉn d√†i, t·ªën ti·ªÅn v√† l√¢u)
        safe_text = request.text[:1000] 

        # 3. K·ªπ thu·∫≠t Non-blocking (QUAN TR·ªåNG NH·∫§T)
        # ƒê·∫©y vi·ªác g·ªçi OpenAI sang lu·ªìng kh√°c ƒë·ªÉ Server v·∫´n nh·∫≠n chat c·ªßa ng∆∞·ªùi kh√°c ƒë∆∞·ª£c
        def _generate_audio():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx", 
                input=safe_text
            )
        
        # D√πng await ƒë·ªÉ ƒë·ª£i lu·ªìng ph·ª• x·ª≠ l√Ω xong
        response = await run_in_threadpool(_generate_audio)
        return Response(content=response.content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [VOICE ERROR]: {str(e)}")
        # N·∫øu l·ªói (h·∫øt ti·ªÅn, m·∫•t m·∫°ng...), tr·∫£ v·ªÅ 204 ƒë·ªÉ Dashboard v·∫´n ch·∫°y ti·∫øp m∆∞·ª£t m√†
        return Response(status_code=204)

@app.post("/api/tts")
async def text_to_speech_api(request: TTSRequest):
    """
    API TTS V2: L·ªçc s·∫°ch k√Ω t·ª± ƒë·∫∑c bi·ªát gi√∫p gi·ªçng ƒë·ªçc m∆∞·ª£t h∆°n (L∆∞·ªõt).
    """
    try:
        # 1. L·∫•y vƒÉn b·∫£n g·ªëc
        raw_text = request.text[:500]
        
        # --- B·ªò L·ªåC L√ÄM M·ªäN (TEXT CLEANER) ---
        def clean_text_for_speech(text):
            # 1. Lo·∫°i b·ªè Markdown (*, #, `) th∆∞·ªùng g·∫∑p trong AI response
            text = text.replace("*", "").replace("#", "").replace("`", "").replace("_", " ")
            
            # 2. Lo·∫°i b·ªè c√°c ƒë∆∞·ªùng link http://... (ƒê·ªçc link r·∫•t ch√°n)
            text = re.sub(r'http\S+', 'li√™n k·∫øt', text)
            
            # 3. Lo·∫°i b·ªè c√°c d·∫•u ngo·∫∑c vu√¥ng nh∆∞ [IMAGE], [1]...
            text = re.sub(r'\[.*?\]', '', text)
            
            # 4. Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát v√¥ nghƒ©a kh√°c, gi·ªØ l·∫°i d·∫•u c√¢u c∆° b·∫£n (. , ? !)
            # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† d·∫•u c√¢u ti·∫øng Vi·ªát
            # (Regex n√†y gi·ªØ l·∫°i ch·ªØ unicode v√† d·∫•u c√¢u c∆° b·∫£n)
            # text = re.sub(r'[^\w\s.,?!]', '', text) # C√≥ th·ªÉ d√πng n·∫øu mu·ªën l·ªçc c·ª±c m·∫°nh
            
            # 5. X√≥a kho·∫£ng tr·∫Øng th·ª´a (nhi·ªÅu d·∫•u c√°ch li·ªÅn nhau)
            text = " ".join(text.split())
            return text.strip()

        # √Åp d·ª•ng b·ªô l·ªçc
        speak_text = clean_text_for_speech(raw_text)
        
        logger.info(f"ü§ñ Google TTS (Cleaned): {speak_text[:50]}...")

        # 2. T·∫°o √¢m thanh (Ch·∫°y trong lu·ªìng ri√™ng)
        def _generate_google_audio():
            # tld='com.vn' gi√∫p gi·ªçng Google chu·∫©n Vi·ªát Nam h∆°n
            tts = gTTS(text=speak_text, lang='vi', tld='com.vn')
            
            buffer = io.BytesIO()
            tts.write_to_fp(buffer)
            buffer.seek(0)
            return buffer.read()

        # 3. Th·ª±c thi
        audio_content = await run_in_threadpool(_generate_google_audio)
        
        return Response(content=audio_content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [GOOGLE TTS ERROR]: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/api/voice_chat")
async def voice_chat(file: UploadFile = File(...), api_key: str = Depends(verify_api_key)):
    """
    T∆Ø∆†NG T√ÅC B·∫∞NG GI·ªåNG N√ìI (Voice-to-Voice) - V2 (Cleaned Audio)
    """
    if not AI_AVAILABLE or 'client' not in globals():
        return JSONResponse(status_code=503, content={"error": "AI/Voice Module ch∆∞a s·∫µn s√†ng"})

    # 1. L∆ØU FILE T·∫†M
    temp_filename = f"temp_{uuid.uuid4()}.webm"
    temp_path = os.path.join(UPLOAD_DIR, temp_filename)
    
    try:
        async with aiofiles.open(temp_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)

        # 2. D·ªäCH GI·ªåNG N√ìI SANG CH·ªÆ (WHISPER)
        def _transcribe():
            with open(temp_path, "rb") as audio_file:
                return client.audio.transcriptions.create(
                    model="whisper-1", 
                    file=audio_file,
                    language="vi"
                )
        
        transcript = await run_in_threadpool(_transcribe)
        user_text = transcript.text
        print(f"üé§ [VOICE INPUT]: {user_text}")
        
        # 3. X·ª¨ L√ù AI (SMART CHAT)
        # --- Logic Chat t·ªëi gi·∫£n cho Voice ---
        memory_context = ""
        if MEMORY_AVAILABLE:
            memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_text))
            
        fast_keywords = ["gi√° v√†ng", "th·ªùi ti·∫øt", "m·∫•y gi·ªù", "ng√†y m·∫•y", "t·ª∑ gi√°"]
        ai_text = ""
        agent_name = "J.A.R.V.I.S"

        # A. Fast Track (Gemini)
        if any(k in user_text.lower() for k in fast_keywords) and LLM_GEMINI:
             try:
                 ai_res = await LLM_GEMINI.ainvoke(f"K√Ω ·ª©c: {memory_context}. H·ªèi: {user_text}")
                 ai_text = ai_res.content
                 agent_name = "Gemini Voice"
             except: pass
        
        # B. Deep Thinking (LangGraph) - N·∫øu Fast Track th·∫•t b·∫°i ho·∫∑c kh√¥ng kh·ªõp
        if not ai_text:
             full_prompt = f"K√Ω ·ª©c: {memory_context}\nUser: {user_text}"
             from langchain_core.messages import HumanMessage
             final_state = await ai_app.ainvoke({"messages": [HumanMessage(content=full_prompt)]}, config={"configurable": {"thread_id": "voice_thread"}})
             last_message = final_state['messages'][-1]
             ai_text = last_message.content
             agent_name = final_state.get("current_agent", "J.A.R.V.I.S")
        
        # 4. T·∫†O GI·ªåNG N√ìI (TTS)
        # --- B∆Ø·ªöC QUAN TR·ªåNG: L√ÄM S·∫†CH VƒÇN B·∫¢N TR∆Ø·ªöC KHI ƒê·ªåC ---
        def clean_text_for_speech(text):
            text = text.replace("*", "").replace("#", "").replace("`", "").replace("_", " ")
            text = re.sub(r'http\S+', '', text) # B·ªè link
            text = re.sub(r'\[.*?\]', '', text) # B·ªè th·∫ª [System]
            return " ".join(text.split()).strip()

        clean_ai_text = clean_text_for_speech(ai_text)
        speak_text = clean_ai_text[:500] # C·∫Øt ng·∫Øn ƒë·ªÉ ti·∫øt ki·ªám

        def _speak():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx",
                input=speak_text
            )
        audio_res = await run_in_threadpool(_speak)

        # 5. TR·∫¢ V·ªÄ K·∫æT QU·∫¢ K√âP
        audio_b64 = base64.b64encode(audio_res.content).decode('utf-8')

        return {
            "text_reply": ai_text, # Tr·∫£ v·ªÅ text g·ªëc (c√≥ markdown) ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp
            "audio_base64": audio_b64, # Audio ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch ƒë·ªÉ ƒë·ªçc m∆∞·ª£t
            "transcript": user_text,
            "agent": agent_name
        }

    except Exception as e:
        logger.error(f"Voice Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.post("/api/plan_project")
async def plan_project_endpoint(
    request: ChatRequest, 
    api_key: str = Depends(verify_api_key) # <--- CH·ªêT CH·∫∂N B·∫¢O M·∫¨T
):
    """
    B∆∞·ªõc 1: CEO y√™u c·∫ßu l·∫≠p k·∫ø ho·∫°ch (Y√™u c·∫ßu API Key).
    """
    # Ki·ªÉm tra tr·∫°ng th√°i AI
    if not AI_AVAILABLE: 
        return JSONResponse(status_code=503, content={"status": "ERROR", "message": "AI Module Offline"})
    
    # T·∫°o ID d·ª± √°n n·∫øu ch∆∞a c√≥
    pid = request.thread_id or f"proj_{int(time.time())}"
    
    try:
        # G·ªçi h√†m architect (Ch·ªù k·∫øt qu·∫£ lu√¥n ƒë·ªÉ tr·∫£ v·ªÅ cho CEO xem ngay)
        # H√†m architect_planner ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u ·ªü b∆∞·ªõc tr∆∞·ªõc
        plan_content, plan_path = await architect_planner(request.message, pid)
        
        return {
            "status": "PLAN_CREATED",
            "project_id": pid,
            "message": "ƒê√£ l·∫≠p xong b·∫£n thi·∫øt k·∫ø. Vui l√≤ng xem x√©t.",
            "blueprint_content": plan_content, # Tr·∫£ v·ªÅ n·ªôi dung ƒë·ªÉ hi·ªán l√™n Dashboard
            "blueprint_path": plan_path,
            "next_action": "N·∫øu ƒë·ªìng √Ω, h√£y g·ªçi /api/heavy_project v·ªõi n·ªôi dung 'EXECUTE_BLUEPRINT'"
        }
    except Exception as e:
        # B·∫Øt l·ªói n·∫øu h√†m architect tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng ho·∫∑c l·ªói b·∫•t ng·ªù
        return JSONResponse(status_code=500, content={"status": "ERROR", "message": f"L·ªói h·ªá th·ªëng: {str(e)}"})

        
@app.post("/api/learn")
async def api_learn(request: LearnRequest, x_api_key: str = Header(None)):
    if x_api_key != ADMIN_SECRET: raise HTTPException(403)
    if not AI_AVAILABLE: return {"status": "error", "message": "AI Offline"}
    
    res = learn_knowledge(request.text)
    return {"status": "success", "message": res}

@app.post("/api/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """API Upload PDF & T·ª± ƒë·ªông h·ªçc (Non-blocking)"""
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Ch·ªâ ch·∫•p nh·∫≠n file .PDF")

    safe_filename = f"{uuid.uuid4().hex[:8]}_{file.filename}"
    file_path = os.path.join(UPLOAD_DIR, safe_filename)
    
    try:
        async with aiofiles.open(file_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)
            
        if AI_AVAILABLE:
            # QUAN TR·ªåNG: Ch·∫°y trong threadpool ƒë·ªÉ kh√¥ng treo server
            result = await run_in_threadpool(lambda: ingest_docs_to_memory(file_path))
            return {"status": "success", "message": result, "path": file_path}
            
        return {"status": "saved", "message": "Saved (AI Offline)"}
        
    except Exception as e:
        if os.path.exists(file_path): os.remove(file_path)
        raise HTTPException(status_code=500, detail=str(e))
# ==========================================
# 6. WEBSOCKET (REAL-TIME DASHBOARD)
# ==========================================
@app.websocket("/ws/nexus")
async def websocket_nexus(websocket: WebSocket):
    await manager.connect(websocket)
    
    # 1. T·∫†O SESSION ID RI√äNG BI·ªÜT (Fix l·ªói tr·ªôn l·∫´n k√Ω ·ª©c)
    session_id = f"ws_{uuid.uuid4().hex[:8]}"
    print(colored(f"üîå New Connection: {session_id}", "green"))
    
    try:
        # G·ª≠i l·ªùi ch√†o (D·∫°ng JSON cho Dashboard)
        await manager.send_json({
            "sender": "J.A.R.V.I.S",
            "content": "H·ªá th·ªëng tr·ª±c tuy·∫øn. ƒêang ƒë·ªìng b·ªô th·ªùi gian th·ª±c...",
            "agent": "System"
        }, websocket)
        
        while True:
            data = await websocket.receive_text()
            print(colored(f"‚ö° [INPUT]: {data}", "cyan"))
            
            # ============================================================
            # PH·∫¶N 1: KH√îI PH·ª§C C√ÅC T√çNH NƒÇNG C≈® (C·ª¶A NG√ÄI)
            # ============================================================
            
            # 1. L·∫§Y TH√îNG TIN H·ªÜ TH·ªêNG (Th·ªùi gian th·ª±c)
            current_time = datetime.now().strftime("%H:%M, Th·ª© %w, ng√†y %d/%m/%Y")
            system_context = f"Hi·ªán t·∫°i l√† {current_time}. V·ªã tr√≠: Phan Thi·∫øt, Vi·ªát Nam."
            
            # 2. H·ªíI T∆Ø·ªûNG K√ù ·ª®C
            mem_ctx = ""
            if MEMORY_AVAILABLE:
                mem_ctx = await run_in_threadpool(lambda: recall_relevant_memories(data))
                if mem_ctx: print(colored(f"üß† [K√ù ·ª®C]: {mem_ctx[:100]}...", "magenta"))

            # ============================================================
            # PH·∫¶N 2: X·ª¨ L√ù TH√îNG MINH (K·∫æT H·ª¢P LANGGRAPH)
            # ============================================================
            
            # T·∫°o Prompt ch·ª©a ƒë·∫ßy ƒë·ªß th√¥ng tin: Th·ªùi gian + K√Ω ·ª©c + C√¢u h·ªèi
            # ƒêi·ªÅu n√†y gi√∫p Agent (H·ªça sƒ©/Coder) c≈©ng bi·∫øt b√¢y gi·ªù l√† m·∫•y gi·ªù
            full_prompt = f"""
            [SYSTEM CONTEXT]: {system_context}
            [MEMORY]: {mem_ctx}
            [USER REQUEST]: {data}
            """
            
            reply_content = ""
            active_agent = "J.A.R.V.I.S"

            # A. FAST TRACK (Gi·ªØ l·∫°i logic c≈© cho c√°c c√¢u h·ªèi ƒë∆°n gi·∫£n ƒë·ªÉ ti·∫øt ki·ªám)
            # N·∫øu ch·ªâ h·ªèi ng√†y gi·ªù, gi√° c·∫£ -> D√πng Gemini/GPT tr·ª±c ti·∫øp cho nhanh
            fast_keywords = ["bao nhi√™u ng√†y", "t·∫øt", "th·ª© m·∫•y", "ng√†y m·∫•y", "m·∫•y gi·ªù", "th·ªùi ti·∫øt", "gi√°"]
            is_simple = any(k in data.lower() for k in fast_keywords) and not any(k in data.lower() for k in ["v·∫Ω", "code", "l·∫≠p tr√¨nh"])

            if is_simple and LLM_GEMINI:
                print(colored("üöÄ K√≠ch ho·∫°t Fast Track (Real-time Context)...", "yellow"))
                try:
                    # G·ªçi Gemini tr·∫£ l·ªùi nhanh c√¢u h·ªèi ng√†y gi·ªù
                    ai_msg = await LLM_GEMINI.ainvoke(full_prompt)
                    reply_content = ai_msg.content
                    active_agent = "J.A.R.V.I.S"
                except: pass
            
            # B. DEEP THINKING (N·∫øu Fast Track b·ªè qua HO·∫∂C l√† l·ªánh V·∫Ω/Code)
            if not reply_content and AI_AVAILABLE:
                # Truy·ªÅn session_id v√†o thread_id ƒë·ªÉ gi·ªØ m·∫°ch chuy·ªán ri√™ng bi·ªát
                config = {"configurable": {"thread_id": session_id}}
                # G·ªçi b·ªô n√£o LangGraph (Supervisor -> Designer/Coder...)
                print(colored("üß© Chuy·ªÉn giao cho B·ªô N√£o Trung T√¢m (LangGraph)...", "blue"))
                
                input_message = HumanMessage(content=full_prompt)
                final_state = await ai_app.ainvoke({"messages": [input_message]}, config=config)
                
                # L·∫•y k·∫øt qu·∫£ t·ª´ Agent cu·ªëi c√πng
                last_message = final_state['messages'][-1]
                reply_content = last_message.content
                
                # X√°c ƒë·ªãnh ai v·ª´a l√†m vi·ªác (ƒê·ªÉ Dashboard s√°ng ƒë√®n)
                active_agent = final_state.get("current_agent", "J.A.R.V.I.S")

            # ============================================================
            # PH·∫¶N 3: PH·∫¢N H·ªíI (D·∫†NG JSON CHO DASHBOARD)
            # ============================================================
            print(colored(f"ü§ñ [{active_agent}]: {reply_content}", "magenta"))
            
            # G·ª≠i JSON xu·ªëng Client
            await manager.send_json({
                "sender": active_agent,
                "content": reply_content,
                "agent": active_agent # Dashboard d√πng c√°i n√†y ƒë·ªÉ highlight icon
            }, websocket)
            
                        # 4. GHI NH·ªö L·∫†I
            if MEMORY_AVAILABLE:
                await run_in_threadpool(lambda: extract_and_save_memory(data, reply_content))

    except WebSocketDisconnect:
        manager.disconnect(websocket)
        print(colored(f"üîå Disconnected: {session_id}", "red"))
    except Exception as e:
        logger.error(f"WS Error: {e}")
        manager.disconnect(websocket)

# ==========================================
# 7. CH·∫†Y D·ª∞ √ÅN L·ªöN (BACKGROUND)
# ==========================================
async def heavy_project_executor(project_request: str, thread_id: str):
    """
    H√†m x·ª≠ l√Ω d·ª± √°n l·ªõn (ERP, CRM) ch·∫°y n·ªÅn h√†ng gi·ªù ƒë·ªìng h·ªì.
    """
    import asyncio
    print(colored(f"üèóÔ∏è [HEAVY PROJECT] B·∫Øt ƒë·∫ßu: {project_request}", "magenta", attrs=["bold"]))
    
    log_file = f"projects/{thread_id}_log.txt"
    blueprint_path = f"projects/{thread_id}_BLUEPRINT.md"

    try:
        if not LLM_SUPERVISOR:
             raise Exception("LLM_SUPERVISOR ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o. Ki·ªÉm tra l·∫°i main.py")
        # Giai ƒëo·∫°n 1: L·∫≠p k·∫ø ho·∫°ch (D√πng Supervisor)
        plan_prompt = (
            f"B·∫°n l√† Ki·∫øn tr√∫c s∆∞ ph·∫ßn m·ªÅm (Architect). Y√™u c·∫ßu d·ª± √°n: '{project_request}'.\n"
            "H√£y chia nh·ªè d·ª± √°n n√†y th√†nh c√°c b∆∞·ªõc k·ªπ thu·∫≠t (Coding Steps) c·ª• th·ªÉ.\n"
            "QUAN TR·ªåNG: Ch·ªâ tr·∫£ v·ªÅ danh s√°ch c√°c b∆∞·ªõc, b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u g·∫°ch ngang (-).\n"
            "V√≠ d·ª•:\n- T·∫°o file models.py\n- Vi·∫øt API login"
        )
        plan_res = await run_in_threadpool(lambda: LLM_SUPERVISOR.invoke(plan_prompt))
        raw_steps = plan_res.content.split('\n')
        steps = []
        for s in raw_steps:
            s = s.strip()
            # L·ªçc c√°c d√≤ng l√† bullet point ho·∫∑c s·ªë th·ª© t·ª±
            if s and (s.startswith('-') or s.startswith('*') or (s[0].isdigit() and s[1] in ['.', ')'])):
                steps.append(s)
        
        # Ghi log k·∫ø ho·∫°ch (D√πng aiofiles ƒë·ªÉ kh√¥ng ch·∫∑n Server)
        async with aiofiles.open(log_file, "w", encoding="utf-8") as f:
            await f.write(f"=== PROJECT PLAN: {project_request} ===\n{plan_res.content}\n{'='*50}\n")
            
        if not steps:
            print(colored("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y b∆∞·ªõc n√†o trong k·∫ø ho·∫°ch. D·ª´ng.", "red"))
            return
        # Giai ƒëo·∫°n 2: Code t·ª´ng ph·∫ßn (Loop)
        for idx, step in enumerate(steps):
            print(colored(f"‚è≥ Doing Step {idx+1}/{len(steps)}: {step}", "yellow"))
            
            # Prompt nh·∫Øc l·∫°i ng·ªØ c·∫£nh (Context Injection)
            # Gi√∫p AI nh·ªõ n√≥ ƒëang l√†m d·ª± √°n g√¨, tr√°nh l·∫°c ƒë·ªÅ
            step_input = (
                f"[D·ª∞ √ÅN T·ªîNG TH·ªÇ]: {project_request}\n"
                f"[NHI·ªÜM V·ª§ HI·ªÜN T·∫†I]: B∆∞·ªõc {idx+1}: {step}.\n"
                "H√£y vi·∫øt code ho√†n ch·ªânh v√† chi ti·∫øt cho nhi·ªám v·ª• n√†y."
            )
            
            # G·ªçi AI Brain (LangGraph ƒë√£ l√† async n√™n d√πng await tr·ª±c ti·∫øp)
            state_res = await ai_app.ainvoke(
                {"messages": [HumanMessage(content=step_input)]},
                config={"configurable": {"thread_id": thread_id}}
            )
            
            ai_output = state_res['messages'][-1].content
            
            # Ghi log k·∫øt qu·∫£ (Async Write)
            async with aiofiles.open(log_file, "a", encoding="utf-8") as f:
                await f.write(f"\n\n--- K·∫æT QU·∫¢ B∆Ø·ªöC {idx+1}: {step} ---\n{ai_output}\n")
            
            # Ngh·ªâ 2 gi√¢y ƒë·ªÉ tr√°nh spam API
            await asyncio.sleep(2)

        print(colored(f"‚úÖ [DONE] D·ª± √°n {thread_id} ƒë√£ ho√†n t·∫•t!", "green"))

    except Exception as e:
        print(colored(f"‚ùå [FAILED] D·ª± √°n b·ªã l·ªói: {e}", "red"))
        # Ghi l·ªói v√†o file log (Async Write)
        try:
            async with aiofiles.open(log_file, "a", encoding="utf-8") as f:
                await f.write(f"\n‚ùå SYSTEM ERROR: {str(e)}")
        except: pass

async def architect_planner(project_request: str, thread_id: str):
    """
    K·∫æN TR√öC S∆Ø TR∆Ø·ªûNG: L·∫≠p b·∫£n v·∫Ω k·ªπ thu·∫≠t & L·ªô tr√¨nh thi c√¥ng.
    (Phi√™n b·∫£n Async + T·ªëi ∆∞u Prompt cho Executor)
    """
    print(colored(f"üìê [ARCHITECT] ƒêang ph√°c th·∫£o d·ª± √°n: {project_request}", "cyan"))
    
    # T·∫°o ƒë∆∞·ªùng d·∫´n file tr∆∞·ªõc
    plan_path = f"projects/{thread_id}_BLUEPRINT.md"

    try:
        if not LLM_SUPERVISOR:
             raise Exception("LLM_SUPERVISOR ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o (AI Offline).")

        # --- N√ÇNG C·∫§P PROMPT ---
        # Th√™m m·ª•c s·ªë 6 ƒë·ªÉ t·∫°o thu·∫≠n l·ª£i cho 'heavy_project_executor' ƒë·ªçc task
        architect_prompt = (
            f"B·∫°n l√† Chief Software Architect (CSA). C√≥ m·ªôt y√™u c·∫ßu d·ª± √°n: '{project_request}'.\n"
            "H√£y l·∫≠p m·ªôt B·∫¢N THI·∫æT K·∫æ K·ª∏ THU·∫¨T (Technical Blueprint) chi ti·∫øt d·∫°ng Markdown:\n\n"
            "1. [OVERVIEW]: T√≥m t·∫Øt m·ª•c ti√™u d·ª± √°n.\n"
            "2. [MODULES]: Danh s√°ch c√°c ch·ª©c nƒÉng ch√≠nh.\n"
            "3. [DATABASE]: S∆° ƒë·ªì b·∫£ng (Table Schema) chi ti·∫øt.\n"
            "4. [TECH STACK]: C√¥ng ngh·ªá s·ª≠ d·ª•ng (Frontend/Backend/Libs).\n"
            "5. [FILE STRUCTURE]: C·∫•u tr√∫c th∆∞ m·ª•c d·ª± ki·∫øn.\n"
            "6. [EXECUTION PLAN] (QUAN TR·ªåNG): H√£y li·ªát k√™ l·ªô tr√¨nh code c·ª• th·ªÉ t·ª´ng b∆∞·ªõc.\n"
            "   - B·∫Øt bu·ªôc d√πng g·∫°ch ƒë·∫ßu d√≤ng (-) cho m·ªói b∆∞·ªõc.\n"
            "   - V√≠ d·ª•:\n"
            "   - T·∫°o m√¥i tr∆∞·ªùng ·∫£o v√† file requirements.txt\n"
            "   - Thi·∫øt k·∫ø database models trong models.py\n"
            "   - Vi·∫øt API ƒëƒÉng nh·∫≠p\n"
        )
        
        # G·ªçi AI (Ch·∫°y trong Threadpool ƒë·ªÉ kh√¥ng ch·∫∑n Server)
        plan_res = await run_in_threadpool(lambda: LLM_SUPERVISOR.invoke(architect_prompt))
        
        # Ghi file b·∫•t ƒë·ªìng b·ªô (Non-blocking I/O)
        async with aiofiles.open(plan_path, "w", encoding="utf-8") as f:
            await f.write(plan_res.content)
            
        print(colored(f"‚úÖ [PLAN READY] B·∫£n v·∫Ω ƒë√£ xong: {plan_path}", "green"))
        
        # Tr·∫£ v·ªÅ n·ªôi dung ƒë·ªÉ hi·ªÉn th·ªã ngay l√™n Dashboard
        return plan_res.content, plan_path

    except Exception as e:
        error_msg = f"L·ªói l·∫≠p k·∫ø ho·∫°ch: {str(e)}"
        print(colored(f"‚ùå {error_msg}", "red"))
        
        # Ghi file l·ªói ƒë·ªÉ debug
        try:
            async with aiofiles.open(plan_path, "w", encoding="utf-8") as f:
                await f.write(f"# ‚ö†Ô∏è PROJECT ERROR\n{error_msg}")
        except: pass
        
        return error_msg, plan_path
    
# 2. API Endpoint ƒë·ªÉ k√≠ch ho·∫°t
@app.post("/api/heavy_project")
async def start_heavy_project(
    request: ChatRequest, 
    background_tasks: BackgroundTasks,
    api_key: str = Depends(verify_api_key) # <--- TH√äM D√íNG N√ÄY ƒê·ªÇ B·∫¢O V·ªÜ
):
    """
    API ƒë·ªÉ CEO k√≠ch ho·∫°t ch·∫ø ƒë·ªô l√†m d·ª± √°n l·ªõn (Y√™u c·∫ßu API Key).
    """
    # T·∫°o Thread ID ri√™ng cho d·ª± √°n n·∫øu ch∆∞a c√≥
    pid = request.thread_id or f"proj_{int(time.time())}"
    
    # ƒê·∫©y v√†o ch·∫°y n·ªÅn (Fire and Forget)
    # L∆∞u √Ω: heavy_project_executor ph·∫£i l√† h√†m async (ƒë√£ s·ª≠a ·ªü b∆∞·ªõc tr∆∞·ªõc)
    background_tasks.add_task(heavy_project_executor, request.message, pid)
    
    return {
        "status": "PROCESSING",
        "project_id": pid,
        "message": "ƒê√£ ti·∫øp nh·∫≠n d·ª± √°n. H·ªá th·ªëng ƒëang x·ª≠ l√Ω ng·∫ßm...",
        "log_path": f"projects/{pid}_log.txt"
    }

# ==========================================
# üöÄ SYSTEM ROUTES
# ==========================================

@app.get("/health")
async def health_check():
    """
    Ki·ªÉm tra t√¨nh tr·∫°ng s·ª©c kh·ªèe to√†n di·ªán (Deep Health Check).
    """
    # 1. Ki·ªÉm tra k·∫øt n·ªëi Database (Th·ª±c t·∫ø)
    db_status = "UNKNOWN"
    try:
        # Th·ª≠ th·ª±c hi·ªán m·ªôt truy v·∫•n si√™u nh·∫π (SELECT 1)
        with db_manager.get_connection() as conn:
            conn.execute("SELECT 1")
            db_status = "CONNECTED (Active)"
    except Exception as e:
        db_status = f"CRITICAL ERROR: {str(e)}"
    
    # 2. Ki·ªÉm tra c√°c Module AI
    return {
        "status": "OPERATIONAL" if "ERROR" not in db_status else "DEGRADED",
        "timestamp": datetime.now().isoformat(),
        "version": "J.A.R.V.I.S v3.0",
        "modules": {
            "ai_brain": "ONLINE" if AI_AVAILABLE else "OFFLINE",
            "voice_core": "ONLINE" if VOICE_AVAILABLE else "OFFLINE",
            "memory_core": "ONLINE" if MEMORY_AVAILABLE else "OFFLINE",
            "knowledge_db": db_status, # Tr·∫°ng th√°i k·∫øt n·ªëi th·∫≠t
        }
    }

def get_latest_audit_report():
    """
    H√†m ƒë·ªçc b√°o c√°o m·ªõi nh·∫•t trong th∆∞ m·ª•c projects
    """
    try:
        # 1. Tr·ªè ƒë√∫ng v√†o th∆∞ m·ª•c 'projects'
        # T√¨m t·∫•t c·∫£ file .md (Bao g·ªìm c·∫£ Project_Audit v√† Morning_Briefing)
        search_path = os.path.join("projects", "*.md") 
        list_of_files = glob.glob(search_path)
        
        if not list_of_files:
            return "Th∆∞a CEO, kho d·ªØ li·ªáu (folder projects) hi·ªán ƒëang tr·ªëng. Ch∆∞a c√≥ b√°o c√°o n√†o ƒë∆∞·ª£c t·∫°o."
            
        # 2. T√¨m file m·ªõi nh·∫•t d·ª±a tr√™n th·ªùi gian t·∫°o (Create Time)
        latest_file = max(list_of_files, key=os.path.getctime)
        
        # L·∫•y t√™n file cho ƒë·∫πp
        filename = os.path.basename(latest_file)
        
        # 3. ƒê·ªçc n·ªôi dung
        with open(latest_file, "r", encoding="utf-8") as f:
            content = f.read()
            
        return f"### üìÇ H·ªí S∆† M·ªöI NH·∫§T: {filename}\n\n{content}"

    except Exception as e:
        logger.error(f"üö® [REPORT ERROR]: {str(e)}")
        return f"‚ö†Ô∏è Th∆∞a CEO, kh√¥ng th·ªÉ truy xu·∫•t h·ªì s∆°: {str(e)}."


# ==========================================
# ‚ö° WEBSOCKET REAL-TIME (THE NEXUS)
# ==========================================


# ==========================================
# üñ•Ô∏è FRONTEND ROUTES
# ==========================================

# --- ENTRY POINT (CH·∫†Y SERVER) ---

if __name__ == "__main__":
    import uvicorn
    # S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng PORT ƒë·ªÉ t∆∞∆°ng th√≠ch Cloud Run sau n√†y
    port = int(os.environ.get("PORT", 8080))
    
    print("="*50)
    print(f"üöÄ J.A.R.V.I.S SYSTEM STARTING ON PORT {port}")
    print(f"üìÑ API Documentation: http://localhost:{port}/docs")
    print("="*50)
    
    # Reload=True gi√∫p server t·ª± kh·ªüi ƒë·ªông l·∫°i khi s·ª≠a code (Dev mode)
    uvicorn.run("server:app", host="0.0.0.0", port=port, reload=True)

