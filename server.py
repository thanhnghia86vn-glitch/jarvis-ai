import glob
import os
import pandas as pd
import sqlite3
import uuid
import time
import io  
import shutil
import random
import logging
import aiofiles
import json  
import base64
import asyncio
import re
from sqlalchemy import create_engine, text
from typing import Optional, List, Dict, Any
from datetime import datetime
from contextlib import asynccontextmanager
from termcolor import colored
from gtts import gTTS
from apscheduler.schedulers.asyncio import AsyncIOScheduler
# --- C√ÄI ƒê·∫∂T TH∆Ø VI·ªÜN: pip install fastapi uvicorn python-multipart jinja2 aiofiles ---
from fastapi import FastAPI, HTTPException, Header, Depends, UploadFile, File, Request, status, WebSocket, WebSocketDisconnect, BackgroundTasks, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, Response, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.concurrency import run_in_threadpool
from pydantic import BaseModel
from langchain_core.messages import HumanMessage
# [QUAN TR·ªåNG]: ƒê√£ th√™m LLM_SUPERVISOR v√† log_training_data
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger("JARVIS_BACKEND")
# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
ADMIN_SECRET = os.environ.get("ADMIN_SECRET", "ai_corp_secret_123")

# 1. X√°c ƒë·ªãnh ƒë∆∞·ªùng d·∫´n g·ªëc (Root Path)
# Ki·ªÉm tra xem th∆∞ m·ª•c /var/data (Mount path tr√™n Render) c√≥ t·ªìn t·∫°i kh√¥ng
RENDER_DISK_PATH = "/var/data"

if os.path.exists(RENDER_DISK_PATH):
    # N·∫øu t√¨m th·∫•y ·ªï c·ª©ng Cloud -> L∆∞u h·∫øt v√†o ƒë√≥
    BASE_DATA_DIR = RENDER_DISK_PATH
    print(colored(f"üíΩ [STORAGE] ƒê√£ k·∫øt n·ªëi ·ªï c·ª©ng Cloud: {BASE_DATA_DIR}", "green", attrs=["bold"]))
else:
    # N·∫øu kh√¥ng th·∫•y -> ƒêang ch·∫°y Local -> L∆∞u t·∫°i ch·ªó
    BASE_DATA_DIR = "."
    print(colored("üíª [STORAGE] ƒêang ch·∫°y ch·∫ø ƒë·ªô Local (L∆∞u tr√™n m√°y t√≠nh)", "yellow"))

# 2. ƒê·ªãnh nghƒ©a c√°c ƒë∆∞·ªùng d·∫´n quan tr·ªçng d·ª±a tr√™n Root Path
# T·∫•t c·∫£ d·ªØ li·ªáu quan tr·ªçng ph·∫£i n·∫±m trong BASE_DATA_DIR
UPLOAD_DIR = os.path.join(BASE_DATA_DIR, "uploads")
PROJECTS_DIR = os.path.join(BASE_DATA_DIR, "projects")
DB_PATH = os.path.join(BASE_DATA_DIR, "ai_corp_projects.db")
VECTOR_DB_PATH = os.path.join(BASE_DATA_DIR, "db_knowledge") # Folder ch·ª©a vector database

# 3. Bi·∫øn m√¥i tr∆∞·ªùng Database (C·∫≠p nh·∫≠t l·∫°i cho SQLite n·∫øu d√πng Disk)
# N·∫øu kh√¥ng d√πng PostgreSQL m√† d√πng SQLite tr√™n Disk th√¨ set l·∫°i url
if not os.environ.get("DATABASE_URL") and os.path.exists(RENDER_DISK_PATH):
    # √âp d√πng SQLite tr√™n ·ªï c·ª©ng Cloud ƒë·ªÉ b·ªÅn v·ªØng
    os.environ["DATABASE_URL"] = f"sqlite:///{DB_PATH}"

AI_AVAILABLE = False
MEMORY_AVAILABLE = False
VOICE_AVAILABLE = False
SERVER_READY = False

try:
    from main import (
        ai_app,                 # B·ªô n√£o LangGraph (Graph ƒë√£ compile)
        log_training_data,      # H√†m t·ª± h·ªçc
        learn_knowledge,        # H√†m h·ªçc ki·∫øn th·ª©c m·ªõi
        ingest_docs_to_memory,  # H√†m ƒë·ªçc PDF
        vector_db,              #Database Vector (Cho Cronjob)
        LLM_GPT4,               # Model GPT-4
        LLM_PERPLEXITY,         # Model Search
        LLM_GEMINI,             # Model Google
        LLM_SUPERVISOR,          # [M·ªöI] T·ªïng qu·∫£n ƒë·ªÉ chia vi·ªác d·ª± √°n l·ªõn
        CODER_PRIMARY
    
    ) 

    AI_AVAILABLE = True
    SERVER_READY = True
    logger.info("‚úÖ CORE AI MODULES: LOADED")
except Exception as e:
    # --- B·∫ÆT L·ªñI V√Ä GHI L·∫†I ---
    import traceback
    AI_BOOT_ERROR = traceback.format_exc() # L∆∞u to√†n b·ªô d·∫•u v·∫øt l·ªói
    logger.error(f"‚ö†Ô∏è CORE AI FAILED TO LOAD: {AI_BOOT_ERROR}")
    
    # Set bi·∫øn v·ªÅ None ƒë·ªÉ kh√¥ng crash server
    AI_AVAILABLE = False
    ai_app = None
    vector_db = None
    LLM_GPT4 = None
    LLM_PERPLEXITY = None
    LLM_GEMINI = None
    LLM_SUPERVISOR = None
    CODER_PRIMARY = None

# --- IMPORT MODULES N·ªòI B·ªò KH√ÅC ---
try:
    from memory_core import recall_relevant_memories, extract_and_save_memory
    MEMORY_AVAILABLE = True
    logger.info("‚úÖ MEMORY CORE: LOADED")
except ImportError:
    logger.warning("‚ö†Ô∏è memory_core.py not found. Memory features disabled.")
  
 
try:
    from voice_engine import client
    VOICE_AVAILABLE = True
except ImportError:
    VOICE_AVAILABLE = False
    client = None

CURRICULUM = {
    # === NH√ìM 1: QU·∫¢N TR·ªä & CHI·∫æN L∆Ø·ª¢C (C-SUITE) ===
    "[ORCHESTRATOR]": [
        "M√¥ h√¨nh OKRs vs KPIs trong qu·∫£n tr·ªã doanh nghi·ªáp AI",
        "Chi·∫øn l∆∞·ª£c qu·∫£n tr·ªã kh·ªßng ho·∫£ng (Crisis Management) th·ªùi gian th·ª±c",
        "T·ªëi ∆∞u h√≥a quy tr√¨nh ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n d·ªØ li·ªáu (Data-Driven Decision Making)",
        "Tin t·ª©c c√¥ng ngh·ªá Deep Tech to√†n c·∫ßu 24h qua"
    ],
    "[FINANCE]": [
        "C√°c chi·∫øn l∆∞·ª£c Hedging r·ªßi ro t·ª∑ gi√° h·ªëi ƒëo√°i",
        "·ª®ng d·ª•ng Blockchain trong qu·∫£n l√Ω d√≤ng ti·ªÅn doanh nghi·ªáp (Corporate Treasury)",
        "Ph√¢n t√≠ch k·ªπ thu·∫≠t n√¢ng cao: S√≥ng Elliott v√† Fibonacci trong th·ªã tr∆∞·ªùng v√†ng/Crypto",
        "T·ªëi ∆∞u h√≥a thu·∫ø cho doanh nghi·ªáp s·ªë (Digital Tax Optimization)"
    ],
    "[HR_MANAGER]": [
        "X√¢y d·ª±ng khung nƒÉng l·ª±c c·ªët l√µi cho nh√¢n s·ª± AI & Blockchain",
        "T√¢m l√Ω h·ªçc h√†nh vi trong gi·ªØ ch√¢n nh√¢n t√†i Gen Z & Alpha",
        "T·ª± ƒë·ªông h√≥a quy tr√¨nh Payroll v√† C&B b·∫±ng Smart Contracts",
        "Lu·∫≠t lao ƒë·ªông qu·ªëc t·∫ø v·ªÅ l√†m vi·ªác t·ª´ xa (Remote Work Compliance)"
    ],

    # === NH√ìM 2: K·ª∏ THU·∫¨T PH·∫¶N M·ªÄM (CORE TECH) ===
    "[CODER]": [
        "L·∫≠p tr√¨nh hi·ªáu nƒÉng cao v·ªõi Rust v√† Go cho Backend",
        "T·ªëi ∆∞u h√≥a truy v·∫•n Database (Indexing, Partitioning, Sharding)",
        "Event-Driven Architecture v·ªõi Apache Kafka v√† RabbitMQ",
        "WebAssembly (Wasm): T∆∞∆°ng lai c·ªßa ·ª©ng d·ª•ng Web hi·ªáu nƒÉng cao"
    ],
    "[ARCHITECT]": [
        "Domain-Driven Design (DDD) trong thi·∫øt k·∫ø Microservices",
        "Tri·ªÉn khai Serverless tr√™n quy m√¥ l·ªõn (AWS Lambda/Google Cloud Run)",
        "M√¥ h√¨nh CQRS v√† Event Sourcing trong h·ªá th·ªëng ph√¢n t√°n",
        "Zero Trust Architecture: Ki·∫øn tr√∫c b·∫£o m·∫≠t kh√¥ng tin c·∫≠y ai"
    ],
    "[SECURITY]": [
        "K·ªπ thu·∫≠t Reverse Engineering m√£ ƒë·ªôc n√¢ng cao",
        "B·∫£o m·∫≠t API theo chu·∫©n OWASP Top 10 nƒÉm 2026",
        "Post-Quantum Cryptography: M√£ h√≥a ch·ªëng m√°y t√≠nh l∆∞·ª£ng t·ª≠",
        "DevSecOps: T√≠ch h·ª£p b·∫£o m·∫≠t v√†o quy tr√¨nh CI/CD"
    ],
    "[DATA_ANALYST]": [
        "X√¢y d·ª±ng RAG (Retrieval-Augmented Generation) cho LLM doanh nghi·ªáp",
        "Data Lakehouse: K·∫øt h·ª£p s·ª©c m·∫°nh c·ªßa Data Lake v√† Data Warehouse",
        "Ph√¢n t√≠ch d·ªØ li·ªáu th·ªùi gian th·ª±c (Real-time Analytics) v·ªõi Apache Flink",
        "M√¥ h√¨nh d·ª± b√°o chu·ªói th·ªùi gian (Time-series Forecasting) b·∫±ng Deep Learning"
    ],

    # === NH√ìM 3: PH·∫¶N C·ª®NG & IOT (HARDWARE) ===
    "[HARDWARE]": [
        "Thi·∫øt k·∫ø m·∫°ch PCB cao t·∫ßn (High-speed PCB Design)",
        "Edge AI: Ch·∫°y m√¥ h√¨nh AI tr·ª±c ti·∫øp tr√™n vi ƒëi·ªÅu khi·ªÉn (TinyML)",
        "C√¥ng ngh·ªá Pin th·∫ø h·ªá m·ªõi v√† qu·∫£n l√Ω nƒÉng l∆∞·ª£ng (Power Management)",
        "L·∫≠p tr√¨nh FPGA cho x·ª≠ l√Ω t√≠n hi·ªáu s·ªë"
    ],
    "[IOT]": [
        "M·∫°ng l∆∞·ªõi v·∫°n v·∫≠t (Mesh Networking) v·ªõi LoRaWAN v√† Zigbee",
        "Digital Twins: B·∫£n sao s·ªë trong c√¥ng nghi·ªáp s·∫£n xu·∫•t",
        "Giao th·ª©c MQTT v5 v√† t·ªëi ∆∞u h√≥a bƒÉng th√¥ng cho thi·∫øt b·ªã IoT",
        "B·∫£o m·∫≠t thi·∫øt b·ªã IoT ·ªü c·∫•p ƒë·ªô ph·∫ßn c·ª©ng (Hardware Security Modules)"
    ],

    # === NH√ìM 4: S√ÅNG T·∫†O & MARKETING (GROWTH) ===
    "[MARKETING]": [
        "Neuromarketing: ·ª®ng d·ª•ng khoa h·ªçc n√£o b·ªô v√†o qu·∫£ng c√°o",
        "Programmatic Advertising: Qu·∫£ng c√°o l·∫≠p tr√¨nh h√≥a t·ª± ƒë·ªông",
        "Chi·∫øn l∆∞·ª£c Growth Hacking d·ª±a tr√™n Ph·ªÖu AARRR",
        "T·ªëi ∆∞u h√≥a t√¨m ki·∫øm b·∫±ng gi·ªçng n√≥i (Voice Search SEO)"
    ],
    "[ARTIST]": [
        "Quy tr√¨nh s·∫£n xu·∫•t Video Generative AI (Runway Gen-3, Sora)",
        "Thi·∫øt k·∫ø tr·∫£i nghi·ªám ng∆∞·ªùi d√πng kh√¥ng gian (Spatial UX cho VR/AR)",
        "L√Ω thuy·∫øt m√†u s·∫Øc n√¢ng cao v√† t√¢m l√Ω h·ªçc h√¨nh ·∫£nh",
        "K·ªπ thu·∫≠t Prompt Engineering chuy√™n s√¢u cho Midjourney v6"
    ],
    "[CONTENT_WRITER]": [
        "K·ªπ thu·∫≠t Storytelling: C·∫•u tr√∫c h√†nh tr√¨nh anh h√πng trong B2B",
        "SEO Semantic Search v√† Topic Clusters (C·ª•m ch·ªß ƒë·ªÅ)",
        "Copywriting th√¥i mi√™n: C√°c m·∫´u c√¢u ch·ªët sale t√¢m l√Ω h·ªçc",
        "Chi·∫øn l∆∞·ª£c n·ªôi dung ƒëa k√™nh (Omnichannel Content Strategy)"
    ],

    # === NH√ìM 5: NGHI·ªÜP V·ª§ B·ªî TR·ª¢ (SUPPORT) ===
    "[LEGAL]": [
        "Khung ph√°p l√Ω v·ªÅ AI v√† b·∫£n quy·ªÅn t√°c gi·∫£ to√†n c·∫ßu",
        "H·ª£p ƒë·ªìng th√¥ng minh (Smart Contract) v√† t√≠nh ph√°p l√Ω",
        "Tu√¢n th·ªß GDPR v√† Ngh·ªã ƒë·ªãnh 13 b·∫£o v·ªá d·ªØ li·ªáu t·∫°i Vi·ªát Nam",
        "Gi·∫£i quy·∫øt tranh ch·∫•p th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠ xuy√™n bi√™n gi·ªõi"
    ],
    "[RESEARCH]": [
        "Xu h∆∞·ªõng c√¥ng ngh·ªá sinh h·ªçc (Biotech) k·∫øt h·ª£p AI",
        "V·∫≠t li·ªáu m·ªõi (Graphene, Carbon Nanotubes) trong c√¥ng nghi·ªáp",
        "T√°c ƒë·ªông c·ªßa 6G l√™n n·ªÅn kinh t·∫ø s·ªë t∆∞∆°ng lai",
        "Nghi√™n c·ª©u h√†nh vi ti√™u d√πng b·ªÅn v·ªØng (Sustainability)"
    ],
    "[SALES]": [
        "M√¥ h√¨nh b√°n h√†ng Challenger Sale (Ng∆∞·ªùi th√°ch th·ª©c)",
        "Account-Based Marketing (ABM) cho kh√°ch h√†ng doanh nghi·ªáp l·ªõn",
        "K·ªπ thu·∫≠t ƒë√†m ph√°n c·∫•p cao (High-stakes Negotiation)",
        "·ª®ng d·ª•ng CRM AI ƒë·ªÉ d·ª± ƒëo√°n t·ª∑ l·ªá ch·ªët ƒë∆°n (Win Rate Prediction)"
    ]
}
# ==========================================
# 1. DATABASE MANAGER
# ==========================================
class DatabaseManager:
    def __init__(self):
        # 1. L·∫•y link DB (∆Øu ti√™n t·ª´ bi·∫øn m√¥i tr∆∞·ªùng, n·∫øu kh√¥ng c√≥ th√¨ d√πng file Local)
        # L∆∞u √Ω: DB_PATH ph·∫£i ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a ·ªü tr√™n ƒë·∫ßu file server.py (vd: DB_PATH = "jarvis_memory.db")
        self.db_url = os.environ.get("DATABASE_URL")
        
        if self.db_url:
            # Fix l·ªói t∆∞∆°ng th√≠ch: Render d√πng 'postgres://' nh∆∞ng SQLAlchemy c·∫ßn 'postgresql://'
            if self.db_url.startswith("postgres://"):
                self.db_url = self.db_url.replace("postgres://", "postgresql://", 1)
            
            # T·∫°o ƒë·ªông c∆° k·∫øt n·ªëi Cloud
            self.engine = create_engine(self.db_url)
            print(colored("üîå K·∫æT N·ªêI DATABASE: CLOUD (POSTGRESQL)", "green"))
        else:
            # T·∫°o ƒë·ªông c∆° k·∫øt n·ªëi Local (SQLite) qua SQLAlchemy
            # L∆∞u √Ω: D√πng 3 d·∫•u g·∫°ch ch√©o /// cho ƒë∆∞·ªùng d·∫´n t∆∞∆°ng ƒë·ªëi
            self.engine = create_engine(f"sqlite:///{DB_PATH}")
            print(colored("üîå K·∫æT N·ªêI DATABASE: LOCAL (SQLITE)", "cyan"))

    def get_connection(self):
        """
        [FIX L·ªñI QUAN TR·ªåNG]
        H√†m n√†y b√¢y gi·ªù tr·∫£ v·ªÅ k·∫øt n·ªëi c·ªßa SQLAlchemy ch·ª© KH√îNG d√πng sqlite3 tr·ª±c ti·∫øp n·ªØa.
        """
        return self.engine.connect()
    
    def init_db(self):
        """Kh·ªüi t·∫°o c·∫•u tr√∫c b·∫£ng & D·ªØ li·ªáu m·∫´u (Chu·∫©n SQLAlchemy)"""
        try:
            with self.get_connection() as conn:
                # 1. T·∫†O C√ÅC B·∫¢NG (D√πng c√∫ ph√°p text() ƒë·ªÉ an to√†n)
                # L∆∞u √Ω: PostgreSQL d√πng SERIAL cho ID t·ª± tƒÉng, SQLite d√πng INTEGER PRIMARY KEY
                # ƒê·ªÉ t∆∞∆°ng th√≠ch c·∫£ 2 m√† kh√¥ng d√πng ORM ph·ª©c t·∫°p, ta d√πng c·∫•u tr√∫c chu·∫©n SQL
                
                # B·∫£ng Products
                conn.execute(text("CREATE TABLE IF NOT EXISTS products (id INTEGER PRIMARY KEY, name TEXT, price REAL)"))
                
                # B·∫£ng Finance Logs
                conn.execute(text("CREATE TABLE IF NOT EXISTS finance_logs (id INTEGER PRIMARY KEY, type TEXT, amount REAL)"))
                
                # B·∫£ng Agent Status (Quan tr·ªçng nh·∫•t)
                conn.execute(text("""
                    CREATE TABLE IF NOT EXISTS agent_status (
                        role_tag TEXT PRIMARY KEY, 
                        xp INTEGER DEFAULT 0, 
                        current_topic TEXT, 
                        last_updated TIMESTAMP
                    )
                """))
                
                # 2. KI·ªÇM TRA & T·∫†O D·ªÆ LI·ªÜU M·∫™U
                # Kh√¥ng d√πng cursor() n·ªØa, d√πng th·∫≥ng conn.execute
                result = conn.execute(text("SELECT count(*) FROM agent_status"))
                count = result.fetchone()[0]
                
                if count == 0:
                    print(colored("üå± DATABASE TR·ªêNG - ƒêANG KH·ªûI T·∫†O ƒê·ªòI NG≈® AGENT...", "yellow"))
                    now = datetime.now()
                    
                    # L·∫∑p qua danh s√°ch Agent
                    for role in CURRICULUM.keys():
                        # L∆ØU √ù: Thay d·∫•u ? b·∫±ng :param (C√∫ ph√°p c·ªßa SQLAlchemy)
                        conn.execute(text("""
                            INSERT INTO agent_status (role_tag, xp, current_topic, last_updated)
                            VALUES (:role, 0, 'ƒêang ch·ªù l·ªánh (Idle)', :time)
                        """), {"role": role, "time": now})
                        
                    conn.commit()
                    print(colored("‚úÖ ƒê√£ t·∫°o h·ªì s∆° cho 15 chuy√™n gia AI.", "green"))
                else:
                    print(colored("‚úÖ Database ƒë√£ c√≥ d·ªØ li·ªáu.", "green"))
                    
                # Nh·ªõ commit cu·ªëi c√πng ƒë·ªÉ ch·∫Øc ch·∫Øn l∆∞u
                conn.commit()

        except Exception as e:
            print(colored(f"‚ùå L·ªói kh·ªüi t·∫°o DB: {e}", "red"))
            # In ra l·ªói chi ti·∫øt ƒë·ªÉ debug n·∫øu c·∫ßn
            import traceback
            traceback.print_exc()
db_manager = DatabaseManager()

# ==========================================
# 2. WEBSOCKET MANAGER
# ==========================================
class ConnectionManager:
    def __init__(self):
        self.active_connections: List[WebSocket] = []

    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)

    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)

    async def send_personal_message(self, message: str, websocket: WebSocket):
        await websocket.send_text(message)

    async def send_json(self, data: dict, websocket: WebSocket):
        """G·ª≠i d·ªØ li·ªáu JSON (Quan tr·ªçng cho Dashboard hi·ªÉn th·ªã ·∫£nh/agent)"""
        await websocket.send_json(data)

    async def broadcast(self, message: str):
        for connection in self.active_connections:
            await connection.send_text(message)

manager = ConnectionManager()

# ==========================================
# 3. BACKGROUND JOBS (AI TRAINING & CRON)
# ==========================================
def calculate_level(xp: int) -> int:
    # C√¥ng th·ª©c ƒë∆°n gi·∫£n: C·ª© 100 XP l√† l√™n 1 Level. Level kh·ªüi ƒë·∫ßu l√† 1.
    return int(xp / 100) + 1

# C·∫≠p nh·∫≠t h√†m ƒë√†o t·∫°o
async def specialized_training_job(role_tag: str):
    """
    PHI√äN B·∫¢N 10.0: COST-OPTIMIZED INHERITANCE (QUY T·∫ÆC K·∫æ TH·ª™A & TI·∫æT KI·ªÜM)
    - Nguy√™n t·∫Øc: "Kh√¥ng mua l·∫°i nh·ªØng g√¨ ƒë√£ c√≥".
    - B∆∞·ªõc 1: Ki·ªÉm tra Kho tri th·ª©c (Vector DB).
    - B∆∞·ªõc 2: 
        + N·∫øu ƒë√£ c√≥ ki·∫øn th·ª©c c≈© (< 7 ng√†y) -> √îN T·∫¨P (Review Mode) -> T·ªën 0ƒë API Search.
        + N·∫øu ch∆∞a c√≥ ho·∫∑c qu√° c≈© -> MUA M·ªöI (Research Mode) -> G·ªçi API.
    """
    print(colored(f"üõ°Ô∏è [INHERITANCE CHECK] {role_tag} ƒëang ki·ªÉm tra kho tri th·ª©c...", "cyan", attrs=["bold"]))
    
    topics = CURRICULUM.get(role_tag, [])
    if not topics: return

    try:
        # 1. CH·ªåN CH·ª¶ ƒê·ªÄ
        current_xp = 0
        with db_manager.get_connection() as conn:
            row = conn.execute("SELECT xp FROM agent_status WHERE role_tag = ?", (role_tag,)).fetchone()
            if row: current_xp = row[0]

        topic_index = int(current_xp / 50) % len(topics)
        current_topic = topics[topic_index]
        
        # 2. KI·ªÇM TRA K·∫æ TH·ª™A (QUAN TR·ªåNG NH·∫§T)
        # T√¨m xem trong DB ƒë√£ c√≥ b√†i n√†o v·ªÅ ch·ªß ƒë·ªÅ n√†y ch∆∞a?
        existing_knowledge = ""
        is_fresh = False
        
        if MEMORY_AVAILABLE and vector_db:
            # T√¨m ki·∫øm trong vector db xem c√≥ g√¨ li√™n quan kh√¥ng
            results = await run_in_threadpool(lambda: vector_db.similarity_search(current_topic, k=1))
            
            if results:
                doc = results[0]
                existing_knowledge = doc.page_content
                # Ki·ªÉm tra xem ki·∫øn th·ª©c n√†y c≈© hay m·ªõi (Gi·∫£ s·ª≠ ta l∆∞u timestamp trong metadata)
                # (·ªû code tr∆∞·ªõc ta ch∆∞a l∆∞u k·ªπ timestamp, nh∆∞ng t·ª´ gi·ªù s·∫Ω l∆∞u)
                # T·∫°m th·ªùi coi nh∆∞ n·∫øu t√¨m th·∫•y l√† "K·∫ø th·ª´a"
                print(colored(f"üí° [FOUND] ƒê√£ t√¨m th·∫•y ki·∫øn th·ª©c k·∫ø th·ª´a v·ªÅ: {current_topic}", "green"))
                is_fresh = True # Gi·∫£ l·∫≠p l√† t√¨m th·∫•y

        # 3. QUY·∫æT ƒê·ªäNH CHI·∫æN L∆Ø·ª¢C (R·∫º NH√ÅNH TI·ªÄN B·∫†C)
        final_output = ""
        xp_earned = 0
        mode = "UNKNOWN"

        # === NH√ÅNH A: K·∫æ TH·ª™A (TI·∫æT KI·ªÜM TI·ªÄN) ===
        # N·∫øu ƒë√£ c√≥ ki·∫øn th·ª©c r·ªìi, ta ch·ªâ d√πng LLM (Gemini) ƒë·ªÉ "X√†o n·∫•u" l·∫°i (Review), kh√¥ng t·ªën ti·ªÅn Search (Perplexity)
        if is_fresh and existing_knowledge:
            mode = "REVIEW (√în T·∫≠p K·∫ø Th·ª´a)"
            print(colored(f"--> Ch·∫ø ƒë·ªô: {mode} - Kh√¥ng t·ªën ph√≠ t√¨m ki·∫øm.", "yellow"))
            
            if LLM_GEMINI:
                # Prompt √în t·∫≠p: D·ª±a tr√™n c√°i c≈© ƒë·ªÉ sinh ra g√≥c nh√¨n m·ªõi
                review_prompt = f"""
                B·∫°n l√† Chuy√™n gia {role_tag}.
                ƒê√¢y l√† ki·∫øn th·ª©c ch√∫ng ta ƒë√£ h·ªçc ƒë∆∞·ª£c trong qu√° kh·ª© v·ªÅ "{current_topic}":
                ---
                {existing_knowledge[:3000]}
                ---
                
                NHI·ªÜM V·ª§: K·∫æ TH·ª™A V√Ä PH√ÅT TRI·ªÇN (INHERIT & EVOLVE).
                Kh√¥ng c·∫ßn t√¨m ki·∫øm th√¥ng tin m·ªõi. H√£y d·ª±a tr√™n ki·∫øn th·ª©c c≈© n√†y ƒë·ªÉ:
                1. T√≥m t·∫Øt l·∫°i c√°c ƒëi·ªÉm c·ªët l√µi.
                2. ƒê·∫∑t ra 1 c√¢u h·ªèi ph·∫£n bi·ªán m·ªõi ƒë·ªÉ th·ª≠ th√°ch t∆∞ duy.
                3. ƒê·ªÅ xu·∫•t 1 √Ω t∆∞·ªüng ·ª©ng d·ª•ng m·ªõi t·ª´ ki·∫øn th·ª©c c≈© n√†y.
                
                M·ª•c ti√™u: C·ªßng c·ªë b·ªô nh·ªõ m√† kh√¥ng c·∫ßn n·∫°p th√™m d·ªØ li·ªáu th√¥.
                """
                try:
                    res = await LLM_GEMINI.ainvoke(review_prompt)
                    final_output = res.content
                    xp_earned = 20 # ƒêi·ªÉm √¥n t·∫≠p th·∫•p h∆°n ƒëi·ªÉm nghi√™n c·ª©u m·ªõi
                except:
                    final_output = existing_knowledge
            else:
                final_output = existing_knowledge

        # === NH√ÅNH B: KH√ÅM PH√Å M·ªöI (CH·∫§P NH·∫¨N CHI PH√ç) ===
        # Ch·ªâ ch·∫°y khi trong ƒë·∫ßu r·ªóng tu·∫øch v·ªÅ ch·ªß ƒë·ªÅ n√†y
        else:
            mode = "RESEARCH (Nghi√™n c·ª©u M·ªõi)"
            print(colored(f"--> Ch·∫ø ƒë·ªô: {mode} - C·∫ßn t√¨m ki·∫øm d·ªØ li·ªáu m·ªõi.", "magenta"))
            
            # (Ph·∫ßn n√†y gi·ªØ nguy√™n logic Research c≈© c·ªßa ng√†i: Perplexity -> Gemini)
            raw_data = ""
            if LLM_PERPLEXITY:
                try:
                    res = await LLM_PERPLEXITY.ainvoke(f"Nghi√™n c·ª©u chuy√™n s√¢u v·ªÅ: {current_topic}")
                    raw_data = res.content
                except: pass
            
            if raw_data and LLM_GEMINI:
                analyze_prompt = f"Ph√¢n t√≠ch chuy√™n s√¢u v·ªÅ {current_topic} d·ª±a tr√™n: {raw_data[:4000]}"
                try:
                    res = await LLM_GEMINI.ainvoke(analyze_prompt)
                    final_output = res.content
                    xp_earned = 50 # ƒêi·ªÉm cao v√¨ h·ªçc c√°i m·ªõi
                except: final_output = raw_data
            else:
                final_output = raw_data

        # 4. L∆ØU K·∫æT QU·∫¢ (CH·ªà L∆ØU N·∫æU L√Ä KI·∫æN TH·ª®C M·ªöI HO·∫∂C G√ìC NH√åN M·ªöI)
        if MEMORY_AVAILABLE and vector_db and final_output:
            # N·∫øu l√† Review, ta c√≥ th·ªÉ kh√¥ng c·∫ßn l∆∞u l·∫°i ƒë·ªÉ tr√°nh r√°c, ho·∫∑c l∆∞u ƒë√®
            # ·ªû ƒë√¢y ta l∆∞u th√™m ƒë·ªÉ l√†m d√†y d·ªØ li·ªáu cho Fine-tuning sau n√†y
            await run_in_threadpool(lambda: vector_db.add_texts(
                texts=[final_output],
                metadatas=[{
                    "source": "Inheritance_Cycle", 
                    "agent": role_tag, 
                    "topic": current_topic,
                    "mode": mode,
                    "timestamp": datetime.now().isoformat()
                }]
            ))

        # 5. C·∫¨P NH·∫¨T TR·∫†NG TH√ÅI
        new_xp = current_xp + xp_earned
        with db_manager.get_connection() as conn:
            c = conn.cursor()
            c.execute("""
                INSERT OR REPLACE INTO agent_status (role_tag, xp, current_topic, last_updated)
                VALUES (?, ?, ?, ?)
            """, (role_tag, new_xp, f"{mode}: {current_topic}", datetime.now()))
            conn.commit()
            
        print(colored(f"‚úÖ [{mode}] {role_tag} +{xp_earned} XP | T·ªïng: {new_xp}", "green"))

    except Exception as e:
        print(colored(f"‚ùå L·ªói: {e}", "red"))    

async def morning_briefing_job():
    """
    PHI√äN B·∫¢N 3.0: T∆∞∆°ng th√≠ch PostgreSQL + T·ª± nh·∫≠n th·ª©c (Meta-Cognition)
    """
    role_tag = "[ORCHESTRATOR]"
    print(colored(f"\n‚è∞ [CRON JOB] {role_tag} ƒëang th·ª±c hi·ªán qu√©t tin t·ª©c bu·ªïi s√°ng...", "cyan", attrs=["bold"]))
    
    if not AI_AVAILABLE: # or not LLM_PERPLEXITY (B·ªè check Perplexity n·∫øu mu·ªën ch·∫°y test v·ªõi Gemini)
        print(colored("‚ö†Ô∏è B·ªè qua Cron Job v√¨ AI Module ch∆∞a s·∫µn s√†ng.", "yellow"))
        return

    # L·∫•y ch·ªß ƒë·ªÅ t·ª´ Gi√°o Tr√¨nh chung
    topics = CURRICULUM.get(role_tag, ["Tin t·ª©c AI m·ªõi nh·∫•t", "Th·ªã tr∆∞·ªùng c√¥ng ngh·ªá 2026"])
    report_buffer = []
    
    for topic in topics:
        try:
            print(colored(f"--> {role_tag} ƒëang ƒë·ªçc: {topic}...", "white"))
            
            # G·ªçi AI (∆Øu ti√™n Perplexity, Fallback sang Gemini/GPT n·∫øu c·∫ßn)
            # Gi·∫£ s·ª≠ d√πng LLM ch√≠nh n·∫øu Perplexity ch∆∞a c·∫•u h√¨nh
            llm_to_use = LLM_PERPLEXITY if LLM_PERPLEXITY else LLM_GEMINI
            res = await llm_to_use.ainvoke(topic)
            content = res.content
            
            # L∆∞u v√†o b·ªô nh·ªõ Vector (RAG)
            if MEMORY_AVAILABLE and vector_db:
                await run_in_threadpool(lambda: vector_db.add_texts(
                    texts=[content],
                    metadatas=[{"source": "Morning_Briefing", "agent": role_tag, "topic": topic}]
                ))
            report_buffer.append(f"### {topic}\n{content[:800]}...") 
        except Exception as e:
            print(colored(f"‚ö†Ô∏è L·ªói ƒë·ªçc tin '{topic}': {e}", "yellow"))

    # T·∫°o b√°o c√°o & C·∫≠p nh·∫≠t Database
    if report_buffer:
        today_str = datetime.now().strftime("%Y-%m-%d")
        full_content = f"# üåÖ B·∫¢N TIN S√ÅNG {today_str}\n\n" + "\n\n".join(report_buffer)
        
        # ID ƒë·∫∑c bi·ªát cho b√°o c√°o (VD: BRIEFING_20260125)
        report_id = f"BRIEFING_{datetime.now().strftime('%Y%m%d')}"

        try:
            with db_manager.get_connection() as conn:
                # ---------------------------------------------------------
                # 1. L∆ØU B√ÅO C√ÅO V√ÄO DB (QUAN TR·ªåNG NH·∫§T ƒê·ªÇ KH√îNG M·∫§T FILE)
                # ---------------------------------------------------------
                # ƒê√≥ng g√≥i n·ªôi dung th√†nh format tin nh·∫Øn ƒë·ªÉ Dashboard ƒë·ªçc ƒë∆∞·ª£c
                history_json = json.dumps([{
                    "type": "ai", 
                    "data": {"content": full_content}
                }])
                
                # D√πng DELETE + INSERT ƒë·ªÉ ƒë·∫£m b·∫£o n·∫øu ch·∫°y l·∫°i kh√¥ng b·ªã l·ªói tr√πng ID
                conn.execute(text("DELETE FROM projects WHERE id = :id"), {"id": report_id})
                
                project_query = text("""
                    INSERT INTO projects (id, name, history, timestamp)
                    VALUES (:id, :name, :history, :time)
                """)
                conn.execute(project_query, {
                    "id": report_id,
                    "name": f"B√°o c√°o s√°ng {today_str}",
                    "history": history_json,
                    "time": datetime.now()
                })
                
                # ---------------------------------------------------------
                # 2. C·∫¨P NH·∫¨T ƒêI·ªÇM XP (GAMIFICATION)
                # ---------------------------------------------------------
                # A. L·∫•y XP hi·ªán t·∫°i
                xp_query = text("SELECT xp FROM agent_status WHERE role_tag = :role")
                row = conn.execute(xp_query, {"role": role_tag}).fetchone()
                new_xp = (row[0] if row else 0) + 100
                
                # B. C·∫≠p nh·∫≠t tr·∫°ng th√°i Agent
                conn.execute(text("DELETE FROM agent_status WHERE role_tag = :role"), {"role": role_tag})
                
                status_query = text("""
                    INSERT INTO agent_status (role_tag, xp, current_topic, last_updated) 
                    VALUES (:role, :xp, :topic, :time)
                """)
                conn.execute(status_query, {
                    "role": role_tag, 
                    "xp": new_xp, 
                    "topic": f"Ho√†n th√†nh b·∫£n tin {today_str}", 
                    "time": datetime.now()
                })

                # ---------------------------------------------------------
                # 3. GHI NH·∫¨T K√ù T·ª∞ NH·∫¨N TH·ª®C (META-COGNITION)
                # ---------------------------------------------------------
                log_query = text("""
                    INSERT INTO learning_logs (event_type, content, agent_name, timestamp)
                    VALUES (:type, :content, :agent, :time)
                """)
                conn.execute(log_query, {
                    "type": "CREATED",
                    "content": f"ƒê√£ t·ªïng h·ª£p v√† l∆∞u tr·ªØ vƒ©nh vi·ªÖn B·∫£n tin s√°ng {today_str}.",
                    "agent": role_tag,
                    "time": datetime.now()
                })
                
                # CH·ªêT ƒê∆†N (COMMIT) 1 L·∫¶N DUY NH·∫§T
                conn.commit()
                print(colored(f"‚úÖ [DATABASE] ƒê√£ l∆∞u b√°o c√°o s√°ng v√†o h·ªá th·ªëng vƒ©nh vi·ªÖn!", "green"))
                
        except Exception as e:
            print(colored(f"‚ùå L·ªói L∆∞u Tr·ªØ Job S√°ng: {e}", "red"))

# ==========================================
# 3. PIPELINE D·ª∞ √ÅN L·ªöN (ƒê√É T·ªêI ∆ØU & H·ª¢P NH·∫§T)
# ==========================================

async def run_architect_phase(project_request: str, thread_id: str):
    """
    B∆∞·ªõc 1: V·∫Ω s∆° ƒë·ªì v√† k·∫ø ho·∫°ch thi c√¥ng.
    Output: File BLUEPRINT.md ch·ª©a danh s√°ch c√°c b∆∞·ªõc (Steps).
    """
    print(colored(f"üìê [ARCHITECT] ƒêang ph√°c th·∫£o d·ª± √°n: {project_request}", "cyan"))
    os.makedirs("projects", exist_ok=True)
    plan_path = f"projects/{thread_id}_BLUEPRINT.md"
    
    try:
        if not SERVER_READY: return "Simulation Plan", plan_path

        architect_prompt = (
            f"B·∫°n l√† Chief Software Architect (CSA). C√≥ m·ªôt y√™u c·∫ßu d·ª± √°n: '{project_request}'.\n"
            "H√£y l·∫≠p m·ªôt B·∫¢N THI·∫æT K·∫æ K·ª∏ THU·∫¨T (Technical Blueprint) chi ti·∫øt d·∫°ng Markdown:\n\n"
            "1. [OVERVIEW]: T√≥m t·∫Øt m·ª•c ti√™u d·ª± √°n.\n"
            "2. [MODULES]: Danh s√°ch c√°c ch·ª©c nƒÉng ch√≠nh.\n"
            "3. [DATABASE]: S∆° ƒë·ªì b·∫£ng (Table Schema) chi ti·∫øt.\n"
            "4. [TECH STACK]: C√¥ng ngh·ªá s·ª≠ d·ª•ng.\n"
            "5. [EXECUTION PLAN] (QUAN TR·ªåNG): H√£y li·ªát k√™ l·ªô tr√¨nh code c·ª• th·ªÉ t·ª´ng b∆∞·ªõc.\n"
            "   - B·∫Øt bu·ªôc d√πng g·∫°ch ƒë·∫ßu d√≤ng (-) cho m·ªói b∆∞·ªõc.\n"
            "   - V√≠ d·ª•:\n"
            "   - T·∫°o m√¥i tr∆∞·ªùng ·∫£o v√† file requirements.txt\n"
            "   - Thi·∫øt k·∫ø database models trong models.py\n"
            "   - Vi·∫øt API ƒëƒÉng nh·∫≠p\n"
        )
        
        plan_res = await run_in_threadpool(lambda: LLM_SUPERVISOR.invoke(architect_prompt))
        content = plan_res.content
        
        async with aiofiles.open(plan_path, "w", encoding="utf-8") as f:
            await f.write(content)
            
        print(colored(f"‚úÖ [ARCHITECT DONE] B·∫£n v·∫Ω ƒë√£ xong: {plan_path}", "green"))
        return content, plan_path

    except Exception as e:
        print(colored(f"‚ùå L·ªói Architect: {e}", "red"))
        return None, None

async def run_coding_phase(blueprint_content: str, thread_id: str):
    """
    B∆∞·ªõc 2: ƒê·ªçc b·∫£n v·∫Ω -> Code t·ª´ng ph·∫ßn -> Ghi log.
    """
    print(colored(f"üèóÔ∏è [EXECUTOR] B·∫Øt ƒë·∫ßu thi c√¥ng d·ª± √°n {thread_id}...", "magenta"))
    log_file = f"projects/{thread_id}_coding_log.txt"
    
    raw_lines = blueprint_content.split('\n')
    steps = []
    is_in_plan = False
    
    # Parsing th√¥ng minh ƒë·ªÉ t√¨m EXECUTION PLAN
    for line in raw_lines:
        if "EXECUTION PLAN" in line.upper(): is_in_plan = True
        if is_in_plan and (line.strip().startswith('-') or line.strip().startswith('*')):
            step_clean = line.strip().lstrip('-* ').strip()
            if len(step_clean) > 5:
                steps.append(step_clean)

    if not steps:
        print(colored("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y b∆∞·ªõc code n√†o trong Blueprint. D·ª´ng.", "yellow"))
        return

    async with aiofiles.open(log_file, "w", encoding="utf-8") as f:
        await f.write(f"=== B·∫ÆT ƒê·∫¶U D·ª∞ √ÅN {thread_id} ===\n\n")

    for idx, step in enumerate(steps):
        print(colored(f"‚è≥ [STEP {idx+1}/{len(steps)}]: {step}", "yellow"))
        
        step_prompt = (
            f"D·ª∞ √ÅN: {thread_id}\n"
            f"NHI·ªÜM V·ª§ C·ª§ TH·ªÇ: {step}\n"
            "Y√™u c·∫ßu: Vi·∫øt code ho√†n ch·ªânh cho nhi·ªám v·ª• n√†y. Kh√¥ng gi·∫£i th√≠ch d√†i d√≤ng."
        )
        
        try:
            if SERVER_READY:
                state_res = await ai_app.ainvoke(
                    {"messages": [HumanMessage(content=step_prompt)]},
                    config={"configurable": {"thread_id": thread_id}}
                )
                ai_output = state_res['messages'][-1].content
            else:
                ai_output = f"[SIMULATION] Coding step {idx+1}..."
                await asyncio.sleep(1)

            async with aiofiles.open(log_file, "a", encoding="utf-8") as f:
                await f.write(f"\n\n{'='*30}\n### B∆Ø·ªöC {idx+1}: {step}\n{'='*30}\n{ai_output}\n")
            
            await asyncio.sleep(2) # Ngh·ªâ ƒë·ªÉ tr√°nh Rate Limit
            
        except Exception as e:
            print(colored(f"‚ùå L·ªói Step {idx+1}: {e}", "red"))

    print(colored(f"‚úÖ [PROJECT COMPLETE] D·ª± √°n {thread_id} ƒë√£ ho√†n th√†nh 100%!", "green"))

async def full_project_pipeline(user_request: str, thread_id: str):
    """
    Quy tr√¨nh kh√©p k√≠n: Architect -> Blueprint -> Executor -> Code.
    """
    blueprint, path = await run_architect_phase(user_request, thread_id)
    if blueprint:
        await run_coding_phase(blueprint, thread_id)
    else:
        print("‚ùå D·ª± √°n b·ªã h·ªßy do l·ªói thi·∫øt k·∫ø.")


# ==========================================
# 4. APP & ROUTES
# ==========================================
@asynccontextmanager
async def lifespan(app: FastAPI):
    directories_to_create = [
        UPLOAD_DIR,      # /var/data/uploads
        PROJECTS_DIR,    # /var/data/projects
        "static",        # ./static (Code)
        "templates"      # ./templates (Code)
    ]
    
    for d in directories_to_create:
        if not os.path.exists(d): 
            os.makedirs(d)
            print(f"üìÅ ƒê√£ t·∫°o th∆∞ m·ª•c: {d}")

    # 2. Kh·ªüi t·∫°o Database
    db_manager.init_db()
    
    # T·∫°o th∆∞ m·ª•c c·∫ßn thi·∫øt
    for d in [UPLOAD_DIR, "static", "templates", "projects"]:
        if not os.path.exists(d): os.makedirs(d)
        
    # --- SCHEDULER SETUP (QUAN TR·ªåNG) ---
    scheduler = AsyncIOScheduler()
    scheduler.add_job(morning_briefing_job, 'cron', hour=7, minute=0)
    scheduler.start()
    
    # --- 3. K√çCH HO·∫†T "H·ªåC VI·ªÜN CA ƒê√äM" (T√çNH NƒÇNG M·ªöI) ---
    # Thay v√¨ d√πng scheduler c·ª©ng nh·∫Øc, ta ch·∫°y Background Task linh ho·∫°t
    # ƒê·ªÉ n√≥ t·ª± ƒë·ªông h·ªçc 60p -> ngh·ªâ -> xoay v√≤ng -> t·ª± d·ª´ng khi c√≥ kh√°ch
    print("üéì [SYSTEM] K√≠ch ho·∫°t ch·∫ø ƒë·ªô 'Adaptive Learning' (H·ªçc lu√¢n phi√™n)...")
    learning_task = asyncio.create_task(adaptive_learning_scheduler())
    yield # Server ch·∫°y t·∫°i ƒë√¢y
    
    # --- SHUTDOWN ---
    scheduler.shutdown()
    # H·ªßy t√°c v·ª• h·ªçc t·∫≠p nh·∫π nh√†ng
    print("üí§ [SYSTEM] ƒêang gi·∫£i t√°n l·ªõp h·ªçc...")
    learning_task.cancel()
    try:
        await learning_task
    except asyncio.CancelledError:
        print("‚úÖ [SYSTEM] ƒê√£ d·ª´ng ch·∫ø ƒë·ªô h·ªçc t·∫≠p an to√†n.")
        
    logger.info("üí§ SYSTEM SHUTDOWN.")

app = FastAPI(
    title="J.A.R.V.I.S Neural Backend",
    version="3.0",
    lifespan=lifespan
)

# 1. C·∫•u h√¨nh CORS (Cho ph√©p m·ªçi k·∫øt n·ªëi)
app.add_middleware(
    CORSMiddleware, 
    allow_origins=["*"], 
    allow_methods=["*"], 
    allow_headers=["*"]
)

# 2. Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n tƒ©nh (Auto-Create Folder)
base_dir = os.path.abspath(os.path.dirname(__file__))
static_dir = os.path.join(base_dir, 'static')
templates_dir = os.path.join(base_dir, 'templates')

# --- QUAN TR·ªåNG: T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥ (Fix l·ªói Render) ---
if not os.path.exists(static_dir):
    os.makedirs(static_dir)
    print(colored("‚ö†Ô∏è ƒê√£ t·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c 'static'.", "yellow"))

if not os.path.exists(templates_dir):
    os.makedirs(templates_dir)
    print(colored("‚ö†Ô∏è ƒê√£ t·ª± ƒë·ªông t·∫°o th∆∞ m·ª•c 'templates'.", "yellow"))

# 3. Mount Static & Templates
app.mount("/static", StaticFiles(directory=static_dir), name="static")
templates = Jinja2Templates(directory=templates_dir)

# --- DATA MODELS (Pydantic) ---
class ChatRequest(BaseModel):
    message: str
    thread_id: str = "ceo_session"

class SpeakRequest(BaseModel):
    text: str

class LearnRequest(BaseModel):
    text: str

class BuyRequest(BaseModel):
    product_id: int

class TTSRequest(BaseModel):
    text: str

# ==========================================
# 5. API ENDPOINTS
# ==========================================
@app.get("/admin")
async def admin_page(request: Request):
    # Truy·ªÅn th√™m bi·∫øn api_key sang giao di·ªán HTML
    return templates.TemplateResponse("admin.html", {
        "request": request, 
        "api_key": ADMIN_SECRET # <--- QUAN TR·ªåNG: D√≤ng n√†y gi√∫p hi·ªÉn th·ªã Key
    })


@app.get("/")
async def home_page(request: Request):
    # N·∫øu ng√†i c√≥ file index.html ho·∫∑c products.html th√¨ ƒë·ªÉ nguy√™n
    # N·∫øu mu·ªën m·∫∑c ƒë·ªãnh v√†o Dashboard th√¨ ƒë·ªïi th√†nh "dashboard.html"
    return templates.TemplateResponse("store.html", {"request": request}) 
    # L∆∞u √Ω: ƒê·∫£m b·∫£o file index.html n√†y t·ªìn t·∫°i trong th∆∞ m·ª•c templates

# 2. Trang Dashboard (Giao di·ªán Chat & V·∫Ω tranh - J.A.R.V.I.S COMMAND CENTER)
@app.get("/dashboard")
async def dashboard_page(request: Request):
    return templates.TemplateResponse("dashboard.html", {"request": request})

@app.get("/index")
async def dashboard_page(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})


async def verify_api_key(x_api_key: Optional[str] = Header(None)):
    """Middleware ki·ªÉm tra b·∫£o m·∫≠t"""
    # Logic: N·∫øu c√≥ g·ª≠i key th√¨ check, n·∫øu kh√¥ng g·ª≠i (Dev mode) th√¨ b·ªè qua ho·∫∑c ch·∫∑n t√πy CEO
    if x_api_key and x_api_key != ADMIN_SECRET:
        raise HTTPException(status_code=403, detail="‚õî SAI M·∫¨T M√É QU√ÇN S·ª∞ (WRONG API KEY)")
    return x_api_key

@app.get("/api/agents/status")
async def get_agents_status_endpoint():
    """API tr·∫£ v·ªÅ Level & XP c·ªßa Agent cho giao di·ªán Admin"""
    try:
        with db_manager.get_connection() as conn:
            # L·∫•y d·ªØ li·ªáu v√† t√≠nh Level
            df = pd.read_sql_query("SELECT *, (xp / 100) + 1 as level FROM agent_status ORDER BY xp DESC", conn)
            # Chuy·ªÉn ƒë·ªïi timestamp th√†nh chu·ªói ƒë·ªÉ JSON kh√¥ng l·ªói
            df['last_updated'] = df['last_updated'].astype(str)
            return df.to_dict(orient="records")
    except Exception as e:
        logger.error(f"Agent Status Error: {e}")
        return []

@app.get("/api/stats")
async def get_system_stats():
    """Th·ªëng k√™ t√†i ch√≠nh"""
    try:
        with db_manager.get_connection() as conn:
            prod_count = conn.execute("SELECT count(*) FROM products").fetchone()[0]
            income = conn.execute("SELECT SUM(amount) FROM finance_logs WHERE type='income'").fetchone()[0] or 0
            expense = conn.execute("SELECT SUM(amount) FROM finance_logs WHERE type='expense'").fetchone()[0] or 0
            return {
                "products": prod_count,
                "revenue": income,
                "expense": expense,
                "balance": income - expense
            }
    except:
        return {"products": 0, "revenue": 0, "expense": 0}

@app.get("/api/products")
async def get_products_api():
    try:
        with db_manager.get_connection() as conn:
            conn.row_factory = sqlite3.Row
            rows = conn.execute("SELECT * FROM products").fetchall()
            return [dict(r) for r in rows]
    except: return []

@app.post("/api/buy")
async def buy_product(req: BuyRequest):
    conn = sqlite3.connect(DB_PATH)
    try:
        product = conn.execute("SELECT price, name FROM products WHERE id=?", (req.product_id,)).fetchone()
        if not product:
            raise HTTPException(status_code=404, detail="Product not found")
            
        price, name = product[0], product[1]
        license_key = str(uuid.uuid4()).upper()[:19]
        
        # X·ª≠ l√Ω t√†i ch√≠nh (Dynamic Import ƒë·ªÉ tr√°nh l·ªói v√≤ng l·∫∑p)
        try:
            from finance_manager import process_order_revenue
            process_order_revenue(order_id=int(time.time()), total_amount=price)
        except ImportError:
            pass 
            
        return {
            "status": "success",
            "msg": f"ƒê√£ mua th√†nh c√¥ng: {name}",
            "license_key": license_key
        }
    finally:
        conn.close()

# --- API ƒê·ªíNG B·ªò D·ªÆ LI·ªÜU ---
@app.get("/api/sync/download_db")
async def download_database():
    if os.path.exists(DB_PATH):
        return FileResponse(path=DB_PATH, filename="ai_corp_data.db", media_type='application/octet-stream')
    return {"error": "Database not found"}


@app.post("/api/chat")
async def chat_endpoint(request: ChatRequest, background_tasks: BackgroundTasks):
    """
    SMART CHAT V4: STABLE & ERROR-PROOF
    Phi√™n b·∫£n s·ª≠a l·ªói 400 OpenAI v√† t·ªëi ∆∞u quy tr√¨nh x·ª≠ l√Ω.
    """
    if not AI_AVAILABLE:
        return {"reply": "‚ö†Ô∏è H·ªá th·ªëng AI ƒëang kh·ªüi ƒë·ªông. Vui l√≤ng ƒë·ª£i 30s."}

    try:
        user_msg_text = str(request.message).strip()
        thread_id = str(request.thread_id) if request.thread_id else "default_session"
        
        # --- 1. X·ª¨ L√ù NHANH (GREETINGS & COMMANDS) ---
        # Gi·ªØ l·∫°i logic ch√†o h·ªèi nhanh ƒë·ªÉ ti·∫øt ki·ªám ti·ªÅn AI
        greetings = ["ch√†o", "hi", "hello", "alo"]
        if user_msg_text.lower() in greetings:
             return {"reply": "Ch√†o CEO! J.A.R.V.I.S ƒë√£ s·∫µn s√†ng nh·∫≠n l·ªánh."}

        # --- 2. CHU·∫®N B·ªä K√ù ·ª®C (MEMORY) ---
        memory_context = ""
        if MEMORY_AVAILABLE:
            # L·∫•y k√Ω ·ª©c ch·∫°y ng·∫ßm ƒë·ªÉ kh√¥ng l√†m ch·∫≠m chat
            try:
                memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_msg_text))
                print(colored(f"üß† K√Ω ·ª©c k√≠ch ho·∫°t: {len(memory_context)} chars", "magenta"))
            except: pass

        # --- 3. ƒê√ìNG G√ìI TIN NH·∫ÆN (THE FIX) ---
        # Thay v√¨ g·ªôp chu·ªói, ta gi·ªØ nguy√™n User Message ƒë·ªÉ OpenAI hi·ªÉu ƒë√¢y l√† l·ªánh m·ªõi
        # Context ƒë∆∞·ª£c ch√®n v√†o System Message ho·∫∑c Memory c·ªßa Graph (t√πy c·∫•u h√¨nh Graph c·ªßa ng√†i)
        # Nh∆∞ng ƒë·ªÉ an to√†n nh·∫•t, ta k·∫πp Context v√†o tin nh·∫Øn nh∆∞ng v·∫´n gi·ªØ role Human
        
        final_input_content = f"""
        [CONTEXT INFO]:
        Location: Phan Thiet
        Time: {datetime.now().strftime('%H:%M %d/%m/%Y')}
        Relevant Memories: {memory_context}
        
        [USER COMMAND]:
        {user_msg_text}
        """
        
        # T·∫°o ƒë·ªëi t∆∞·ª£ng tin nh·∫Øn chu·∫©n LangChain
        human_msg = HumanMessage(content=final_input_content)
        
        # C·∫•u h√¨nh phi√™n l√†m vi·ªác
        config = {"configurable": {"thread_id": thread_id}}

        print(colored(f"üì• INPUT: {user_msg_text[:50]}...", "cyan"))

        # --- 4. G·ªåI B·ªò N√ÉO (LANGGRAPH) ---
        # D√πng invoke (ƒë·ªìng b·ªô) thay v√¨ ainvoke ·ªü ƒë√¢y ƒë·ªÉ tr√°nh race condition g√¢y l·ªói 400
        # ƒê·∫£m b·∫£o tin nh·∫Øn ƒë∆∞·ª£c append v√†o list tr∆∞·ªõc khi g·ª≠i ƒëi
        output = await run_in_threadpool(lambda: ai_app.invoke(
            {"messages": [human_msg]}, 
            config=config
        ))
        
        # --- 5. TR√çCH XU·∫§T K·∫æT QU·∫¢ ---
        last_message = output["messages"][-1]
        ai_reply = last_message.content
        
        # --- 6. H·∫¨U X·ª¨ L√ù (L∆ØU K√ù ·ª®C & LOG) ---
        if MEMORY_AVAILABLE:
            background_tasks.add_task(extract_and_save_memory, user_msg_text, ai_reply)
            
        return {
            "status": "success", 
            "reply": ai_reply,
            "agent": "J.A.R.V.I.S v2.0"
        }

    except Exception as e:
        error_msg = str(e)
        print(colored(f"‚ùå CHAT ERROR: {error_msg}", "red"))
        
        # T·ª± ƒë·ªông s·ª≠a l·ªói 400 b·∫±ng c√°ch reset nh·∫π h·ªôi tho·∫°i
        if "Last message must have role user" in error_msg:
            return {
                "reply": "‚ö†Ô∏è L·ªói ƒë·ªìng b·ªô h·ªôi tho·∫°i. T√¥i ƒë√£ t·ª± ƒë·ªông s·∫Øp x·∫øp l·∫°i b·ªô nh·ªõ. Vui l√≤ng g·ª≠i l·∫°i c√¢u l·ªánh v·ª´a r·ªìi."
            }
            
        return {"reply": f"üí• L·ªói h·ªá th·ªëng: {error_msg}"}

@app.post("/api/speak")
async def api_speak(request: SpeakRequest):
    """
    API T·∫°o gi·ªçng n√≥i (ƒê√£ t·ªëi ∆∞u h√≥a Non-blocking & Fail-safe).
    """
    # 1. Ki·ªÉm tra an to√†n: N·∫øu module voice ch∆∞a load ho·∫∑c client ch∆∞a c√≥ -> B·ªè qua nh·∫π nh√†ng
    if not VOICE_AVAILABLE or 'client' not in globals() or client is None:
        # Tr·∫£ v·ªÅ 204 (No Content) ƒë·ªÉ Dashboard bi·∫øt m√† im l·∫∑ng, kh√¥ng b√°o l·ªói ƒë·ªè
        return Response(status_code=204)
    
    try:
        # 2. T·ªëi ∆∞u chi ph√≠ & T·ªëc ƒë·ªô: Ch·ªâ ƒë·ªçc 500 k√Ω t·ª± ƒë·∫ßu
        # (J.A.R.V.I.S kh√¥ng n√™n ƒë·ªçc c·∫£ b√†i vƒÉn d√†i, t·ªën ti·ªÅn v√† l√¢u)
        safe_text = request.text[:1000] 

        # 3. K·ªπ thu·∫≠t Non-blocking (QUAN TR·ªåNG NH·∫§T)
        # ƒê·∫©y vi·ªác g·ªçi OpenAI sang lu·ªìng kh√°c ƒë·ªÉ Server v·∫´n nh·∫≠n chat c·ªßa ng∆∞·ªùi kh√°c ƒë∆∞·ª£c
        def _generate_audio():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx", 
                input=safe_text
            )
        
        # D√πng await ƒë·ªÉ ƒë·ª£i lu·ªìng ph·ª• x·ª≠ l√Ω xong
        response = await run_in_threadpool(_generate_audio)
        return Response(content=response.content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [VOICE ERROR]: {str(e)}")
        # N·∫øu l·ªói (h·∫øt ti·ªÅn, m·∫•t m·∫°ng...), tr·∫£ v·ªÅ 204 ƒë·ªÉ Dashboard v·∫´n ch·∫°y ti·∫øp m∆∞·ª£t m√†
        return Response(status_code=204)

@app.post("/api/tts")
async def text_to_speech_api(request: TTSRequest):
    """
    API TTS V2: L·ªçc s·∫°ch k√Ω t·ª± ƒë·∫∑c bi·ªát gi√∫p gi·ªçng ƒë·ªçc m∆∞·ª£t h∆°n (L∆∞·ªõt).
    """
    try:
        # 1. L·∫•y vƒÉn b·∫£n g·ªëc
        raw_text = request.text[:500]
        
        # --- B·ªò L·ªåC L√ÄM M·ªäN (TEXT CLEANER) ---
        def clean_text_for_speech(text):
            # 1. Lo·∫°i b·ªè Markdown (*, #, `) th∆∞·ªùng g·∫∑p trong AI response
            text = text.replace("*", "").replace("#", "").replace("`", "").replace("_", " ")
            
            # 2. Lo·∫°i b·ªè c√°c ƒë∆∞·ªùng link http://... (ƒê·ªçc link r·∫•t ch√°n)
            text = re.sub(r'http\S+', 'li√™n k·∫øt', text)
            
            # 3. Lo·∫°i b·ªè c√°c d·∫•u ngo·∫∑c vu√¥ng nh∆∞ [IMAGE], [1]...
            text = re.sub(r'\[.*?\]', '', text)
            
            # 4. Lo·∫°i b·ªè c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát v√¥ nghƒ©a kh√°c, gi·ªØ l·∫°i d·∫•u c√¢u c∆° b·∫£n (. , ? !)
            # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i, s·ªë v√† d·∫•u c√¢u ti·∫øng Vi·ªát
            # (Regex n√†y gi·ªØ l·∫°i ch·ªØ unicode v√† d·∫•u c√¢u c∆° b·∫£n)
            # text = re.sub(r'[^\w\s.,?!]', '', text) # C√≥ th·ªÉ d√πng n·∫øu mu·ªën l·ªçc c·ª±c m·∫°nh
            
            # 5. X√≥a kho·∫£ng tr·∫Øng th·ª´a (nhi·ªÅu d·∫•u c√°ch li·ªÅn nhau)
            text = " ".join(text.split())
            return text.strip()

        # √Åp d·ª•ng b·ªô l·ªçc
        speak_text = clean_text_for_speech(raw_text)
        
        logger.info(f"ü§ñ Google TTS (Cleaned): {speak_text[:50]}...")

        # 2. T·∫°o √¢m thanh (Ch·∫°y trong lu·ªìng ri√™ng)
        def _generate_google_audio():
            # tld='com.vn' gi√∫p gi·ªçng Google chu·∫©n Vi·ªát Nam h∆°n
            tts = gTTS(text=speak_text, lang='vi', tld='com.vn')
            
            buffer = io.BytesIO()
            tts.write_to_fp(buffer)
            buffer.seek(0)
            return buffer.read()

        # 3. Th·ª±c thi
        audio_content = await run_in_threadpool(_generate_google_audio)
        
        return Response(content=audio_content, media_type="audio/mpeg")

    except Exception as e:
        logger.error(f"üö® [GOOGLE TTS ERROR]: {str(e)}")
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/api/voice_chat")
async def voice_chat(file: UploadFile = File(...), api_key: str = Depends(verify_api_key)):
    """
    T∆Ø∆†NG T√ÅC B·∫∞NG GI·ªåNG N√ìI (Voice-to-Voice) - V2 (Cleaned Audio)
    """
    if not AI_AVAILABLE or 'client' not in globals():
        return JSONResponse(status_code=503, content={"error": "AI/Voice Module ch∆∞a s·∫µn s√†ng"})

    # 1. L∆ØU FILE T·∫†M
    temp_filename = f"temp_{uuid.uuid4()}.webm"
    temp_path = os.path.join(UPLOAD_DIR, temp_filename)
    
    try:
        async with aiofiles.open(temp_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)

        # 2. D·ªäCH GI·ªåNG N√ìI SANG CH·ªÆ (WHISPER)
        def _transcribe():
            with open(temp_path, "rb") as audio_file:
                return client.audio.transcriptions.create(
                    model="whisper-1", 
                    file=audio_file,
                    language="vi"
                )
        
        transcript = await run_in_threadpool(_transcribe)
        user_text = transcript.text
        print(f"üé§ [VOICE INPUT]: {user_text}")
        
        # 3. X·ª¨ L√ù AI (SMART CHAT)
        # --- Logic Chat t·ªëi gi·∫£n cho Voice ---
        memory_context = ""
        if MEMORY_AVAILABLE:
            memory_context = await run_in_threadpool(lambda: recall_relevant_memories(user_text))
            
        fast_keywords = ["gi√° v√†ng", "th·ªùi ti·∫øt", "m·∫•y gi·ªù", "ng√†y m·∫•y", "t·ª∑ gi√°"]
        ai_text = ""
        agent_name = "J.A.R.V.I.S"

        # A. Fast Track (Gemini)
        if any(k in user_text.lower() for k in fast_keywords) and LLM_GEMINI:
             try:
                 ai_res = await LLM_GEMINI.ainvoke(f"K√Ω ·ª©c: {memory_context}. H·ªèi: {user_text}")
                 ai_text = ai_res.content
                 agent_name = "Gemini Voice"
             except: pass
        
        # B. Deep Thinking (LangGraph) - N·∫øu Fast Track th·∫•t b·∫°i ho·∫∑c kh√¥ng kh·ªõp
        if not ai_text:
             full_prompt = f"K√Ω ·ª©c: {memory_context}\nUser: {user_text}"
             from langchain_core.messages import HumanMessage
             final_state = await ai_app.ainvoke({"messages": [HumanMessage(content=full_prompt)]}, config={"configurable": {"thread_id": "voice_thread"}})
             last_message = final_state['messages'][-1]
             ai_text = last_message.content
             agent_name = final_state.get("current_agent", "J.A.R.V.I.S")
        
        # 4. T·∫†O GI·ªåNG N√ìI (TTS)
        # --- B∆Ø·ªöC QUAN TR·ªåNG: L√ÄM S·∫†CH VƒÇN B·∫¢N TR∆Ø·ªöC KHI ƒê·ªåC ---
        def clean_text_for_speech(text):
            text = text.replace("*", "").replace("#", "").replace("`", "").replace("_", " ")
            text = re.sub(r'http\S+', '', text) # B·ªè link
            text = re.sub(r'\[.*?\]', '', text) # B·ªè th·∫ª [System]
            return " ".join(text.split()).strip()

        clean_ai_text = clean_text_for_speech(ai_text)
        speak_text = clean_ai_text[:500] # C·∫Øt ng·∫Øn ƒë·ªÉ ti·∫øt ki·ªám

        def _speak():
            return client.audio.speech.create(
                model="tts-1",
                voice="onyx",
                input=speak_text
            )
        audio_res = await run_in_threadpool(_speak)

        # 5. TR·∫¢ V·ªÄ K·∫æT QU·∫¢ K√âP
        audio_b64 = base64.b64encode(audio_res.content).decode('utf-8')

        return {
            "text_reply": ai_text, # Tr·∫£ v·ªÅ text g·ªëc (c√≥ markdown) ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp
            "audio_base64": audio_b64, # Audio ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch ƒë·ªÉ ƒë·ªçc m∆∞·ª£t
            "transcript": user_text,
            "agent": agent_name
        }

    except Exception as e:
        logger.error(f"Voice Error: {e}")
        return JSONResponse(status_code=500, content={"error": str(e)})
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

@app.post("/api/plan_project")
async def plan_project_endpoint(
    request: ChatRequest, 
    api_key: str = Depends(verify_api_key) # <--- CH·ªêT CH·∫∂N B·∫¢O M·∫¨T
):
    """
    B∆∞·ªõc 1: CEO y√™u c·∫ßu l·∫≠p k·∫ø ho·∫°ch (Y√™u c·∫ßu API Key).
    """
    # Ki·ªÉm tra tr·∫°ng th√°i AI
    if not AI_AVAILABLE: 
        return JSONResponse(status_code=503, content={"status": "ERROR", "message": "AI Module Offline"})
    
    # T·∫°o ID d·ª± √°n n·∫øu ch∆∞a c√≥
    pid = request.thread_id or f"proj_{int(time.time())}"
    
    try:
        # G·ªçi h√†m architect M·ªöI (run_architect_phase)
        plan_content, plan_path = await run_architect_phase(request.message, pid)
        
        return {
            "status": "PLAN_CREATED",
            "project_id": pid,
            "message": "ƒê√£ l·∫≠p xong b·∫£n thi·∫øt k·∫ø. Vui l√≤ng xem x√©t.",
            "blueprint_content": plan_content, # Tr·∫£ v·ªÅ n·ªôi dung ƒë·ªÉ hi·ªán l√™n Dashboard
            "blueprint_path": plan_path,
            "next_action": "N·∫øu ƒë·ªìng √Ω, h√£y g·ªçi /api/heavy_project v·ªõi n·ªôi dung 'EXECUTE_BLUEPRINT'"
        }
    except Exception as e:
        # B·∫Øt l·ªói n·∫øu h√†m architect tr·∫£ v·ªÅ kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng ho·∫∑c l·ªói b·∫•t ng·ªù
        return JSONResponse(status_code=500, content={"status": "ERROR", "message": f"L·ªói h·ªá th·ªëng: {str(e)}"})

# --- C·∫§U H√åNH H·ªåC T·∫¨P ---
LEARNING_QUEUE = ["CODER", "ARTIST", "ENGINEERING", "MARKETING", "LEGAL"]
CURRENT_LEARNER_INDEX = 0
IS_BUSY = False  # Tr·∫°ng th√°i b·∫≠n r·ªôn c·ªßa h·ªá th·ªëng
LAST_ACTIVITY_TIME = datetime.now()

async def adaptive_learning_scheduler():
    """
    H·ªá th·ªëng l·∫≠p l·ªãch h·ªçc t·∫≠p th√¥ng minh.
    Ch·∫°y ng·∫ßm (Background Loop) song song v·ªõi Server.
    """
    global CURRENT_LEARNER_INDEX, IS_BUSY
    
    print("üéì [SCHEDULER] ƒê√£ k√≠ch ho·∫°t H·ªçc vi·ªán Agent t·ª± ƒë·ªông.")
    
    while True:
        # 1. Ki·ªÉm tra tr·∫°ng th√°i r·∫£nh r·ªói (Idle Check)
        # N·∫øu kh√¥ng c√≥ l·ªánh m·ªõi trong 5 ph√∫t -> Coi nh∆∞ r·∫£nh
        idle_duration = (datetime.now() - LAST_ACTIVITY_TIME).total_seconds()
        if idle_duration > 300: 
            IS_BUSY = False
        else:
            IS_BUSY = True

        # 2. Logic ƒëi·ªÅu ph·ªëi
        if IS_BUSY:
            print("üöß [SYSTEM] H·ªá th·ªëng ƒëang b·∫≠n d·ª± √°n. T·∫°m ho√£n vi·ªác h·ªçc.", end="\r")
            await asyncio.sleep(60) # Ch·ªù 1 ph√∫t r·ªìi check l·∫°i
            continue

        # 3. B·∫Øt ƒë·∫ßu phi√™n h·ªçc 60 ph√∫t
        agent_name = LEARNING_QUEUE[CURRENT_LEARNER_INDEX]
        print(f"\nüìö [LEARNING] B·∫Øt ƒë·∫ßu phi√™n h·ªçc 60p cho Agent: {agent_name}")
        
        # Gi·∫£ l·∫≠p qu√° tr√¨nh h·ªçc (Chia nh·ªè th√†nh 60 l·∫ßn 1 ph√∫t ƒë·ªÉ d·ªÖ ng·∫Øt ngang)
        for minute in range(60):
            # KI·ªÇM TRA NG·∫ÆT NGANG: N·∫øu CEO ƒë·ªôt nhi√™n ra l·ªánh
            if IS_BUSY: 
                print(f"üõë [INTERRUPT] Ng·ª´ng phi√™n h·ªçc c·ªßa {agent_name} ƒë·ªÉ ph·ª•c v·ª• CEO!")
                break 
            
            # Th·ª±c hi·ªán h√†nh ƒë·ªông h·ªçc (V√≠ d·ª•: ƒê·ªçc 1 trang t√†i li·ªáu ng·∫´u nhi√™n trong DB)
            # await self_study(agent_name) 
            
            print(f"‚è≥ {agent_name} ƒëang h·ªçc... ({minute+1}/60 ph√∫t)", end="\r")
            await asyncio.sleep(60) # H·ªçc 1 ph√∫t

        # 4. K·∫øt th√∫c phi√™n -> Xoay v√≤ng
        if not IS_BUSY: # Ch·ªâ chuy·ªÉn ng∆∞·ªùi n·∫øu h·ªçc tr·ªçn v·∫πn (ho·∫∑c ch·∫•p nh·∫≠n h·ªçc d·ªü)
            print(f"‚úÖ [DONE] {agent_name} ƒë√£ ho√†n th√†nh phi√™n h·ªçc.")
            # Ghi nh·∫≠t k√Ω t·ª± nh·∫≠n th·ª©c
            # log_system_activity("LEARNED", f"{agent_name} ho√†n th√†nh 60p t·ª± nghi√™n c·ª©u.", "SCHEDULER")
            
            # Chuy·ªÉn sang ng∆∞·ªùi ti·∫øp theo
            CURRENT_LEARNER_INDEX = (CURRENT_LEARNER_INDEX + 1) % len(LEARNING_QUEUE)
        
        # Ngh·ªâ 1 ch√∫t tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu ca sau
        await asyncio.sleep(10)

# --- T√çCH H·ª¢P V√ÄO STARTUP ---
@app.on_event("startup")
async def start_scheduler():
    # Ch·∫°y loop n√†y ·ªü ch·∫ø ƒë·ªô n·ªÅn (kh√¥ng ch·∫∑n API)
    asyncio.create_task(adaptive_learning_scheduler())

# --- C·∫¨P NH·∫¨T TR·∫†NG TH√ÅI KHI C√ì L·ªÜNH ---
# Trong h√†m chat_endpoint, th√™m d√≤ng n√†y:
# global LAST_ACTIVITY_TIME, IS_BUSY
# LAST_ACTIVITY_TIME = datetime.now()
# IS_BUSY = True

@app.post("/api/learn")
async def api_learn(request: LearnRequest, x_api_key: str = Header(None)):
    if x_api_key != ADMIN_SECRET: raise HTTPException(403)
    if not AI_AVAILABLE: return {"status": "error", "message": "AI Offline"}
    
    res = learn_knowledge(request.text)
    return {"status": "success", "message": res}

@app.post("/api/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """API Upload PDF & T·ª± ƒë·ªông h·ªçc (Non-blocking)"""
    if not file.filename.lower().endswith('.pdf'):
        raise HTTPException(status_code=400, detail="Ch·ªâ ch·∫•p nh·∫≠n file .PDF")

    safe_filename = f"{uuid.uuid4().hex[:8]}_{file.filename}"
    file_path = os.path.join(UPLOAD_DIR, safe_filename)
    
    try:
        async with aiofiles.open(file_path, 'wb') as out_file:
            content = await file.read()
            await out_file.write(content)
            
        if AI_AVAILABLE:
            # QUAN TR·ªåNG: Ch·∫°y trong threadpool ƒë·ªÉ kh√¥ng treo server
            result = await run_in_threadpool(lambda: ingest_docs_to_memory(file_path))
            return {"status": "success", "message": result, "path": file_path}
            
        return {"status": "saved", "message": "Saved (AI Offline)"}
        
    except Exception as e:
        if os.path.exists(file_path): os.remove(file_path)
        raise HTTPException(status_code=500, detail=str(e))

# ==========================================
# 6. WEBSOCKET (REAL-TIME DASHBOARD)
# ==========================================
@app.websocket("/ws/nexus")
async def websocket_nexus(websocket: WebSocket):
    await manager.connect(websocket)
    
    # 1. T·∫†O SESSION ID RI√äNG BI·ªÜT (Fix l·ªói tr·ªôn l·∫´n k√Ω ·ª©c)
    session_id = f"ws_{uuid.uuid4().hex[:8]}"
    print(colored(f"üîå New Connection: {session_id}", "green"))
    
    try:
        # G·ª≠i l·ªùi ch√†o (D·∫°ng JSON cho Dashboard)
        await manager.send_json({
            "sender": "J.A.R.V.I.S",
            "content": "H·ªá th·ªëng tr·ª±c tuy·∫øn. ƒêang ƒë·ªìng b·ªô th·ªùi gian th·ª±c...",
            "agent": "System"
        }, websocket)
        
        while True:
            data = await websocket.receive_text()
            print(colored(f"‚ö° [INPUT]: {data}", "cyan"))
            
            # ============================================================
            # PH·∫¶N 1: KH√îI PH·ª§C C√ÅC T√çNH NƒÇNG C≈® (C·ª¶A NG√ÄI)
            # ============================================================
            
            # 1. L·∫§Y TH√îNG TIN H·ªÜ TH·ªêNG (Th·ªùi gian th·ª±c)
            current_time = datetime.now().strftime("%H:%M, Th·ª© %w, ng√†y %d/%m/%Y")
            system_context = f"Hi·ªán t·∫°i l√† {current_time}. V·ªã tr√≠: Phan Thi·∫øt, Vi·ªát Nam."
            
            # 2. H·ªíI T∆Ø·ªûNG K√ù ·ª®C
            mem_ctx = ""
            if MEMORY_AVAILABLE:
                mem_ctx = await run_in_threadpool(lambda: recall_relevant_memories(data))
                if mem_ctx: print(colored(f"üß† [K√ù ·ª®C]: {mem_ctx[:100]}...", "magenta"))

            # ============================================================
            # PH·∫¶N 2: X·ª¨ L√ù TH√îNG MINH (K·∫æT H·ª¢P LANGGRAPH)
            # ============================================================
            
            # T·∫°o Prompt ch·ª©a ƒë·∫ßy ƒë·ªß th√¥ng tin: Th·ªùi gian + K√Ω ·ª©c + C√¢u h·ªèi
            # ƒêi·ªÅu n√†y gi√∫p Agent (H·ªça sƒ©/Coder) c≈©ng bi·∫øt b√¢y gi·ªù l√† m·∫•y gi·ªù
            full_prompt = f"""
            [SYSTEM CONTEXT]: {system_context}
            [MEMORY]: {mem_ctx}
            [USER REQUEST]: {data}
            """
            
            reply_content = ""
            active_agent = "J.A.R.V.I.S"

            # A. FAST TRACK (Gi·ªØ l·∫°i logic c≈© cho c√°c c√¢u h·ªèi ƒë∆°n gi·∫£n ƒë·ªÉ ti·∫øt ki·ªám)
            # N·∫øu ch·ªâ h·ªèi ng√†y gi·ªù, gi√° c·∫£ -> D√πng Gemini/GPT tr·ª±c ti·∫øp cho nhanh
            fast_keywords = ["bao nhi√™u ng√†y", "t·∫øt", "th·ª© m·∫•y", "ng√†y m·∫•y", "m·∫•y gi·ªù", "th·ªùi ti·∫øt", "gi√°"]
            is_simple = any(k in data.lower() for k in fast_keywords) and not any(k in data.lower() for k in ["v·∫Ω", "code", "l·∫≠p tr√¨nh"])

            if is_simple and LLM_GEMINI:
                print(colored("üöÄ K√≠ch ho·∫°t Fast Track (Real-time Context)...", "yellow"))
                try:
                    # G·ªçi Gemini tr·∫£ l·ªùi nhanh c√¢u h·ªèi ng√†y gi·ªù
                    ai_msg = await LLM_GEMINI.ainvoke(full_prompt)
                    reply_content = ai_msg.content
                    active_agent = "J.A.R.V.I.S"
                except: pass
            
            # B. DEEP THINKING (N·∫øu Fast Track b·ªè qua HO·∫∂C l√† l·ªánh V·∫Ω/Code)
            if not reply_content and AI_AVAILABLE:
                # Truy·ªÅn session_id v√†o thread_id ƒë·ªÉ gi·ªØ m·∫°ch chuy·ªán ri√™ng bi·ªát
                config = {"configurable": {"thread_id": session_id}}
                # G·ªçi b·ªô n√£o LangGraph (Supervisor -> Designer/Coder...)
                print(colored("üß© Chuy·ªÉn giao cho B·ªô N√£o Trung T√¢m (LangGraph)...", "blue"))
                
                input_message = HumanMessage(content=full_prompt)
                final_state = await ai_app.ainvoke({"messages": [input_message]}, config=config)
                
                # L·∫•y k·∫øt qu·∫£ t·ª´ Agent cu·ªëi c√πng
                last_message = final_state['messages'][-1]
                reply_content = last_message.content
                
                # X√°c ƒë·ªãnh ai v·ª´a l√†m vi·ªác (ƒê·ªÉ Dashboard s√°ng ƒë√®n)
                active_agent = final_state.get("current_agent", "J.A.R.V.I.S")

            # ============================================================
            # PH·∫¶N 3: PH·∫¢N H·ªíI (D·∫†NG JSON CHO DASHBOARD)
            # ============================================================
            print(colored(f"ü§ñ [{active_agent}]: {reply_content}", "magenta"))
            
            # G·ª≠i JSON xu·ªëng Client
            await manager.send_json({
                "sender": active_agent,
                "content": reply_content,
                "agent": active_agent # Dashboard d√πng c√°i n√†y ƒë·ªÉ highlight icon
            }, websocket)
            
                        # 4. GHI NH·ªö L·∫†I
            if MEMORY_AVAILABLE:
                await run_in_threadpool(lambda: extract_and_save_memory(data, reply_content))

    except WebSocketDisconnect:
        manager.disconnect(websocket)
        print(colored(f"üîå Disconnected: {session_id}", "red"))
    except Exception as e:
        logger.error(f"WS Error: {e}")
        manager.disconnect(websocket)

# ==========================================
# üöÄ SYSTEM ROUTES
# ==========================================

@app.get("/health")
async def health_check():
    """
    Ki·ªÉm tra t√¨nh tr·∫°ng s·ª©c kh·ªèe to√†n di·ªán (Deep Health Check).
    """
    # 1. Ki·ªÉm tra k·∫øt n·ªëi Database (Th·ª±c t·∫ø)
    db_status = "UNKNOWN"
    try:
        # Th·ª≠ th·ª±c hi·ªán m·ªôt truy v·∫•n si√™u nh·∫π (SELECT 1)
        with db_manager.get_connection() as conn:
            conn.execute("SELECT 1")
            db_status = "CONNECTED (Active)"
    except Exception as e:
        db_status = f"CRITICAL ERROR: {str(e)}"
    
    # 2. Ki·ªÉm tra c√°c Module AI
    return {
        "status": "OPERATIONAL" if "ERROR" not in db_status else "DEGRADED",
        "timestamp": datetime.now().isoformat(),
        "version": "JARVIS v3.0",
        "chi_tiet_loi": AI_BOOT_ERROR if not AI_AVAILABLE else "Kh√¥ng c√≥ l·ªói",
        "modules": {
            "ai_brain": "ONLINE" if AI_AVAILABLE else "OFFLINE",
            "voice_core": "ONLINE" if VOICE_AVAILABLE else "OFFLINE",
            "memory_core": "ONLINE" if MEMORY_AVAILABLE else "OFFLINE",
            "knowledge_db": db_status, # Tr·∫°ng th√°i k·∫øt n·ªëi th·∫≠t
        }
    }

def get_latest_audit_report():
    """
    H√†m ƒë·ªçc b√°o c√°o m·ªõi nh·∫•t trong th∆∞ m·ª•c projects
    """
    try:
        # 1. Tr·ªè ƒë√∫ng v√†o th∆∞ m·ª•c 'projects'
        # T√¨m t·∫•t c·∫£ file .md (Bao g·ªìm c·∫£ Project_Audit v√† Morning_Briefing)
        search_path = os.path.join("projects", "*.md") 
        list_of_files = glob.glob(search_path)
        
        if not list_of_files:
            return "Th∆∞a CEO, kho d·ªØ li·ªáu (folder projects) hi·ªán ƒëang tr·ªëng. Ch∆∞a c√≥ b√°o c√°o n√†o ƒë∆∞·ª£c t·∫°o."
            
        # 2. T√¨m file m·ªõi nh·∫•t d·ª±a tr√™n th·ªùi gian t·∫°o (Create Time)
        latest_file = max(list_of_files, key=os.path.getctime)
        
        # L·∫•y t√™n file cho ƒë·∫πp
        filename = os.path.basename(latest_file)
        
        # 3. ƒê·ªçc n·ªôi dung
        with open(latest_file, "r", encoding="utf-8") as f:
            content = f.read()
            
        return f"### üìÇ H·ªí S∆† M·ªöI NH·∫§T: {filename}\n\n{content}"

    except Exception as e:
        logger.error(f"üö® [REPORT ERROR]: {str(e)}")
        return f"‚ö†Ô∏è Th∆∞a CEO, kh√¥ng th·ªÉ truy xu·∫•t h·ªì s∆°: {str(e)}."


# --- ENTRY POINT (CH·∫†Y SERVER) ---

if __name__ == "__main__":
    import uvicorn
    # S·ª≠ d·ª•ng bi·∫øn m√¥i tr∆∞·ªùng PORT ƒë·ªÉ t∆∞∆°ng th√≠ch Cloud Run sau n√†y
    port = int(os.environ.get("PORT", 8080))
    
    print("="*50)
    print(f"üöÄ J.A.R.V.I.S SYSTEM STARTING ON PORT {port}")
    print(f"üìÑ API Documentation: http://localhost:{port}/docs")
    print("="*50)
    
    # Reload=True gi√∫p server t·ª± kh·ªüi ƒë·ªông l·∫°i khi s·ª≠a code (Dev mode)
    uvicorn.run("server:app", host="0.0.0.0", port=port, reload=True)
