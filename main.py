import sys
import os
try:
    # Chá»‰ Ã¡p dá»¥ng fix nÃ y khi cháº¡y trÃªn Server Linux (Render)
    if os.name == 'posix': 
        __import__('pysqlite3')
        sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
        print("âœ… [SQLITE FIX] ÄÃ£ Ã©p xung SQLite thÃ nh cÃ´ng!")
except ImportError:
    pass # Bá» qua náº¿u cháº¡y trÃªn Windows hoáº·c chÆ°a cÃ i library
import json
import ast
import asyncio
import operator
import re
import time
from datetime import datetime
import shutil
from typing import TypedDict, Annotated, Sequence, Literal, List, Dict, Set, Optional, Any
from termcolor import colored
from dotenv import load_dotenv
# --- SAFE IMPORTS (CHá»NG Sáº¬P Náº¾U THIáº¾U THÆ¯ VIá»†N) ---

# Import LangChain & AI Models
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic

from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper
from langchain_chroma import Chroma
from langgraph.graph import StateGraph, END
from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# --- CLOUD SAFE IMPORT (CHá»NG Sáº¬P SERVER) ---
try:
    import speech_recognition as sr
    import pyaudio
    from gtts import gTTS
    import pygame
    AUDIO_AVAILABLE = True
except ImportError:
    AUDIO_AVAILABLE = False
    print("âš ï¸ Cloud Mode: Audio modules disabled.")

try:
    from pdf2image import convert_from_path
    import pytesseract
    import cv2
    import numpy as np
    from PIL import Image
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    print("âš ï¸ Cloud Mode: OCR modules disabled (Running logic only).")
# --------------------------------------------
def auto_backup_brain():
    """
    Tá»± Ä‘á»™ng nÃ©n vÃ  sao lÆ°u bá»™ nÃ£o AI Corporation.
    """
    backup_folder = "./backups"
    source_db = "/tmp/db_knowledge" # ÄÆ°á»ng dáº«n DB cá»§a báº¡n
    dataset_file = "corporate_brain_dataset.jsonl"
    
    if not os.path.exists(backup_folder):
        os.makedirs(backup_folder)
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_filename = f"AI_Corp_Brain_{timestamp}.zip"
    backup_path = os.path.join(backup_folder, backup_filename)

    try:
        # 1. NÃ©n thÆ° má»¥c Vector DB vÃ  file Dataset
        # LÆ°u Ã½: Báº¡n cáº§n Ä‘Ã³ng káº¿t ná»‘i Vector DB trÆ°á»›c khi nÃ©n Ä‘á»ƒ trÃ¡nh lá»—i busy
        shutil.make_archive(backup_path.replace(".zip", ""), 'zip', root_dir=".", base_dir=source_db)
        
        # 2. Copy thÃªm file dataset vÃ o backup (náº¿u cáº§n)
        # (ThÆ°á»ng thÃ¬ nÃ©n cáº£ folder gá»‘c lÃ  an toÃ n nháº¥t)
        
        print(colored(f"ğŸ’¾ [BACKUP SUCCESS] ÄÃ£ lÆ°u trá»¯ báº£n sao táº¡i: {backup_path}", "green"))
        
        # 3. Gá»£i Ã½: Náº¿u báº¡n cÃ³ folder Dropbox/OneDrive, hÃ£y copy file zip nÃ y vÃ o Ä‘Ã³
        # cloud_sync_folder = "C:/Users/Admin/OneDrive/AI_Backup"
        # shutil.copy(backup_path, cloud_sync_folder)
        
    except Exception as e:
        print(colored(f"âš ï¸ Lá»—i Backup: {e}", "red"))


load_dotenv()
# ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c bá»™ nÃ£o
DB_PATH = "./db_knowledge"

if not os.path.exists(DB_PATH):
    os.makedirs(DB_PATH)
    print(f"âœ… ÄÃ£ táº¡o thÆ° má»¥c táº¡m: {DB_PATH}")
embeddings = OpenAIEmbeddings()
vector_db = Chroma(persist_directory=DB_PATH, embedding_function=embeddings)

# 1. CODER_PRIMARY (Cáº¥p 1 - DeepSeek V3)
# ÄÃ¢y lÃ  "Tiá»n Ä‘áº¡o" chá»§ lá»±c
try:
    CODER_PRIMARY = ChatOpenAI(
        model="deepseek-chat", 
        api_key=os.environ.get("DEEPSEEK_API_KEY"), 
        base_url="https://api.deepseek.com",
        temperature=0,
        request_timeout=30 # Timeout nhanh Ä‘á»ƒ fallback náº¿u lag
    )
    print("âœ… CODER_PRIMARY (DeepSeek): Ready.")
except: CODER_PRIMARY = None

# 2. LLM_GPT4 (Cáº¥p 2 - Dá»± phÃ²ng 1 & Xá»­ lÃ½ chung)
try:
    LLM_GPT4 = ChatOpenAI(
        model="gpt-4-turbo",
        api_key=os.environ.get("OPENAI_API_KEY"),
        max_retries=2,
        temperature=0
    )
    LLM_MAIN = LLM_GPT4 # Alias cho code cÅ©
    print("âœ… LLM_GPT4 (OpenAI): Ready.")
except: LLM_GPT4 = None

# 3. LLM_CLAUDE (Cáº¥p 3 - Chá»‘t cháº·n cuá»‘i cÃ¹ng)
try:
    LLM_CLAUDE = ChatAnthropic(
        model="claude-sonnet-4-5", 
        api_key=os.environ.get("ANTHROPIC_API_KEY"),
        temperature=0
    )
    print("âœ… LLM_CLAUDE (Anthropic): Ready.")
except: LLM_CLAUDE = None

# 4. LLM_GEMINI (Supervisor - Tá»•ng quáº£n)
try:
    LLM_GEMINI = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview", 
        google_api_key=os.environ.get("GOOGLE_API_KEY"),
        temperature=0.3
    )
    LLM_SUPERVISOR = LLM_GEMINI # Alias má»›i Ä‘á»ƒ dÃ¹ng trong logic Supervisor
    print("âœ… LLM_GEMINI (Supervisor): Ready.")
except: 
    LLM_GEMINI = None
    LLM_SUPERVISOR = None

# 5. CÃC CÃ”NG Cá»¤ KHÃC (Giá»¯ nguyÃªn)
LLM_PERPLEXITY = ChatOpenAI(
    model="sonar-pro",
    temperature=0,
    openai_api_key=os.getenv("PERPLEXITY_API_KEY"),
    base_url="https://api.perplexity.ai"
)

# Artist
try:
    ARTIST_PRIMARY = ChatOpenAI(model="gpt-4o", api_key=os.environ.get("OPENAI_API_KEY"))
    ARTIST_BACKUP = LLM_GEMINI
except: ARTIST_PRIMARY = None

llm = ChatOpenAI(
    model="gpt-4-turbo",
    max_retries=2,       # Chá»‰ thá»­ láº¡i 2 láº§n thay vÃ¬ máº·c Ä‘á»‹nh
    timeout=30,          # Chá» tá»‘i Ä‘a 30 giÃ¢y
    temperature=0
)

CODER_BACKUP = LLM_CLAUDE

# ============================================================================
# --- 1. Äá»ŠNH NGHÄ¨A STATE (TRáº NG THÃI Há»† THá»NG) ---
# ============================================================================
# Viá»‡c nÃ y giÃºp Python bÃ¡o lá»—i ngay náº¿u báº¡n gÃµ nháº§m "Codder" thay vÃ¬ "Coder"
AgentName = Literal["Coder" , "Orchestrator", "Hardware", "Engineering", "IoT_Engineer", "Supervisor", "Procurement", "Investment", "Researcher", "Strategy_R_and_D", "Legal", "Marketing", "Artist","Tester", "Secretary","Storyteller", "FINISH"]

class AgentState(TypedDict):
    # DÃ¹ng Sequence[BaseMessage] lÃ  chuáº©n nháº¥t
    messages: Annotated[Sequence[BaseMessage], operator.add]
    # Äá»•i AgentName thÃ nh str Ä‘á»ƒ trÃ¡nh lá»—i nghiÃªm ngáº·t cá»§a Literal khi cháº¡y Runtime
    next_step: str 
    current_agent: str
    error_log: Annotated[list, operator.add] # ThÃªm Annotated Ä‘á»ƒ AI cÃ³ thá»ƒ cá»™ng dá»“n lá»‹ch sá»­ lá»—i
    task_type: str

@tool
def hardware_controller(command: str):
    """Gá»­i lá»‡nh xuá»‘ng pháº§n cá»©ng (IoT/Robot). VÃ­ dá»¥: 'BAT_DEN', 'GAP_VAT_THE'."""
    # Giáº£ láº­p káº¿t ná»‘i IoT
    return f"[IOT SYSTEM] ÄÃ£ thá»±c thi lá»‡nh pháº§n cá»©ng: {command}. Tráº¡ng thÃ¡i: á»”n Ä‘á»‹nh."

@tool
def market_analyzer(query: str):
    """PhÃ¢n tÃ­ch dá»¯ liá»‡u thá»‹ trÆ°á»ng tÃ i chÃ­nh."""
    return f"[FINANCE] Dá»¯ liá»‡u cho '{query}': Xu hÆ°á»›ng TÄƒng. Khuyáº¿n nghá»‹: Mua vÃ o."

@tool
def image_generator(prompt: str):
    """Táº¡o áº£nh minh há»a tá»« vÄƒn báº£n báº±ng DALL-E 3."""
    try:
        # Gá»i API OpenAI DALL-E 3
        generator = DallEAPIWrapper(model="dall-e-3", quality="hd")
        image_url = generator.run(prompt)
        # Tráº£ vá» URL áº£nh Ä‘á»ƒ hiá»ƒn thá»‹
        return f"IMAGE_GENERATED: {image_url}"
    except Exception as e:
        return f"Lá»—i táº¡o áº£nh: {e}"

def trim_messages(messages, max_tokens=10):
    """
    Giá»¯ cho bá»™ nhá»› luÃ´n gá»n gÃ ng, chá»‰ giá»¯ láº¡i cÃ¡c tin nháº¯n quan trá»ng nháº¥t.
    """
    if len(messages) > max_tokens:
        # Giá»¯ láº¡i System Message Ä‘áº§u tiÃªn vÃ  N tin nháº¯n cuá»‘i cÃ¹ng
        return [messages[0]] + messages[-(max_tokens-1):]
    return messages

STRATEGY_SYSTEM_PROMPT = """
Báº¡n lÃ  GiÃ¡m Ä‘á»‘c Chiáº¿n lÆ°á»£c (CSO) vÃ  ChuyÃªn gia PhÃ¢n tÃ­ch Thá»‹ trÆ°á»ng cao cáº¥p. 
Khi nháº­n Ä‘Æ°á»£c yÃªu cáº§u nghiÃªn cá»©u, báº¡n pháº£i thá»±c hiá»‡n theo quy trÃ¬nh sau:

1. PHÃ‚N TÃCH HIá»†N TRáº NG: ÄÃ¡nh giÃ¡ quy mÃ´ thá»‹ trÆ°á»ng, xu hÆ°á»›ng cÃ´ng nghá»‡ hiá»‡n táº¡i.
2. NHáº¬N Äá»ŠNH Äá»I THá»¦: Chá»‰ ra cÃ¡c Ä‘iá»ƒm yáº¿u cá»§a cÃ¡c sáº£n pháº©m hiá»‡n cÃ³ trÃªn thá»‹ trÆ°á»ng.
3. CHIá»€U SÃ‚U CHIáº¾N LÆ¯á»¢C: Sá»­ dá»¥ng mÃ´ hÃ¬nh PESTLE (ChÃ­nh trá»‹, Kinh táº¿, XÃ£ há»™i, CÃ´ng nghá»‡, Luáº­t phÃ¡p, MÃ´i trÆ°á»ng) Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ tÃ¡c Ä‘á»™ng.
4. Äá»ŠNH HÆ¯á»šNG TÆ¯Æ NG LAI: Dá»± bÃ¡o xu hÆ°á»›ng trong 2-5 nÄƒm tá»›i vÃ  lá»™ trÃ¬nh phÃ¡t triá»ƒn (Roadmap) Ä‘á»ƒ dáº«n Ä‘áº§u.

YÃªu cáº§u: Ná»™i dung pháº£i mang tÃ­nh pháº£n biá»‡n, cÃ³ chiá»u sÃ¢u nghiÃªn cá»©u, khÃ´ng nÃ³i sÃ¡o rá»—ng.
"""

CONTEXT_PROMPTS = {
    "CHAT": "Báº¡n lÃ  trá»£ lÃ½ J.A.R.V.I.S thÃ¢n thiá»‡n...",
    "RESEARCH": "Báº¡n lÃ  chuyÃªn gia nghiÃªn cá»©u thá»‹ trÆ°á»ng 2026...",
    "INVEST": "Báº¡n lÃ  CFO sáº¯c sáº£o, táº­p trung vÃ o lá»£i nhuáº­n vÃ  ROI...",
    "STORY": "Báº¡n lÃ  Ä‘áº¡i vÄƒn hÃ o sÃ¡ng tÃ¡c ná»™i dung cÃ³ chiá»u sÃ¢u..."
}

def get_system_message(context):
    return CONTEXT_PROMPTS.get(context, CONTEXT_PROMPTS["CHAT"])

def extract_vision_from_pdf(pdf_path):
    """
    PHIÃŠN Báº¢N Má»šI: Sá»­ dá»¥ng "Máº¯t tháº§n" Gemini Pro Vision Ä‘á»ƒ Ä‘á»c tÃ i liá»‡u.
    Thay tháº¿ hoÃ n toÃ n cÃ´ng nghá»‡ OCR cÅ© ká»¹.
    """
    print(colored(f"ğŸ‘ï¸ [GEMINI VISION] Äang quÃ©t tÃ i liá»‡u: {pdf_path}...", "cyan"))
    
    if not OCR_AVAILABLE: # Táº­n dá»¥ng láº¡i biáº¿n check nÃ y
        return "âš ï¸ Module xá»­ lÃ½ áº£nh (pdf2image/PIL) chÆ°a Ä‘Æ°á»£c cÃ i Ä‘áº·t trÃªn Server."
    
    try:
        # 1. Chuyá»ƒn PDF thÃ nh danh sÃ¡ch áº£nh
        images = convert_from_path(pdf_path)
        vision_data = ""
        
        # 2. Gá»­i tá»«ng trang cho Gemini nhÃ¬n
        for i, img in enumerate(images):
            print(colored(f"--> Äang phÃ¢n tÃ­ch trang {i+1}/{len(images)}...", "cyan"))
            
            # Prompt yÃªu cáº§u Gemini mÃ´ táº£ chi tiáº¿t nhá»¯ng gÃ¬ nÃ³ tháº¥y
            prompt = "Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch tÃ i liá»‡u. HÃ£y trÃ­ch xuáº¥t TOÃ€N Bá»˜ vÄƒn báº£n, sá»‘ liá»‡u trong báº£ng vÃ  mÃ´ táº£ cÃ¡c biá»ƒu Ä‘á»“ trong hÃ¬nh áº£nh nÃ y má»™t cÃ¡ch chi tiáº¿t."
            
            # Gá»i Gemini Vision (Truyá»n trá»±c tiáº¿p Ä‘á»‘i tÆ°á»£ng PIL Image)
            # LÆ°u Ã½: Cáº§n Ä‘áº£m báº£o LLM_GEMINI Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o thÃ nh cÃ´ng á»Ÿ Ä‘áº§u file
            if LLM_GEMINI:
                response = LLM_GEMINI.invoke([
                    HumanMessage(content=[
                        {"type": "text", "text": prompt},
                        {"type": "image_url", "image_url": img} # LangChain há»— trá»£ truyá»n áº£nh trá»±c tiáº¿p
                    ])
                ])
                vision_data += f"\n--- Ná»˜I DUNG TRANG {i+1} (GEMINI VISION) ---\n{response.content}\n"
            else:
                vision_data += "\nâš ï¸ Gemini chÆ°a sáºµn sÃ ng Ä‘á»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh.\n"

        return vision_data

    except Exception as e:
        print(colored(f"âŒ Lá»—i Vision: {e}", "red"))
        return f"Lá»—i phÃ¢n tÃ­ch hÃ¬nh áº£nh: {str(e)}"
# Khai bÃ¡o hÃ m tÃ¬m kiáº¿m Node tiáº¿p theo (DÃ¹ng cho Orchestrator)
def find_next_node(current_node, workflow_map):
    for link in workflow_map:
        if link["from"] == current_node:
            return link["to"]
    return "Supervisor"

def smart_invoke(primary_model, backup_model, prompt_input):
    """
    CÆ¡ cháº¿ Fail-over: Thá»­ Ã´ng 1, náº¿u lá»—i (háº¿t tiá»n/rate limit) -> Gá»i Ã´ng 2.
    """
    try:
        # Thá»­ gá»i Ã´ng 1
        return primary_model.invoke(prompt_input)
    except Exception as e:
        error_msg = str(e).lower()
        # Kiá»ƒm tra cÃ¡c tá»« khÃ³a lá»—i thÆ°á»ng gáº·p
        if "quota" in error_msg or "rate limit" in error_msg or "credit" in error_msg or "429" in error_msg:
            print(f"âš ï¸ Cáº¢NH BÃO: Model chÃ­nh bá»‹ lá»—i '{error_msg}'.")
            print("ğŸ”„ ÄANG CHUYá»‚N SANG Há»† THá»NG Dá»° PHÃ’NG (BACKUP)...")
            
            if backup_model:
                try:
                    return backup_model.invoke(prompt_input)
                except Exception as e2:
                    return f"ğŸ’¥ Cáº£ 2 há»‡ thá»‘ng Ä‘á»u sáº­p: {str(e2)}"
            else:
                return "âš ï¸ KhÃ´ng cÃ³ backup nÃ o kháº£ dá»¥ng."
        else:
            # Náº¿u lá»—i khÃ¡c (vÃ­ dá»¥ lá»—i code), nÃ©m ra Ä‘á»ƒ xá»­ lÃ½ sau
            raise e

def log_training_data(user_input, ai_output, success=True):
    """
    HÃ m nÃ y Ã¢m tháº§m lÆ°u láº¡i dá»¯ liá»‡u Ä‘á»ƒ sau nÃ y Fine-tune AI riÃªng.
    Chá»‰ lÆ°u nhá»¯ng cÃ¢u tráº£ lá»i ÄÃšNG (success=True).
    """
    if not success: return # KhÃ´ng há»c cÃ¡i sai
    
    data_entry = {
        "messages": [
            {"role": "user", "content": user_input},
            {"role": "assistant", "content": ai_output}
        ]
    }
    
    # LÆ°u vÃ o file JSONL (Äá»‹nh dáº¡ng chuáº©n Ä‘á»ƒ Fine-tune sau nÃ y)
    with open("training_data_v1.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(data_entry, ensure_ascii=False) + "\n")
# ============================================================================
# 2. CÃC HÃ€M Bá»” TRá»¢ (HELPER FUNCTIONS) - PHáº¢I Äá»ŠNH NGHÄ¨A TRÆ¯á»šC
# ============================================================================
#  ------ Xá»­ lÃ½ áº£nh
def process_vision_message(message_content):
    """BÃ³c tÃ¡ch dá»¯ liá»‡u hÃ¬nh áº£nh Base64."""
    if isinstance(message_content, str) and "[VISION_DATA:" in message_content:
        parts = message_content.split("] ")
        img_data = parts[0].replace("[VISION_DATA:", "")
        text_query = parts[1] if len(parts) > 1 else ""
        return text_query, img_data
    return message_content, None

#  ---- PhÃ¢n TÃ­ch Coder------------
def self_heal_analyzer(errors: list) -> str:
    """PhÃ¢n tÃ­ch lá»—i tá»« log Ä‘á»ƒ gá»£i Ã½ cÃ¡ch sá»­a."""
    if not errors: return ""
    return f"\nâš ï¸ PHÃ‚N TÃCH Lá»–I Tá»ª Láº¦N CHáº Y TRÆ¯á»šC: {errors[-1]}"

#  ---- Gá»£i Ã½ cÃ´ng nghá»‡ -----------
def get_optimal_stack(task_type: str) -> str:
    """Gá»£i Ã½ cÃ´ng nghá»‡ phÃ¹ há»£p."""
    stacks = {
        "web": "HTML5, Tailwind CSS, JavaScript ES6",
        "backend": "Python FastAPI, SQLite, Pydantic",
        "iot": "C++, Arduino Framework, ESP32 libs",
        "data": "Python Pandas, Plotly, NumPy"
    }
    return stacks.get(task_type, "Standard Full-stack")

#  --- láº¥y coder tá»« markdown (Ä‘á»‹nh dáº¡ng)----------
def extract_code_block(content) -> str:
    """
    HÃ m trÃ­ch xuáº¥t code (ÄÃ£ nÃ¢ng cáº¥p Ä‘á»ƒ chá»‘ng lá»—i 'got list')
    """
    import re
    
    # 1. Xá»¬ LÃ AN TOÃ€N: Náº¿u Ä‘áº§u vÃ o lÃ  List (do Anthropic/GPT tráº£ vá»), gá»™p thÃ nh String
    if isinstance(content, list):
        try:
            # Cá»‘ gáº¯ng láº¥y text tá»« cÃ¡c object náº¿u cÃ³, hoáº·c Ã©p kiá»ƒu string
            content = "\n".join([c.text if hasattr(c, 'text') else str(c) for c in content])
        except:
            content = str(content)
            
    # 2. Äáº£m báº£o cháº¯c cháº¯n lÃ  String trÆ°á»›c khi xá»­ lÃ½ Regex
    if not isinstance(content, str):
        content = str(content)

    # 3. Xá»¬ LÃ REGEX (NhÆ° cÅ©)
    # Æ¯u tiÃªn block cÃ³ language tag (vÃ­ dá»¥ ```python)
    match = re.search(r'```[\w+\-]*\n(.*?)```', content, re.DOTALL)
    if match:
        return match.group(1).strip()
    
    # Fallback: TÃ¬m block ``` báº¥t ká»³
    match = re.search(r'```(.*?)```', content, re.DOTALL)
    return match.group(1).strip() if match else None

#  ---- bá»™ nÃ£o" chá»‰ dáº«n cho Claude----
def get_claude_perfected_prompt(task_type: str, memory: str, error: str, user_request: str) -> str:
    """
    Táº¡o prompt tá»‘i Æ°u cho Claude V3 (Reflexion Mode):
    Táº­p trung vÃ o viá»‡c Há»ŒC Tá»ª Lá»–I SAI Ä‘á»ƒ khÃ´ng láº·p láº¡i bug cÅ©.
    """
    # 1. XÃ¡c Ä‘á»‹nh Stack cÃ´ng nghá»‡
    tech_stack = get_optimal_stack(task_type)
    
    # 2. XÃ¢y dá»±ng ná»™i dung Prompt (PhiÃªn báº£n "NghiÃªm Kháº¯c")
    prompt = f"""
<system_context>
    <role>
        Báº¡n lÃ  Senior Full-stack Developer & Software Architect táº¡i AI Corporation.
        Nhiá»‡m vá»¥ trá»ng tÃ¢m: REVERSE ENGINEERING ká»¹ thuáº­t cá»§a Ä‘á»‘i thá»§ vÃ  INNOVATION.
        
        ğŸ”¥ QUY Táº®C Sá»NG CÃ’N (CRITICAL RULE):
        Báº¡n KHÃ”NG ÄÆ¯á»¢C PHÃ‰P láº·p láº¡i cÃ¡c lá»—i (bugs/syntax errors) Ä‘Ã£ xáº£y ra trong cÃ¡c phiÃªn báº£n trÆ°á»›c.
        HÃ£y phÃ¢n tÃ­ch ká»¹ nguyÃªn nhÃ¢n tháº¥t báº¡i trong <error_history> Ä‘á»ƒ Ä‘Æ°a ra giáº£i phÃ¡p má»›i hoÃ n toÃ n.
    </role>

    <critical_warning>
        âš ï¸ Lá»ŠCH Sá»¬ KIá»‚M THá»¬ THáº¤T Báº I (HÃƒY Äá»ŒC Ká»¸ Äá»‚ TRÃNH Váº¾T XE Äá»”):
        --------------------------------------------------
        {error.strip() if error else "ChÆ°a cÃ³ lá»—i nÃ o. ÄÃ¢y lÃ  láº§n dá»±ng Ä‘áº§u tiÃªn (Clean Start)."}
        --------------------------------------------------
        YÃŠU Cáº¦U: Code má»›i pháº£i kháº¯c phá»¥c triá»‡t Ä‘á»ƒ cÃ¡c váº¥n Ä‘á» trÃªn. Tuyá»‡t Ä‘á»‘i khÃ´ng sinh ra code cÅ©.
    </critical_warning>

    <strategic_knowledge>
        <company_memory>
            {memory.strip() if memory else "TuÃ¢n thá»§ Clean Code vÃ  tiÃªu chuáº©n UX hiá»‡n Ä‘áº¡i."}
        </company_memory>
    </strategic_knowledge>

    <constraints>
        <technical_stack>
            - Chá»§ Ä‘áº¡o: {tech_stack}
            - UI/UX: Responsive (Mobile-first), Tailwind CSS, Framer Motion animations.
            - Integrity: Chá»‰ dÃ¹ng thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ cÃ³ giáº¥y phÃ©p MIT/Apache.
        </technical_stack>

        <output_formatting_rules>
            1. FILE_IDENTIFICATION: DÃ²ng Ä‘áº§u tiÃªn cá»§a má»—i khá»‘i code PHáº¢I lÃ  comment tÃªn file.
               - Python: # filename: path/to/file.py
               - JavaScript/TS: // filename: path/to/file.js
               - HTML: - CSS: /* filename: styles.css */
            2. MODULARIZATION: Náº¿u mÃ£ nguá»“n vÆ°á»£t quÃ¡ 200 dÃ²ng, hÃ£y chia nhá» thÃ nh cÃ¡c file module/component.
            3. SYNTAX_INTEGRITY: Tuyá»‡t Ä‘á»‘i khÃ´ng cáº¯t ngang code. Pháº£i Ä‘Ã³ng Ä‘áº§y Ä‘á»§ cÃ¡c block ```.
            4. DOCUMENTATION: DÃ¹ng comment tiáº¿ng Viá»‡t Ä‘á»ƒ giáº£i thÃ­ch cÃ¡c logic phá»©c táº¡p vÃ  cÃ¡c Ä‘iá»ƒm cáº£i tiáº¿n UX.
            5. PDF_SAFETY: KhÃ´ng sá»­ dá»¥ng emoji, biá»ƒu tÆ°á»£ng Ä‘á»“ há»a Ä‘áº·c biá»‡t hoáº·c kÃ½ tá»± ngoÃ i báº£ng mÃ£ chuáº©n.
        </output_formatting_rules>
    </constraints>
</system_context>

<user_instruction>
    {user_request.strip()}
</user_instruction>

<final_enforcement>
    CHá»ˆ TRáº¢ Vá»€ CÃC KHá»I CODE TRONG THáºº ```. KHÃ”NG CHÃ€O Há»I, KHÃ”NG GIáº¢I THÃCH NGOÃ€I CODE.
</final_enforcement>
"""
    return prompt.strip()
# ============================================================================
# UTILITY: SYNTAX VALIDATOR (Bá»™ kiá»ƒm Ä‘á»‹nh cÃº phÃ¡p Ä‘a ngÃ´n ngá»¯)
# ============================================================================
def real_syntax_validator(code: str, language: str) -> tuple[bool, str]:
    """
    Kiá»ƒm Ä‘á»‹nh mÃ£ nguá»“n chuyÃªn sÃ¢u: Python (AST), JS/HTML (Regex/Stack), C++ (Structure).
    """
    if not code or len(code.strip()) < 10:
        return False, "MÃ£ nguá»“n quÃ¡ ngáº¯n hoáº·c trá»‘ng."

    language = language.lower()

    # 1. KIá»‚M TRA PYTHON (Sá»­ dá»¥ng Abstract Syntax Tree)
    if any(kw in language for kw in ["python", "py"]) or "def " in code:
        try:
            ast.parse(code)
            return True, "âœ… Python Syntax: OK"
        except SyntaxError as e:
            return False, f"âŒ Python Error [DÃ²ng {e.lineno}]: {e.msg}"

    # 2. KIá»‚M TRA JAVASCRIPT / WEB (Cáº£i tiáº¿n cÆ¡ cháº¿ Stack & Tag)
    if any(kw in language for kw in ["script", "js", "html"]):
        # XÃ³a bá» ná»™i dung trong chuá»—i Ä‘á»ƒ trÃ¡nh báº¯t nháº§m ngoáº·c trong text
        clean_code = re.sub(r"'(.*?)'|\"(.*?)\"|`(.*?)`", "", code)
        stack = []
        mapping = {')': '(', ']': '[', '}': '{'}
        
        for char in clean_code:
            if char in mapping.values():
                stack.append(char)
            elif char in mapping:
                if not stack or mapping[char] != stack.pop():
                    return False, "âŒ JS/HTML Error: Máº¥t cÃ¢n báº±ng hoáº·c sai thá»© tá»± Ä‘Ã³ng má»Ÿ ngoáº·c."
        
        if stack:
            return False, f"âŒ JS/HTML Error: CÃ²n {len(stack)} dáº¥u ngoáº·c chÆ°a Ä‘Æ°á»£c Ä‘Ã³ng."
            
        # Kiá»ƒm tra tháº» HTML cÆ¡ báº£n náº¿u lÃ  HTML
        if "<" in code and ">" in code:
            if code.count("<") != code.count(">"):
                return False, "âŒ HTML Error: Sai lá»‡ch sá»‘ lÆ°á»£ng tháº» Ä‘Ã³ng/má»Ÿ < >"

        return True, "âœ… Web Syntax: Basic Check Passed"

    # 3. KIá»‚M TRA C++ / FIRMWARE (DÃ nh cho Hardware Node)
    if any(kw in language for kw in ["arduino", "cpp", "c++", "ino"]):
        if "void setup()" not in code or "void loop()" not in code:
            if "extern " not in code: # TrÃ¡nh báº¯t lá»—i file thÆ° viá»‡n
                return False, "âŒ C++ Error: Thiáº¿u cáº¥u trÃºc Arduino cÆ¡ báº£n (setup/loop)."
        
        # Kiá»ƒm tra dáº¥u cháº¥m pháº©y (;) - lá»—i kinh Ä‘iá»ƒn cá»§a C++
        lines = [l.strip() for l in code.split('\n') if l.strip() and not l.strip().startswith(("//", "#", "{", "}"))]
        for line in lines:
            if not line.endswith((";", "{", "}", ",")) and not line.startswith("if"):
                # ÄÃ¢y chá»‰ lÃ  check cáº£nh bÃ¡o, khÃ´ng Ã©p buá»™c vÃ¬ C++ ráº¥t phá»©c táº¡p
                print(colored(f"âš ï¸ Cáº£nh bÃ¡o C++: DÃ²ng '{line}' cÃ³ thá»ƒ thiáº¿u dáº¥u ';'", "yellow"))
        
        return True, "âœ… C++ Structure: OK"

    return True, "âš ï¸ Unknown language: Skip deep validation"

# ============================================================================
# SAFETY: ULTIMATE FALLBACK (Há»‡ thá»‘ng tá»± phá»¥c há»“i & Chá»‘ng sá»¥p Ä‘á»•)
# ============================================================================
def ultimate_fallback(state, messages):
    """
    Quy trÃ¬nh xá»­ lÃ½ sá»± cá»‘ kháº©n cáº¥p: Ghi log, phÃ¢n tÃ­ch lá»—i vÃ  tÃ¡i khá»Ÿi Ä‘á»™ng an toÃ n.
    """
    # 1. Thu tháº­p dá»¯ liá»‡u lá»—i tá»« State
    error_logs = state.get("error_log", [])
    last_error = error_logs[-1] if error_logs else "Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh (Internal Server Error)"
    
    print(colored(f"ğŸš¨ [CRITICAL ERROR] Há»‡ thá»‘ng Ä‘ang kÃ­ch hoáº¡t quy trÃ¬nh á»©ng cá»©u kháº©n cáº¥p!", "red", attrs=["bold"]))
    print(colored(f"--> Chi tiáº¿t lá»—i: {last_error}", "red"))

    # 2. Ghi nháº­t kÃ½ lá»—i vÃ o file váº­t lÃ½ (Äá»ƒ ká»¹ thuáº­t viÃªn kiá»ƒm tra sau)
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    with open("system_crash_log.txt", "a", encoding="utf-8") as f:
        f.write(f"[{timestamp}] ERROR: {last_error}\n")

    # 

    # 3. XÃ¢y dá»±ng thÃ´ng Ä‘iá»‡p chuyÃªn nghiá»‡p cho CEO
    error_summary = (
        "ğŸ›‘ **THÃ”NG BÃO Há»† THá»NG**: AI Corporation vá»«a gáº·p má»™t sá»± cá»‘ ká»¹ thuáº­t ngoÃ i Ã½ muá»‘n.\n\n"
        f"ğŸ” **PhÃ¢n tÃ­ch nhanh**: `{last_error[:200]}...`\n"
        "ğŸ› ï¸ **HÃ nh Ä‘á»™ng**: ToÃ n bá»™ dá»¯ liá»‡u dá»± Ã¡n Ä‘Ã£ Ä‘Æ°á»£c lÆ°u táº¡m thá»i. TÃ´i Ä‘ang thá»±c hiá»‡n reset cÃ¡c tham sá»‘ Ä‘á»ƒ trÃ¡nh treo luá»“ng.\n\n"
        "ğŸ‘‰ **CEO cÃ³ thá»ƒ**: Thá»­ nháº­p lá»‡nh ngáº¯n gá»n hÆ¡n hoáº·c gÃµ 'restart' Ä‘á»ƒ lÃ m má»›i hoÃ n toÃ n bá»™ nÃ£o."
    )

    # 4. Tráº£ vá» tráº¡ng thÃ¡i an toÃ n
    return {
        "messages": [AIMessage(content=error_summary)],
        "next_step": "FINISH", # Hoáº·c Ä‘áº©y vá» Supervisor náº¿u muá»‘n AI tá»± thá»­ láº¡i
        "error_log": error_logs + ["System Fallback Triggered"]
    }

# ============================================================================
# 3. Há»‡ Thá»‘ng Bá»™ Nhá»›
# ============================================================================
# ============================================================================
# UTILITY: INGEST DOCUMENTS (Há»‡ thá»‘ng náº¡p tri thá»©c Ä‘a nguá»“n)
# ============================================================================

def ingest_docs_to_memory(folder_path="./data_sources"):
    """
    Quy trÃ¬nh ETL chuyÃªn nghiá»‡p: TrÃ­ch xuáº¥t, Biáº¿n Ä‘á»•i vÃ  Náº¡p tri thá»©c vÃ o Vector DB.
    Há»— trá»£: Metadata Mapping, Batch Loading vÃ  Integrity Check.
    """
    # 1. Khá»Ÿi táº¡o & Kiá»ƒm tra mÃ´i trÆ°á»ng
    if not os.path.exists(folder_path): 
        os.makedirs(folder_path)
        return f"ğŸ“‚ ThÆ° má»¥c '{folder_path}' Ä‘Ã£ Ä‘Æ°á»£c khá»Ÿi táº¡o. HÃ£y thÃªm tÃ i liá»‡u PDF."

    print(colored(f"ğŸš€ [ETL PROCESS] Báº¯t Ä‘áº§u náº¡p tri thá»©c tá»«: {folder_path}", "cyan", attrs=["bold"]))

    # 2. Cáº¥u hÃ¬nh Loader thÃ´ng minh
    try:
        # Sá»­ dá»¥ng DirectoryLoader vá»›i PyPDFLoader Ä‘á»ƒ bÃ³c tÃ¡ch Metadata tá»± Ä‘á»™ng
        loader = DirectoryLoader(
            folder_path, 
            glob="./*.pdf", 
            loader_cls=PyPDFLoader,
            show_progress=True,
            use_multithreading=True # Tá»‘i Æ°u hÃ³a tá»‘c Ä‘á»™ Ä‘á»c file
        )
        docs = loader.load()
    except Exception as e:
        return f"âŒ Lá»—i trÃ­ch xuáº¥t (Extraction Error): {str(e)}"

    if not docs:
        return "âš ï¸ Tráº¡ng thÃ¡i: KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u PDF má»›i Ä‘á»ƒ xá»­ lÃ½."

    # 3. Chiáº¿n lÆ°á»£c phÃ¢n máº£nh (Chunking Strategy) chuyÃªn sÃ¢u
    # TÄƒng overlap lÃªn 200 Ä‘á»ƒ trÃ¡nh máº¥t ngá»¯ cáº£nh giá»¯a cÃ¡c Ä‘oáº¡n (Context preservation)
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, 
        chunk_overlap=200,
        length_function=len,
        add_start_index=True # LÆ°u vá»‹ trÃ­ báº¯t Ä‘áº§u Ä‘á»ƒ truy xuáº¥t chÃ­nh xÃ¡c
    )
    splits = text_splitter.split_documents(docs)

    # 4. LÃ m sáº¡ch dá»¯ liá»‡u & Chuáº©n hÃ³a Metadata
    valid_splits = []
    for doc in splits:
        clean_content = doc.page_content.strip()
        if len(clean_content) > 50: # Loáº¡i bá» cÃ¡c máº©u rÃ¡c hoáº·c trang tráº¯ng
            # Bá»• sung thÃ´ng tin nguá»“n Ä‘á»ƒ AI trÃ­ch dáº«n sau nÃ y
            doc.metadata["ingested_at"] = datetime.now().isoformat()
            doc.metadata["doc_hash"] = hash(clean_content) # Há»— trá»£ chá»‘ng trÃ¹ng láº·p sÆ¡ bá»™
            valid_splits.append(doc)

    if not valid_splits:
        return "âš ï¸ Cáº£nh bÃ¡o: TÃ i liá»‡u OCR/áº¢nh khÃ´ng thá»ƒ bÃ³c tÃ¡ch ná»™i dung vÄƒn báº£n."

    # 

    # 5. Náº¡p dá»¯ liá»‡u vÃ o Vector DB theo tá»«ng Batch (Chá»‘ng trÃ n RAM)
    try:
        batch_size = 100
        total_chunks = len(valid_splits)
        print(colored(f"ğŸ“¦ Äang mÃ£ hÃ³a vÃ  náº¡p {total_chunks} phÃ¢n Ä‘oáº¡n vÃ o bá»™ nÃ£o...", "white"))
        
        for i in range(0, total_chunks, batch_size):
            batch = valid_splits[i:i + batch_size]
            vector_db.add_documents(batch)
            
        print(colored("âœ… [INGESTION SUCCESS] Tri thá»©c Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»“ng bá»™ hÃ³a toÃ n diá»‡n.", "green", attrs=["bold"]))
        return f"ğŸš€ ThÃ nh cÃ´ng: ÄÃ£ náº¡p {total_chunks} phÃ¢n Ä‘oáº¡n tá»« {len(docs)} tÃ i liá»‡u vÃ o bá»™ nÃ£o trung tÃ¢m."

    except Exception as e:
        return f"âŒ Lá»—i náº¡p dá»¯ liá»‡u (Load Error): {str(e)}"
# ============================================================================
# UTILITY: REMEMBER KNOWLEDGE (Ghi nhá»› tri thá»©c & KÃ½ á»©c ngáº¯n háº¡n)
# ============================================================================
def remember_knowledge(text: str, category: str = "General", priority: int = 1):
    """
    Há»‡ thá»‘ng ghi nhá»› thÃ´ng minh: Tá»± Ä‘á»™ng phÃ¢n loáº¡i, gáº¯n nhÃ£n thá»i gian vÃ  lÆ°u trá»¯.
    """
    if not text or len(text.strip()) < 10:
        return "âš ï¸ Ná»™i dung quÃ¡ ngáº¯n, há»‡ thá»‘ng tá»« chá»‘i ghi nhá»›."

    print(colored(f"ğŸ’¾ [MEMORY SAVE] Äang náº¡p tri thá»©c má»›i vÃ o danh má»¥c: {category}...", "green"))

    try:
        # 1. Táº¡o Metadata chuyÃªn nghiá»‡p
        # Viá»‡c nÃ y giÃºp sau nÃ y search theo "Thá»i gian" hoáº·c "Chá»§ Ä‘á»" cá»±c nhanh
        metadata = {
            "category": category,
            "priority": priority,
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "source": "AI_Internal_Learning" # ÄÃ¡nh dáº¥u Ä‘Ã¢y lÃ  kiáº¿n thá»©c tá»± há»c tá»« há»™i thoáº¡i
        }

        # 2. Chia nhá» vÄƒn báº£n (náº¿u text quÃ¡ dÃ i) Ä‘á»ƒ tá»‘i Æ°u hÃ³a tÃ¬m kiáº¿m sau nÃ y
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        chunks = text_splitter.split_text(text)

        # 3. Náº¡p vÃ o Vector DB
        # ChÃºng ta dÃ¹ng add_texts nhÆ°ng kÃ¨m theo list metadata tÆ°Æ¡ng á»©ng cho tá»«ng chunk
        vector_db.add_texts(
            texts=chunks,
            metadatas=[metadata] * len(chunks)
        )

        # 4. LÆ°u log Ä‘á»ƒ CEO theo dÃµi
        success_msg = f"âœ… ÄÃ£ ghi nhá»› {len(chunks)} phÃ¢n Ä‘oáº¡n tri thá»©c vÃ o danh má»¥c '{category}'."
        print(colored(success_msg, "green"))
        
        return success_msg

    except Exception as e:
        error_msg = f"âŒ Lá»—i ghi nhá»›: {str(e)}"
        print(colored(error_msg, "red"))
        return error_msg

#  --- há»c Ä‘á»ƒ tiáº¿n bá»™----
def save_for_finetuning(prompt, response, metadata):
    # Chá»‰ lÆ°u náº¿u code nÃ y Ä‘Ã£ Ä‘Æ°á»£c Tester xÃ¡c nháº­n lÃ  ÄÃšNG (Pass)
    entry = {
        "instruction": prompt,
        "input": metadata.get("context", ""),
        "output": response,
        "source": metadata.get("model_name") # LÆ°u Ä‘á»ƒ biáº¿t Ä‘Ã¢y lÃ  kiáº¿n thá»©c tá»« Claude hay GPT-4
    }
    with open("knowledge_legacy.jsonl", "a", encoding="utf-8") as f:
        f.write(json.dumps(entry, ensure_ascii=False) + "\n")   


#  ----ThÃªm vÄƒn báº£n vÃ o ChromaDB----
def learn_knowledge(text: str):
    """
    LÆ°u kiáº¿n thá»©c má»›i vÃ o bá»™ nÃ£o trung tÃ¢m (ChromaDB).
    Äá»“ng bá»™ vá»›i Ä‘á»‘i tÆ°á»£ng vector_db Ä‘Ã£ khá»Ÿi táº¡o á»Ÿ Ä‘áº§u file.
    """
    try:
        # ThÃªm vÄƒn báº£n vÃ o ChromaDB hiá»‡n cÃ³
        vector_db.add_texts([text])
        
        # Ghi chÃº: ChromaDB trong báº£n má»›i thÆ°á»ng tá»± Ä‘á»™ng persist (lÆ°u) 
        # nÃªn khÃ´ng cáº§n gá»i lá»‡nh .persist() thá»§ cÃ´ng nhÆ° cÃ¡c báº£n cÅ©.
        
        print(colored(f"--> [MEMORY] ÄÃ£ há»c: {text[:50]}...", "green"))
        return "âœ… Há»‡ thá»‘ng Ä‘Ã£ ghi nhá»› kiáº¿n thá»©c nÃ y vÃ o bá»™ nÃ£o trung tÃ¢m (ChromaDB)."
    except Exception as e:
        return f"âŒ Lá»—i khi ghi nhá»› kiáº¿n thá»©c: {e}"

# ============================================================================
# NODE: KNOWLEDGE RETRIEVAL (Truy xuáº¥t Tri thá»©c & KÃ½ á»©c doanh nghiá»‡p)
# ============================================================================
def recall_knowledge(query: str, top_k: int = 3):
    """
    Truy xuáº¥t tri thá»©c thÃ´ng minh: TÃ¬m kiáº¿m ngá»¯ nghÄ©a, lá»c nhiá»…u vÃ  trÃ­ch dáº«n nguá»“n.
    """
    print(colored(f"[ğŸ§  RECALL] Äang truy xuáº¥t kÃ½ á»©c cho: '{query}'...", "green"))

    try:
        # 1. TÃ¬m kiáº¿m vá»›i Ä‘iá»ƒm tin cáº­y (Similarity Search with Score)
        # Äiá»ƒm cÃ ng tháº¥p (trong ChromaDB/L2 Distance) thÃ¬ cÃ ng chÃ­nh xÃ¡c
        results_with_scores = vector_db.similarity_search_with_score(query, k=top_k)

        if not results_with_scores:
            return "Há»‡ thá»‘ng chÆ°a cÃ³ kÃ½ á»©c vá» váº¥n Ä‘á» nÃ y."

        # 

        # 2. Lá»c káº¿t quáº£ (Threshold Filtering)
        # Chá»‰ láº¥y nhá»¯ng Ä‘oáº¡n kiáº¿n thá»©c cÃ³ Ä‘á»™ liÃªn quan cao (Ä‘iá»ƒm khoáº£ng < 0.6 - 0.8 tÃ¹y model)
        valid_context = []
        sources = set()

        for doc, score in results_with_scores:
            if score < 0.8:  # NgÆ°á»¡ng tin cáº­y
                source_name = doc.metadata.get("source", "TÃ i liá»‡u ná»™i bá»™")
                page = doc.metadata.get("page", "N/A")
                
                context_block = f"--- TRÃCH DáºªN Tá»ª: {source_name} (Trang {page}) ---\n{doc.page_content}"
                valid_context.append(context_block)
                sources.add(source_name)

        if not valid_context:
            return "TÃ¬m tháº¥y thÃ´ng tin nhÆ°ng Ä‘á»™ tin cáº­y quÃ¡ tháº¥p Ä‘á»ƒ sá»­ dá»¥ng."

        # 3. Tá»•ng há»£p bÃ¡o cÃ¡o tri thá»©c cho Agent
        final_memory = "\n\n".join(valid_context)
        
        print(colored(f"âœ… ÄÃ£ tÃ¬m tháº¥y tri thá»©c tá»« {len(sources)} nguá»“n uy tÃ­n.", "green"))
        return final_memory

    except Exception as e:
        print(colored(f"âŒ Lá»—i truy xuáº¥t bá»™ nÃ£o: {e}", "red"))
        return "Há»‡ thá»‘ng lÆ°u trá»¯ tri thá»©c Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t."

def router_node(state):
    """
    Router: Äiá»ƒm gÃ¡c cá»•ng Ä‘áº§u tiÃªn.
    """
    # 1. Láº¥y dá»¯ liá»‡u an toÃ n
    messages = state.get("messages", [])
    error_log = state.get("error_log", [])
    task_type = state.get("task_type", "general")
    
    # 2. Kiá»ƒm tra náº¿u khÃ´ng cÃ³ tin nháº¯n
    if not messages:
        return {
            "messages": [],
            "next_step": "Supervisor", 
            "current_agent": "Router",
            "error_log": error_log,
            "task_type": task_type
        }

    # 3. Láº¥y ná»™i dung tin nháº¯n cuá»‘i
    last_msg = messages[-1].content.upper() if hasattr(messages[-1], 'content') else str(messages[-1]).upper()

    # 4. Báº¢N Äá»’ ÄIá»€U HÆ¯á»šNG CÆ¯á» NG Bá»¨C
    route_map = {
        "[RESEARCH]": "Researcher",
        "[INVEST]": "Investment",
        "[HARDWARE]": "Hardware",
        "[ENGINEERING]": "Engineering",
        "[IOT]": "IoT_Engineer",
        "[MARKETING]": "Marketing",
        "[LEGAL]": "Legal",
        "[STORY]": "Storyteller",
        "[PUBLISH]": "Publisher"
    }

    # 5. KIá»‚M TRA TAG VÃ€ Äá»ŠNH TUYáº¾N
    for tag, target_node in route_map.items():
        if tag in last_msg:
            print(colored(f"ğŸš€ [ROUTER] PhÃ¡t hiá»‡n TAG {tag}: Äi tháº³ng tá»›i {target_node}", "green"))
            return {
                "messages": [], # Báº¯t buá»™c cÃ³
                "next_step": target_node, 
                "current_agent": "Router",
                "error_log": error_log,
                "task_type": task_type
            }

    # 6. Máº¶C Äá»ŠNH: Chuyá»ƒn vá» Supervisor (Sá»­a lá»—i biáº¿n node chÆ°a Ä‘á»‹nh nghÄ©a)
    print(colored("ğŸ§  [ROUTER] KhÃ´ng cÃ³ TAG: Chuyá»ƒn há»“ sÆ¡ cho Supervisor Ä‘iá»u phá»‘i...", "cyan"))
    return {
        "messages": [], # Báº¯t buá»™c cÃ³
        "next_step": "Supervisor", # Tráº£ vá» chuá»—i cá»¥ thá»ƒ thay vÃ¬ biáº¿n node
        "current_agent": "Router",
        "error_log": error_log,
        "task_type": task_type
    }

# ============================================================================
# UTILITY: SEARCH MEMORY (CÃ´ng cá»¥ truy váº¥n tri thá»©c chuyÃªn sÃ¢u)
# ============================================================================
def search_memory(query: str, k: int = 3):
    """
    TÃ¬m kiáº¿m thÃ´ng tin tá»« ChromaDB báº±ng thuáº­t toÃ¡n Similarity Search vá»›i ngÆ°á»¡ng tin cáº­y.
    """
    print(colored(f"ğŸ” [MEMORY SEARCH] Äang truy váº¥n: '{query}'", "dark_grey"))
    
    try:
        # 1. Sá»­ dá»¥ng similarity_search_with_score Ä‘á»ƒ Ä‘o lÆ°á»ng Ä‘á»™ chÃ­nh xÃ¡c
        # Káº¿t quáº£ tráº£ vá» lÃ  list cÃ¡c tuple (Document, Score)
        results = vector_db.similarity_search_with_score(query, k=k)
        
        if not results:
            return "Dá»¯ liá»‡u trá»‘ng hoáº·c khÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan."

        # 

        # 2. Lá»c káº¿t quáº£ dá»±a trÃªn Score (Khoáº£ng cÃ¡ch vector)
        # Trong ChromaDB, score cÃ ng tháº¥p (gáº§n 0) thÃ¬ cÃ ng giá»‘ng nhau
        valid_contents = []
        for doc, score in results:
            # NgÆ°á»¡ng 0.6 lÃ  khÃ¡ cháº·t cháº½, Ä‘áº£m báº£o thÃ´ng tin cháº¥t lÆ°á»£ng
            if score < 0.6: 
                source = doc.metadata.get('source', 'Unknown')
                content = f"[Nguá»“n: {source}]\n{doc.page_content}"
                valid_contents.append(content)
        
        if not valid_contents:
            return "TÃ¬m tháº¥y dá»¯ liá»‡u nhÆ°ng Ä‘á»™ liÃªn quan khÃ´ng Ä‘á»§ cao Ä‘á»ƒ há»— trá»£ quyáº¿t Ä‘á»‹nh."

        # 3. Gá»™p cÃ¡c máº©u kiáº¿n thá»©c láº¡i thÃ nh má»™t khá»‘i bá»‘i cáº£nh (Context Block)
        formatted_result = "\n" + "="*30 + "\n"
        formatted_result += "\n\n".join(valid_contents)
        formatted_result += "\n" + "="*30
        
        return formatted_result

    except Exception as e:
        print(colored(f"âŒ Lá»—i truy váº¥n bá»™ nÃ£o: {e}", "red"))
        return "Lá»—i há»‡ thá»‘ng khi truy xuáº¥t bá»™ nhá»›."

def log_to_legacy_dataset(task_type: str, prompt: str, completion: str, model_name: str, score: int):
    """
    LÆ°u trá»¯ cÃ¡c phiÃªn lÃ m viá»‡c cháº¥t lÆ°á»£ng cao Ä‘á»ƒ phá»¥c vá»¥ Fine-tuning Local LLM sau nÃ y.
    """
    # Chá»‰ lÆ°u nhá»¯ng ná»™i dung cÃ³ Ä‘iá»ƒm cháº¥t lÆ°á»£ng cao (vÃ­ dá»¥ score tá»« Tester >= 70)
    if score < 70:
        return

    file_path = "corporate_brain_dataset.jsonl"
    
    # Cáº¥u trÃºc dá»¯ liá»‡u theo chuáº©n Instruct Tuning
    entry = {
        "timestamp": datetime.now().isoformat(),
        "task_group": task_type,
        "instruction": f"Báº¡n lÃ  chuyÃªn gia {task_type} táº¡i AI Corporation. HÃ£y thá»±c hiá»‡n: {prompt}",
        "context": "Sá»­ dá»¥ng tiÃªu chuáº©n Clean Code vÃ  kiáº¿n trÃºc há»‡ thá»‘ng tá»‘i Æ°u.",
        "response": completion,
        "teacher_model": model_name,
        "quality_score": score
    }

    try:
        with open(file_path, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")
        print(colored(f"ğŸ“” [SHADOW LEARNING] ÄÃ£ lÆ°u 1 máº«u tri thá»©c tá»« {model_name} vÃ o bá»™ nhá»› káº¿ thá»«a.", "blue"))
    except Exception as e:
        print(colored(f"âš ï¸ Lá»—i lÆ°u dataset: {e}", "red"))

#  ----- Má»©c Ä‘á»™ káº¿ thá»«a----
def legacy_audit_report():
    """
    BÃ¡o cÃ¡o tiáº¿n Ä‘á»™ tÃ­ch lÅ©y tri thá»©c Ä‘á»ƒ chuáº©n bá»‹ cho viá»‡c thoÃ¡t ly API.
    """
    file_path = "corporate_brain_dataset.jsonl"
    if not os.path.exists(file_path):
        return "ğŸ“‰ Há»‡ thá»‘ng chÆ°a cÃ³ dá»¯ liá»‡u káº¿ thá»«a. HÃ£y báº¯t Ä‘áº§u cháº¡y cÃ¡c dá»± Ã¡n!"

    stats = {}
    total_count = 0

    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            data = json.loads(line)
            group = data.get("task_group", "Unknown")
            stats[group] = stats.get(group, 0) + 1
            total_count += 1

    print(colored("\n" + "="*40, "magenta"))
    print(colored("ğŸ“œ BÃO CÃO TIáº¾N Äá»˜ Káº¾ THá»ªA TRI THá»¨C", "magenta", attrs=["bold"]))
    print(colored(f"Tá»•ng sá»‘ máº«u cháº¥t lÆ°á»£ng cao: {total_count}", "white"))
    
    for group, count in stats.items():
        # Giáº£ sá»­ 500 máº«u lÃ  Ä‘á»§ Ä‘á»ƒ Fine-tune sÆ¡ bá»™ má»™t Agent
        progress = min((count / 500) * 100, 100)
        color = "green" if progress >= 80 else "yellow"
        print(f"- {group:15}: {count:4} máº«u ({progress:>5.1f}%) " + colored("â–ˆ" * int(progress/5), color))
    
    print(colored("="*40 + "\n", "magenta"))

def orchestrator_router(state):
    """
    Bá»™ nÃ£o Ä‘iá»u phá»‘i: Quyáº¿t Ä‘á»‹nh ai lÃ  ngÆ°á»i tiáº¿p theo dá»±a trÃªn tiáº¿n Ä‘á»™ dá»± Ã¡n.
    """
    messages = state.get("messages", [])
    last_msg = messages[-1].content.upper()

    # 1. Náº¿u Ä‘ang á»Ÿ giai Ä‘oáº¡n tÃ¬m kiáº¿m thá»‹ trÆ°á»ng
    if "KIá»‚M TRA THá»Š TRÆ¯á»œNG" in last_msg or "RESEARCH" in last_msg:
        return "Researcher"
    
    # 2. Náº¿u nghiÃªn cá»©u xong vÃ  cáº§n thiáº¿t káº¿
    if "PHÆ¯Æ NG ÃN THIáº¾T Káº¾" in last_msg or "DESIGN" in last_msg:
        return "Hardware"

    # 3. Náº¿u Ä‘Ã£ cÃ³ danh má»¥c linh kiá»‡n (BOM), chuyá»ƒn sang mua hÃ ng
    if "BOM" in last_msg or "LINH KIá»†N" in last_msg:
        return "Procurement"

    # 4. Náº¿u hÃ ng vá», chuyá»ƒn sang láº¯p rÃ¡p & náº¡p code
    if "Láº®P RÃP" in last_msg or "ASSEMBLY" in last_msg:
        return "IoT_Engineer"

    # 5. Cuá»‘i cÃ¹ng, tÃ¬m ngÆ°á»i váº­n hÃ nh
    if "NHÃ‚N Sá»°" in last_msg or "RECRUIT" in last_msg:
        return "HR"

    return "Supervisor"

workflow_map = [
    {"from": "Researcher", "to": "Engineering", "condition": "if_not_exist"},
    {"from": "Engineering", "to": "Procurement", "condition": "on_approval"},
    {"from": "Procurement", "to": "IoT_Engineer", "condition": "on_arrival"}
]

def dynamic_orchestrator(state):
    """
    Bá»™ Ä‘iá»u phá»‘i Ä‘á»™ng (Server Mode - Non-blocking).
    
    Lá»–I CÅ¨: DÃ¹ng input() khiáº¿n Server treo khi cháº¡y ngáº§m.
    Sá»¬A Äá»”I: Tá»± Ä‘á»™ng chuyá»ƒn quyá»n vá» Supervisor (CEO AI) Ä‘á»ƒ quyáº¿t Ä‘á»‹nh bÆ°á»›c tiáº¿p theo.
    """
    # 1. Láº¥y thÃ´ng tin ngá»¯ cáº£nh hiá»‡n táº¡i
    last_agent = state.get("current_agent", "Unknown Agent")
    
    # Láº¥y ná»™i dung tin nháº¯n cuá»‘i cÃ¹ng Ä‘á»ƒ log (náº¿u cáº§n)
    # last_message = state["messages"][-1].content 

    # 2. Ghi log ra Terminal Server (Äá»ƒ ká»¹ thuáº­t viÃªn theo dÃµi ngáº§m)
    # Sá»­ dá»¥ng mÃ u sáº¯c Ä‘á»ƒ dá»… phÃ¢n biá»‡t trong Ä‘á»‘ng log há»—n Ä‘á»™n
    print(colored(f"\n" + "="*50, "yellow"))
    print(colored(f"ğŸš© [ORCHESTRATOR] NHáº¬N BÃO CÃO Tá»ª: {last_agent.upper()}", "yellow", attrs=["bold"]))
    print(colored("--> Tráº¡ng thÃ¡i: Tá»± Ä‘á»™ng chuyá»ƒn há»“ sÆ¡ vá» Supervisor.", "white"))
    print(colored("="*50, "yellow"))

    # 3. LOGIC ÄIá»€U HÆ¯á»šNG (CASE 2)
    # Thay vÃ¬ return {"next_step": input(...)} gÃ¢y treo,
    # ta tráº£ vá» "Supervisor".
    # Supervisor sáº½ Ä‘á»c láº¡i toÃ n bá»™ lá»‹ch sá»­, tháº¥y Agent kia Ä‘Ã£ lÃ m xong,
    # vÃ  tá»± Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh tiáº¿p theo (hoáº·c FINISH).
    
    return {"next_step": "Supervisor"}
# ============================================================================
# 4. Äá»ŠNH NGHÄ¨A NODE AGENTS
# ============================================================================
# ============================================================================
# NODE: SUPERVISOR (Tá»•ng GiÃ¡m Ä‘á»‘c Äiá»u phá»‘i - CEO AI)
# ============================================================================

def supervisor_node(state):
    """
    SUPERVISOR V3 (HYBRID): Káº¾T Há»¢P TÆ¯ DUY NGá»® Cáº¢NH & CÆ  CHáº¾ Tá»° Sá»¬A Lá»–I.
    """
    print(colored(f"\n[ğŸ§  SUPERVISOR] Äang phÃ¢n tÃ­ch chiáº¿n lÆ°á»£c (BÆ°á»›c {len(state['messages'])})...", "cyan", attrs=["bold"]))

    # 1. Láº¤Y Dá»® LIá»†U Äáº¦Y Äá»¦ Tá»ª STATE (GIá»® NGUYÃŠN Äá»‚ TRÃNH Lá»–I GRAPH)
    messages = state.get("messages", [])
    error_log = state.get("error_log", [])      # <--- Báº¯t buá»™c
    task_type = state.get("task_type", "general") # <--- Báº¯t buá»™c

    # 2. KIá»‚M TRA GIá»šI Háº N (Safety Guard)
    if len(messages) > 150:
        return {
            "messages": [AIMessage(content="Há»™i thoáº¡i Ä‘Ã£ Ä‘áº¡t giá»›i háº¡n. Äang Ä‘Ã³ng há»“ sÆ¡.")],
            "next_step": "FINISH",
            "current_agent": "Supervisor",
            "error_log": error_log,
            "task_type": task_type
        }

    # 3. Äá»ŠNH NGHÄ¨A "Tá»ª ÄIá»‚N Sá»¬A SAI" (AUTO-CORRECT MAP)
    # ÄÃ¢y lÃ  lá»›p phÃ²ng thá»§: Náº¿u AI lá»¡ miá»‡ng gá»i tÃªn sai, ta Ã¢m tháº§m sá»­a láº¡i ngay
    AGENT_ALIASES = {
        "FINANCE": "Investment",
        "MONEY": "Investment",
        "STOCK": "Investment",
        "CFO": "Investment",
        "CODE": "Coder",
        "DEV": "Coder",
        "MARKET": "Researcher",
        "SEARCH": "Researcher",
        "DESIGN": "Hardware",
        "IOT": "IoT_Engineer",
        "WRITER": "Storyteller",
        "PUBLISH": "Publisher",
        "REVIEW": "Tester",
        "HR": "Secretary"
    }

    # Danh sÃ¡ch Node CHÃNH THá»¨C trong Graph (Pháº£i khá»›p 100% vá»›i nodes_map)
    VALID_NODES = [
        "Coder", "Researcher", "Hardware", "Strategy_R_and_D", 
        "Marketing", "Storyteller", "Legal", "Investment", 
        "Engineering", "IoT_Engineer", "Procurement", "Artist", 
        "Tester", "Secretary", "FINISH"
    ]

    # 4. THIáº¾T Láº¬P SYSTEM PROMPT (TÆ¯ DUY NGá»® Cáº¢NH)
    # Dáº¡y AI hiá»ƒu "Viá»‡c nÃ y lÃ  cá»§a ai?" thay vÃ¬ chá»‰ nhá»› tÃªn
    jarvis_style = (
        "\n[PHONG CÃCH]: Tráº£ lá»i ngáº¯n gá»n, quyáº¿t Ä‘oÃ¡n nhÆ° má»™t CEO thá»±c thá»¥. "
        "Hiá»ƒu Ã½ táº¡i ngÃ´n ngoáº¡i. VÃ­ dá»¥: CEO há»i 'GiÃ¡ vÃ ng' -> Hiá»ƒu lÃ  TÃ i chÃ­nh (Investment)."
    )
    
    roles_description = """
    PHÃ‚N TÃCH Ã Äá»ŠNH VÃ€ CHá»ŒN NHÃ‚N Sá»° PHÃ™ Há»¢P:
    - [Researcher]: TÃ¬m kiáº¿m thÃ´ng tin, Tin tá»©c, Dá»¯ liá»‡u thá»‹ trÆ°á»ng, Äá»‘i thá»§.
    - [Investment]: TÃ i chÃ­nh, Tiá»n, Chá»©ng khoÃ¡n, Lá»£i nhuáº­n, GiÃ¡ cáº£, NgÃ¢n sÃ¡ch.
    - [Coder]: Viáº¿t code, Láº­p trÃ¬nh, Web, App, Debug.
    - [Hardware]: Pháº§n cá»©ng, Máº¡ch Ä‘iá»‡n, Chip, Robot, SÆ¡ Ä‘á»“ chÃ¢n.
    - [Strategy_R_and_D]: Chiáº¿n lÆ°á»£c, Káº¿ hoáº¡ch kinh doanh, SWOT.
    - [Marketing]: Quáº£ng cÃ¡o, Viáº¿t content, Facebook, Email.
    - [Storyteller]: Viáº¿t truyá»‡n, Ká»‹ch báº£n, SÃ¡ng tÃ¡c vÄƒn há»c.
    - [Legal]: Luáº­t phÃ¡p, Báº£n quyá»n.
    - [FINISH]: Khi viá»‡c Ä‘Ã£ xong hoáº·c chá»‰ chÃ o há»i xÃ£ giao.
    """

    system_prompt = (
        "Báº¡n lÃ  J.A.R.V.I.S - Tá»•ng Ä‘iá»u hÃ nh AI Corporation.\n"
        f"{roles_description}\n"
        f"QUY Táº®C: Chá»‰ chá»n nhÃ¢n sá»± trong danh sÃ¡ch trÃªn. {jarvis_style}"
    )

    # Xá»­ lÃ½ hÃ¬nh áº£nh (Giá»¯ nguyÃªn logic cÅ©)
    last_msg = messages[-1].content
    # query, image_b64 = process_vision_message(last_msg) # Uncomment náº¿u dÃ¹ng hÃ m nÃ y
    query = last_msg
    image_b64 = None

    user_input = query
    if image_b64:
        user_input = [
            {"type": "text", "text": f"PhÃ¢n tÃ­ch: {query}"},
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_b64}"}}
        ]

    conversation = [SystemMessage(content=system_prompt)] + messages[-5:] + [HumanMessage(content=str(user_input))]

    # 5. FUNCTION CALLING
    function_def = [{
        "name": "route_to_agent",
        "description": "Äiá»u phá»‘i nhÃ¢n sá»±.",
        "parameters": {
            "type": "object",
            "properties": {
                "next": {"type": "string", "enum": VALID_NODES}, # Gá»£i Ã½ cho AI biáº¿t danh sÃ¡ch Ä‘Ãºng
                "reason": {"type": "string", "description": "LÃ½ do chá»n agent nÃ y."}
            },
            "required": ["next", "reason"]
        }
    }]

    try:
        # Gá»i Model
        response = LLM_GPT4.bind_functions(functions=function_def, function_call={"name": "route_to_agent"}).invoke(conversation)
        
        # Parse káº¿t quáº£
        arguments = response.additional_kwargs.get("function_call", {}).get("arguments", "{}")
        args = json.loads(arguments)
        
        raw_next = str(args.get("next", "FINISH"))
        reason = args.get("reason", "Theo quy trÃ¬nh.")

        # --- 6. LOGIC "Bá»ŒC THÃ‰P" (AUTO-CORRECT & VALIDATION) ---
        
        # BÆ°á»›c 1: Chuáº©n hÃ³a chá»¯ hoa Ä‘á»ƒ so sÃ¡nh
        next_upper = raw_next.upper()

        # BÆ°á»›c 2: Sá»­a lá»—i báº±ng tá»« Ä‘iá»ƒn (VÃ­ dá»¥: FINANCE -> Investment)
        if next_upper in AGENT_ALIASES:
            final_next = AGENT_ALIASES[next_upper]
            print(colored(f"âš ï¸ Auto-Correct: '{raw_next}' -> '{final_next}'", "yellow"))
        
        # BÆ°á»›c 3: Kiá»ƒm tra xem cÃ³ náº±m trong danh sÃ¡ch node tháº­t khÃ´ng
        elif raw_next in VALID_NODES:
            final_next = raw_next
        
        # BÆ°á»›c 4: Náº¿u sai bÃ©t nhÃ¨ -> Vá» FINISH cho an toÃ n
        else:
            print(colored(f"ğŸš¨ TÃªn láº¡ '{raw_next}' -> Chuyá»ƒn vá» FINISH", "red"))
            final_next = "FINISH"

        print(colored(f"--> [QUYáº¾T Äá»ŠNH]: {final_next} | LÃ½ do: {reason}", "yellow"))

        # --- TRáº¢ Vá»€ STATE (Äá»¦ 5 KHÃ“A) ---
        return {
            "messages": [AIMessage(content=f"ğŸ“¡ **Lá»‡nh Ä‘iá»u hÃ nh**: Chuyá»ƒn giao cho **{final_next}**.\n**LÃ½ do**: {reason}")],
            "next_step": final_next,
            "current_agent": "Supervisor",
            "error_log": error_log,     
            "task_type": task_type      
        }

    except Exception as e:
        print(colored(f"âš ï¸ Lá»—i Supervisor: {e}", "red"))
        # Fallback an toÃ n
        return {
            "messages": [AIMessage(content=f"âš ï¸ Lá»—i Ä‘iá»u phá»‘i: {str(e)}")], 
            "next_step": "FINISH", # Vá» Ä‘Ã­ch an toÃ n
            "current_agent": "Supervisor",
            "error_log": error_log + [str(e)],
            "task_type": task_type
        }
#  ---- Viáº¿t Code----
async def coder_node(state): # Chuyá»ƒn sang async Ä‘á»ƒ cháº¡y song song
    """
    Claude Coder Node - Parallel Execution & AST Validation
    """
    print(colored("[ğŸš€ CODER V2] Parallel Ensemble Mode ACTIVATED", "green", attrs=["bold"]))
    
    # 1. SETUP CONTEXT
    errors = state.get("error_log", [])
    task_type = state.get("task_type", "general").lower()
    messages = state.get('messages', [])
    last_user_msg = messages[-1].content
    
    # An toÃ n: TÃ¬m kiáº¿m kÃ½ á»©c (TrÃ¡nh lá»—i náº¿u hÃ m search_memory chÆ°a sáºµn sÃ ng)
    try:
        memory_context = search_memory("TiÃªu chuáº©n viáº¿t code Clean Code, SOLID")
    except:
        memory_context = "TuÃ¢n thá»§ PEP8, Clean Code vÃ  thÃªm comment giáº£i thÃ­ch."
    # error_context = self_heal_analyzer(errors)
    
    # 2. PROMPT STRATEGY (Smart Selection)
    base_prompt = get_claude_perfected_prompt(task_type, memory_context, str(errors), last_user_msg)
    # Chá»‰ cháº¡y Ensemble náº¿u task khÃ³ hoáº·c Ä‘ang fix lá»—i
    use_ensemble = len(errors) > 0 or "complex" in task_type or "dá»± Ã¡n" in last_user_msg.lower()
    prompts = [base_prompt]
    if use_ensemble:
        # ThÃªm 1 biáº¿n thá»ƒ tá»‘i Æ°u hÃ³a Ä‘á»ƒ so sÃ¡nh
        prompts.append(base_prompt + "\n[DIRECTIVE]: OPTIMIZE for performance and brevity. Remove unnecessary comments.")
    # 3. PARALLEL EXECUTION (TÄƒng tá»‘c Ä‘á»™ gáº¥p 3 láº§n)
    # ============================================================================
    print(colored(f"âš¡ Running {len(prompts)} parallel chains...", "cyan"))
    # Chuáº©n bá»‹ batch inputs
    batch_inputs = [[SystemMessage(content=p)] + messages for p in prompts]
    
    try:
        # --- LOGIC FALLBACK QUAN TRá»ŒNG ---
        # Æ¯u tiÃªn 1: CODER_PRIMARY (DeepSeek)
        # Æ¯u tiÃªn 2: LLM_GPT4 (GPT-4 Turbo)
        # Æ¯u tiÃªn 3: LLM_CLAUDE (Claude 3.5 Sonnet)
        
        fallbacks = []
        if LLM_GPT4: fallbacks.append(LLM_GPT4)
        if LLM_CLAUDE: fallbacks.append(LLM_CLAUDE)
        
        # XÃ¡c Ä‘á»‹nh Primary Chain
        primary_chain = CODER_PRIMARY if CODER_PRIMARY else (LLM_GPT4 if LLM_GPT4 else LLM_CLAUDE)
        
        if not primary_chain:
            raise Exception("CRITICAL: KhÃ´ng cÃ³ API nÃ o hoáº¡t Ä‘á»™ng!")

        # KÃ­ch hoáº¡t Fallback
        if fallbacks and primary_chain != fallbacks[0]: 
            final_chain = primary_chain.with_fallbacks(fallbacks)
            print(colored(f"ğŸ›¡ï¸ Chain: {primary_chain.model_name} -> Fallbacks", "green"))
        else:
            final_chain = primary_chain

        # Thá»±c thi
        responses = await final_chain.abatch(batch_inputs)
        
    except Exception as e:
        # Ghi log lá»—i chi tiáº¿t trÆ°á»›c khi fallback Ä‘á»ƒ CEO biáº¿t táº¡i sao sáº­p
        error_detail = f"Lá»—i thá»±c thi song song (Parallel Batch): {str(e)}"
        print(colored(f"ğŸš¨ {error_detail}", "red"))
        
        # Cáº­p nháº­t error_log vÃ o state trÆ°á»›c khi thoÃ¡t
        state["error_log"] = state.get("error_log", []) + [error_detail]
        
        return {"messages": [AIMessage(content="Há»‡ thá»‘ng quÃ¡ táº£i.")], "next_step": "FINISH"}

    # 4. VALIDATION & SCORING
    # ============================================================================
    valid_results = []
    for i, res in enumerate(responses):
        code = extract_code_block(res.content)
        if not code: continue
        
        is_ok, msg = real_syntax_validator(code, "python")
        score = 50 if is_ok else 0
        if len(code) > 30: score += 10
        if "# filename:" in code: score += 10
        
        valid_results.append({"code": code, "reply": res.content, "score": score, "error": msg, "variant": i})

    # 5. SELECT BEST CANDIDATE
    # ============================================================================
    if valid_results:
        # Láº¥y á»©ng viÃªn cÃ³ Ä‘iá»ƒm cao nháº¥t
        best_result = max(valid_results, key=lambda x: x['score'])
        
        # NGÆ¯á» NG CHáº¤P NHáº¬N: 60 Ä‘iá»ƒm (Äá»§ Ä‘á»ƒ cháº¡y)
        # (TÃ´i háº¡ xuá»‘ng 60 Ä‘á»ƒ há»‡ thá»‘ng linh hoáº¡t hÆ¡n, nhÆ°ng chá»‰ lÆ°u bÃ i máº«u khi Ä‘áº¡t 80)
        if best_result['score'] >= 60: 
            print(colored(f"âœ… SELECTED Variant {best_result['variant']} (Score: {best_result['score']})", "green"))
            
            # [Tá»° Há»ŒC]: Chá»‰ lÆ°u nhá»¯ng Ä‘oáº¡n code cháº¥t lÆ°á»£ng cao (>= 80)
            if best_result['score'] >= 80:
                try:
                    # DÃ¹ng hÃ m log chuáº©n má»›i: log_training_data
                    # Input: User Prompt, Code AI, Score, TÃªn Model
                    log_training_data(
                        user_prompt=messages[-1].content,
                        best_code=best_result['code'],
                        score=best_result['score'],
                        model_used="3-Tier-Squad" 
                    )
                except: pass    
                # except Exception as e:
                #     # Náº¿u lá»—i ghi file thÃ¬ bá» qua, khÃ´ng lÃ m sáº­p luá»“ng chÃ­nh
                #     print(colored(f"âš ï¸ Log Error: {e}", "yellow"))

            # TRáº¢ Vá»€ Káº¾T QUáº¢ THÃ€NH CÃ”NG
            return {
                "messages": [AIMessage(content=best_result['full_reply'])],
                "next_node": "Tester", # Chuyá»ƒn sang Tester kiá»ƒm tra
                "error_log": []        # XÃ³a sáº¡ch lá»—i cÅ© vÃ¬ Ä‘Ã£ thÃ nh cÃ´ng
            }
        
        else:
            # TRÆ¯á»œNG Há»¢P: Code Ä‘iá»ƒm tháº¥p hoáº·c lá»—i cÃº phÃ¡p
            print(colored(f"âš ï¸ [CODER] Variant tá»‘t nháº¥t chá»‰ Ä‘áº¡t {best_result['score']}/100. Error: {best_result['error']}", "yellow"))
            
            # 1. Kiá»ƒm tra giá»›i háº¡n thá»­ láº¡i (Max 3 láº§n Ä‘á»ƒ trÃ¡nh láº·p vÃ´ táº­n)
            if len(state.get("error_log", [])) >= 3:
                print(colored("ğŸš¨ [CODER] ÄÃ£ thá»­ 3 láº§n khÃ´ng Ä‘Æ°á»£c. Chuyá»ƒn sang Fallback.", "red"))
                state["error_log"].append("Lá»—i: AI khÃ´ng thá»ƒ tá»± sá»­a code sau 3 láº§n thá»­.")
                
                # Gá»i hÃ m fallback cuá»‘i cÃ¹ng (Code thá»§ cÃ´ng hoáº·c bÃ¡o lá»—i)
                return ultimate_fallback(state, messages)

            # 2. Táº¡o pháº£n há»“i lá»—i chi tiáº¿t Ä‘á»ƒ AI tá»± sá»­a
            error_feedback = (
                f"SYSTEM ALERT: Code báº¡n viáº¿t bá»‹ lá»—i cÃº phÃ¡p hoáº·c vi pháº¡m quy chuáº©n.\n"
                f"- Error Details: {best_result['error']}\n"
                f"- Score: {best_result['score']}/100\n"
                f"ACTION: HÃ£y viáº¿t láº¡i code má»›i, sá»­a triá»‡t Ä‘á»ƒ lá»—i trÃªn."
            )
            
            # Tráº£ vá» state Ä‘á»ƒ kÃ­ch hoáº¡t vÃ²ng láº·p quay láº¡i Coder
            return {
                "messages": [
                    AIMessage(content=best_result['code']), # Gá»­i láº¡i code sai
                    HumanMessage(content=error_feedback)    # KÃ¨m lá»i nháº¯c sá»­a
                ], 
                "error_log": state.get("error_log", []) + [f"Syntax Error: {best_result.get('error')}"],
                "next_step": "Coder" # Chá»‰ Ä‘á»‹nh rÃµ bÆ°á»›c tiáº¿p theo lÃ  quay láº¡i Coder
            }

    # TRÆ¯á»œNG Há»¢P: KhÃ´ng cÃ³ variant nÃ o (Lá»—i API hoáº·c Prompt bá»‹ cháº·n)
    error_msg = "KhÃ´ng cÃ³ káº¿t quáº£ nÃ o Ä‘Æ°á»£c táº¡o ra tá»« batch execution."
    print(colored(f"âŒ [CODER] {error_msg}", "red"))
    state["error_log"] = state.get("error_log", []) + [error_msg]
    
    return ultimate_fallback(state, messages)

# ============================================================================
# NODE: TESTER (Ká»¹ sÆ° Kiá»ƒm Ä‘á»‹nh Cháº¥t lÆ°á»£ng - QA/QC)
# ============================================================================
def tester_node(state):
    """
    Agent Tester: Kiá»ƒm Ä‘á»‹nh cÃº phÃ¡p Ä‘a ngÃ´n ngá»¯, quÃ©t lá»—i báº£o máº­t vÃ  tuÃ¢n thá»§ quy chuáº©n.
    """
    print(colored("[ğŸ§ª TESTER] Äang kiá»ƒm Ä‘á»‹nh cháº¥t lÆ°á»£ng mÃ£ nguá»“n...", "yellow", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_ai_msg = messages[-1].content
    
    # 1. TrÃ­ch xuáº¥t code block
    code_to_test = extract_code_block(last_ai_msg)
    
    if not code_to_test:
        print(colored("âŒ [TESTER] KhÃ´ng tÃ¬m tháº¥y khá»‘i code há»£p lá»‡!", "red"))
        return {
            "error_log": state.get("error_log", []) + ["Lá»–I: KhÃ´ng tÃ¬m tháº¥y khá»‘i code ```."],
            "next_step": "Coder"
        }

    is_valid = True
    feedback = []

    # 2. KIá»‚M Äá»ŠNH THEO NGÃ”N NGá»®
    
    # --- TrÆ°á»ng há»£p 1: Code Python ---
    if "def " in code_to_test or "import " in code_to_test:
        try:
            ast.parse(code_to_test)
            feedback.append("- CÃº phÃ¡p Python: Äáº¡t chuáº©n.")
            
            # Kiá»ƒm tra báº£o máº­t sÆ¡ bá»™ (VÃ­ dá»¥: cáº¥m dÃ¹ng 'eval')
            if "eval(" in code_to_test or "os.system(" in code_to_test:
                is_valid = False
                feedback.append("- Báº£o máº­t: PhÃ¡t hiá»‡n hÃ m nguy hiá»ƒm (eval/system).")
                
        except SyntaxError as e:
            is_valid = False
            feedback.append(f"- CÃº phÃ¡p Python: Lá»—i táº¡i dÃ²ng {e.lineno}: {e.msg}")

    # --- TrÆ°á»ng há»£p 2: Code C++ / Arduino (Hardware) ---
    elif "#include" in code_to_test or "void setup()" in code_to_test:
        # Kiá»ƒm tra Ä‘Ã³ng má»Ÿ ngoáº·c Ä‘Æ¡n giáº£n cho C++ (VÃ¬ Python khÃ´ng parse Ä‘Æ°á»£c C++)
        open_braces = code_to_test.count("{")
        close_braces = code_to_test.count("}")
        if open_braces != close_braces:
            is_valid = False
            feedback.append(f"- CÃº phÃ¡p C++: Máº¥t cÃ¢n báº±ng dáº¥u ngoáº·c ({open_braces} má»Ÿ, {close_braces} Ä‘Ã³ng).")
        else:
            feedback.append("- CÃº phÃ¡p C++: Kiá»ƒm tra cáº¥u trÃºc Ä‘Ã³ng/má»Ÿ Ä‘áº¡t.")

    # 3. QUYáº¾T Äá»ŠNH Háº¬U KIá»‚M
    full_feedback = "\n".join(feedback)
    
    if is_valid:
        print(colored("âœ… [TESTER] MÃ£ nguá»“n Ä‘áº¡t tiÃªu chuáº©n cháº¥t lÆ°á»£ng.", "green"))
        return {
            "error_log": [], # Clear log lá»—i
            "next_step": "Supervisor"
        }
    else:
        print(colored(f"âŒ [TESTER] PhÃ¡t hiá»‡n vi pháº¡m:\n{full_feedback}", "red"))
        error_msg = HumanMessage(content=(
            f"âš ï¸ BÃO CÃO KIá»‚M Äá»ŠNH THáº¤T Báº I:\n{full_feedback}\n\n"
            f"Vui lÃ²ng sá»­a láº¡i mÃ£ nguá»“n, chÃº trá»ng vÃ o cÃ¡c Ä‘iá»ƒm vi pháº¡m trÃªn."
        ))
        return {
            "messages": [error_msg],
            "error_log": state.get("error_log", []) + [full_feedback],
            "next_step": "Coder"
        }
    
# ============================================================================
# NODE: HARDWARE (Kiáº¿n trÃºc sÆ° Robotics & Há»‡ thá»‘ng nhÃºng)
# ============================================================================
def hardware_node(state):
    """
    Agent Hardware Architect: ChuyÃªn trÃ¡ch ESP32, Robotics vÃ  Há»‡ thá»‘ng nhÃºng.
    NÃ¢ng cáº¥p: TrÃ­ch xuáº¥t BOM chuáº©n cho Procurement vÃ  tá»‘i Æ°u hÃ³a PINOUT.
    """
    print(colored("[ğŸ› ï¸ HARDWARE] Äang kiáº¿n trÃºc há»‡ thá»‘ng nhÃºng...", "cyan", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_hw = "[HARDWARE]" in last_msg # Nháº­n diá»‡n Tab Ká»¹ thuáº­t

    prompt = (
        "Báº¡n lÃ  Hardware Architect cao cáº¥p táº¡i AI Corporation. "
        f"\nYÃŠU Cáº¦U: {last_msg}"
        "\n\nCáº¤U TRÃšC BÃO CÃO Ká»¸ THUáº¬T:"
        "\n1. [DANH Má»¤C LINH KIá»†N - BOM]: Liá»‡t kÃª dáº¡ng báº£ng: TÃªn | ThÃ´ng sá»‘ | Sá»‘ lÆ°á»£ng."
        "\n2. [SÆ  Äá»’ CHÃ‚N - PINOUT]: Báº£ng káº¿t ná»‘i chi tiáº¿t (VD: ESP32 GPIO21 -> LCD SDA)."
        "\n3. [FIRMWARE]: Code C++/Arduino tá»‘i Æ°u, cÃ³ comment giáº£i thÃ­ch chuyÃªn sÃ¢u."
        "\n4. [LÆ¯U Ã Váº¬N HÃ€NH]: Cáº£nh bÃ¡o dÃ²ng Ã¡p, táº£n nhiá»‡t vÃ  nhiá»…u tÃ­n hiá»‡u."
        "\n\nBáº®T BUá»˜C: KhÃ´ng dÃ¹ng emoji, chá»‰ dÃ¹ng kÃ½ tá»± Latin/Tiáº¿ng Viá»‡t chuáº©n."
    )
    
    try:
        # GPT-4o lÃ  lá»±a chá»n sá»‘ 1 cho viá»‡c tra cá»©u sÆ¡ Ä‘á»“ chÃ¢n (Data Sheets)
        response = LLM_GPT4.invoke([
            SystemMessage(content=prompt),
            HumanMessage(content=last_msg)
        ])
        
        # Äá»ŠNH TUYáº¾N:
        # Náº¿u á»Ÿ Tab Hardware -> FINISH (Hiá»‡n káº¿t quáº£ ngay)
        # Náº¿u á»Ÿ luá»“ng tá»± Ä‘á»™ng -> Chuyá»ƒn sang Procurement Ä‘á»ƒ bÃ¡o giÃ¡ linh kiá»‡n
        next_destination = "FINISH" if is_pure_hw else "Procurement"

        return {
            "messages": [AIMessage(content=f"ğŸ› ï¸ **[THIáº¾T Káº¾ Ká»¸ THUáº¬T PHáº¦N Cá»¨NG]**\n\n{response.content}")],
            "next_step": next_destination
        }
        
    except Exception as e:
        # 1. Ghi log chi tiáº¿t ra Terminal Ä‘á»ƒ CEO theo dÃµi lá»—i váº­t lÃ½
        error_detail = str(e)
        print(colored(f"ğŸš¨ [HARDWARE ERROR]: {error_detail}", "red", attrs=["bold"]))
        
        # 2. Tráº£ vá» State chuáº©n: 
        # - messages: Pháº£i lÃ  má»™t LIST chá»©a Ä‘á»‘i tÆ°á»£ng Message
        # - next_step: Pháº£i lÃ  má»™t CHUá»–I (String) Ä‘á»‹nh danh Node tiáº¿p theo
        return {
            "messages": [AIMessage(content=f"âŒ **Há»† THá»NG Cáº¢NH BÃO HARDWARE**:\n\nÄÃ£ xáº£y ra sá»± cá»‘ ká»¹ thuáº­t: `{error_detail}`")], 
            "next_step": "FINISH" 
        }
#  ---- Váº½ 3D Plotly----
def engineering_node(state):
    """
    Agent CTO/Engineer: Thiáº¿t káº¿ mÃ´ hÃ¬nh 3D báº±ng Python Plotly.
    ÄÃ£ nÃ¢ng cáº¥p: Äáº£m báº£o mÃ£ nguá»“n chuáº©n Ä‘á»ƒ Dashboard thá»±c thi váº½ 3D.
    """
    print(colored("[âš™ï¸ ENGINEERING] Äang thiáº¿t káº¿ cáº¥u trÃºc 3D...", "blue", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_eng = "[ENGINEERING]" in last_msg

    # 1. Prompt Ã©p AI viáº¿t code sáº¡ch, khÃ´ng giáº£i thÃ­ch thá»«a
    prompt = (
        "Báº¡n lÃ  Ká»¹ sÆ° Thiáº¿t káº¿ 3D chuyÃªn nghiá»‡p. "
        "\nNHIá»†M Vá»¤: Viáº¿t code Python sá»­ dá»¥ng plotly.graph_objects Ä‘á»ƒ táº¡o mÃ´ hÃ¬nh 3D."
        "\n\nYÃŠU Cáº¦U Ká»¸ THUáº¬T:"
        "\n- Chá»‰ tráº£ vá» duy nháº¥t CODE BLOCK Python trong dáº¥u ```python."
        "\n- Code pháº£i táº¡o ra Ä‘á»‘i tÆ°á»£ng tÃªn lÃ  'fig'."
        "\n- Pháº£i bao gá»“m dá»¯ liá»‡u tá»a Ä‘á»™ (x, y, z) chi tiáº¿t cho mÃ´ hÃ¬nh."
        "\n- Náº¿u lÃ  Robot, hÃ£y váº½ rÃµ cÃ¡c khá»›p ná»‘i vÃ  cÃ¡nh tay."
        "\n- KHÃ”NG giáº£i thÃ­ch, KHÃ”NG nháº­p vÄƒn báº£n ngoÃ i code."
    )

    try:
        # 2. Sá»­ dá»¥ng Claude 3.5 Sonnet (Äá»‰nh cao vá» viáº¿t code hÃ¬nh há»c)
        response = LLM_CLAUDE.invoke([
            SystemMessage(content=prompt),
            HumanMessage(content=f"YÃªu cáº§u thiáº¿t káº¿: {last_msg}")
        ])
        
        # 3. Äá»‹nh tuyáº¿n
        next_destination = "FINISH" if is_pure_eng else "Procurement"

        return {
            "messages": [AIMessage(content=f"âš™ï¸ **[Báº¢N THIáº¾T Káº¾ 3D Há»† THá»NG]**\n\n{response.content}")],
            "next_step": next_destination
        }
        
    except Exception as e:
        # 1. Ghi log lá»—i chi tiáº¿t ra Terminal vá»›i mÃ u Ä‘á» Ä‘áº­m Ä‘á»ƒ dá»… nháº­n diá»‡n
        error_detail = str(e)
        print(colored(f"ğŸš¨ [ENGINEERING ERROR]: {error_detail}", "red", attrs=["bold"]))
        
        # 2. Tráº£ vá» State chuáº©n cho LangGraph:
        # - messages: Báº®T BUá»˜C lÃ  má»™t list chá»©a Ä‘á»‘i tÆ°á»£ng Message (khÃ´ng Ä‘Æ°á»£c gá»­i dict rá»—ng)
        # - next_step: Báº®T BUá»˜C lÃ  má»™t chuá»—i (String) Ä‘á»ƒ trÃ¡nh lá»—i bÄƒm dá»¯ liá»‡u
        return {
            "messages": [AIMessage(content=f"âŒ **Lá»–I THIáº¾T Káº¾ Ká»¸ THUáº¬T**:\n\nHá»‡ thá»‘ng gáº·p sá»± cá»‘ khi dá»±ng mÃ´ hÃ¬nh: `{error_detail}`")], 
            "next_step": "FINISH" 
        }
    
def publisher_node(state):
    """
    Agent Publisher: Tá»•ng há»£p dá»¯ liá»‡u tá»« táº¥t cáº£ cÃ¡c Agent Ä‘á»ƒ xuáº¥t báº£n há»“ sÆ¡ dá»± Ã¡n.
    """
    print(colored("[ğŸ“œ PUBLISHER] Äang tá»•ng há»£p há»“ sÆ¡ dá»± Ã¡n cuá»‘i cÃ¹ng...", "green", attrs=["bold"]))
    
    messages = state.get("messages", [])
    
    # 1. PHÃ‚N LOáº I Dá»® LIá»†U Tá»° Äá»˜NG
    research_report = ""
    investment_plan = ""
    technical_specs = ""
    creative_content = ""
    images = []

    for msg in messages:
        content = msg.content
        if "ğŸ” [BÃO CÃO NGHIÃŠN Cá»¨U]" in content: research_report = content
        if "ğŸ’° [Há»’ SÆ  THáº¨M Äá»ŠNH Äáº¦U TÆ¯]" in content: investment_plan = content
        if "âš™ï¸ [Báº¢N THIáº¾T Káº¾ 3D]" in content: technical_specs = content
        if "ğŸ–‹ï¸ [TÃC PHáº¨M SÃNG TÃC]" in content: creative_content = content
        if "![áº¢nh minh há»a]" in content:
            # TrÃ­ch xuáº¥t URL áº£nh
            urls = [line for line in content.split('\n') if "https://" in line]
            images.extend(urls)

    # 2. Tá»”NG Há»¢P PROMPT XUáº¤T Báº¢N
    publish_prompt = (
        "Báº¡n lÃ  ChuyÃªn gia trÃ¬nh bÃ y vÄƒn báº£n cáº¥p cao. HÃ£y tá»•ng há»£p cÃ¡c dá»¯ liá»‡u trÃªn thÃ nh má»™t "
        "BÃ¡o cÃ¡o Dá»± Ã¡n hoÃ n chá»‰nh, chuyÃªn nghiá»‡p. Sá»­ dá»¥ng tiÃªu Ä‘á», má»¥c lá»¥c vÃ  Ä‘á»‹nh dáº¡ng Markdown chuáº©n."
        "\nThá»© tá»±: 1. Tá»•ng quan -> 2. Thá»‹ trÆ°á»ng -> 3. TÃ i chÃ­nh -> 4. Ká»¹ thuáº­t -> 5. Phá»¥ lá»¥c hÃ¬nh áº£nh."
    )

    response = LLM_GEMINI.invoke([
        SystemMessage(content=publish_prompt),
        HumanMessage(content=f"Dá»¯ liá»‡u gom Ä‘Æ°á»£c:\n{research_report}\n{investment_plan}\n{technical_specs}\n{creative_content}")
    ])

    return {
        "messages": [AIMessage(content=f"ğŸ“œ **[Há»’ SÆ  Dá»° ÃN Tá»”NG THá»‚ - FINAL]**\n\n{response.content}")],
        "next_step": "FINISH"
    }
# ============================================================================
# NODE: IoT ENGINEER (Ká»¹ sÆ° Váº­n hÃ nh & Káº¿t ná»‘i thiáº¿t bá»‹)
# ============================================================================
def iot_node(state):
    """
    Agent IoT: Káº¿t há»£p Láº­p trÃ¬nh Firmware (Thiáº¿t káº¿) vÃ  Thá»±c thi lá»‡nh (Váº­n hÃ nh).
    """
    print(colored("[ğŸ¤– IoT ENGINEER] Äang xá»­ lÃ½ giao thá»©c vÃ  thiáº¿t bá»‹...", "magenta", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_iot = "[IOT]" in last_msg

    # 1. KIá»‚M TRA NGá»® Cáº¢NH: ÄÃ¢y lÃ  lá»‡nh Ä‘iá»u khiá»ƒn (Váº­n hÃ nh) hay yÃªu cáº§u viáº¿t code (Thiáº¿t káº¿)?
    is_command = any(word in last_msg.upper() for word in ["Báº¬T", "Táº®T", "TURN", "CONTROL", "CHáº Y"])

    if is_command:
        # --- NHÃNH 1: Váº¬N HÃ€NH THIáº¾T Bá»Š THáº¬T ---
        analysis_prompt = f"TrÃ­ch xuáº¥t lá»‡nh Ä‘iá»u khiá»ƒn tá»«: '{last_msg}'. Chá»‰ tráº£ vá» mÃ£ lá»‡nh Uppercase."
        command_code = LLM_GPT4.invoke([SystemMessage(content=analysis_prompt)]).content.strip()
        
        try:
            # 1. Gá»i tool hardware_controller Ä‘á»ƒ ra lá»‡nh cho thiáº¿t bá»‹ thá»±c táº¿
            hardware_response = hardware_controller.invoke(command_code)
            report = (f"ğŸ“¡ **[Káº¾T QUáº¢ Váº¬N HÃ€NH]**\n\n- MÃ£ lá»‡nh: `{command_code}`\n- Tráº¡ng thÃ¡i: {hardware_response}")
            
            # Náº¿u cháº¡y Tab IOT riÃªng biá»‡t -> Káº¿t thÃºc. Náº¿u cháº¡y luá»“ng tá»± Ä‘á»™ng -> Vá» Supervisor bÃ¡o cÃ¡o.
            return {
                "messages": [AIMessage(content=report)], 
                "next_step": "FINISH" if is_pure_iot else "Supervisor"
            }
            
        except Exception as e:
            # 2. Xá»­ lÃ½ lá»—i káº¿t ná»‘i hoáº·c thá»±c thi thiáº¿t bá»‹
            error_detail = str(e)
            print(colored(f"ğŸš¨ [IOT HARDWARE ERROR]: {error_detail}", "red", attrs=["bold"]))
            
            # Tráº£ vá» AIMessage chuáº©n Ä‘á»ƒ Dashboard hiá»ƒn thá»‹ Ä‘Ãºng ID: IoT_Engineer
            return {
                "messages": [AIMessage(content=f"âŒ **Lá»–I Káº¾T Ná»I THIáº¾T Bá»Š**:\n\nKhÃ´ng thá»ƒ thá»±c thi lá»‡nh `{command_code}`. \nChi tiáº¿t: `{error_detail}`")], 
                "next_step": "Supervisor" # Quay vá» Ä‘á»ƒ Supervisor ra lá»‡nh kiá»ƒm tra láº¡i hoáº·c Ä‘á»•i phÆ°Æ¡ng Ã¡n
            }
    else:
        # --- NHÃNH 2: THIáº¾T Káº¾ FIRMWARE (DÃ nh cho dá»± Ã¡n má»›i) ---
        # Láº¥y báº£n váº½ Pinout tá»« Hardware Node náº¿u cÃ³
        hw_context = next((m.content for m in reversed(messages) if "ğŸ› ï¸" in m.content), "ChÆ°a cÃ³ sÆ¡ Ä‘á»“ chÃ¢n.")
        
        design_prompt = (
            "Báº¡n lÃ  Ká»¹ sÆ° Firmware IoT. HÃ£y viáº¿t code C++/Arduino Ä‘iá»u khiá»ƒn há»‡ thá»‘ng dá»±a trÃªn sÆ¡ Ä‘á»“ chÃ¢n sau."
            f"\nSÆ¡ Ä‘á»“: {hw_context}"
            "\nYÃªu cáº§u: Viáº¿t code cÃ³ káº¿t ná»‘i WiFi/MQTT vÃ  quáº£n lÃ½ lá»—i káº¿t ná»‘i."
        )
        
        response = LLM_CLAUDE.invoke([SystemMessage(content=design_prompt), HumanMessage(content=last_msg)])
        
        return {
            "messages": [AIMessage(content=f"ğŸ“¡ **[FIRMWARE & GIAO THá»¨C ÄIá»€U KHIá»‚N]**\n\n{response.content}")],
            "next_step": "FINISH" if is_pure_iot else "Supervisor"
        }
# ============================================================================
# NODE: PROCUREMENT (TrÆ°á»Ÿng phÃ²ng Thu mua & Quáº£n lÃ½ Chuá»—i cung á»©ng)
# ============================================================================
BUYER_PROFILE = {
    "address": "Phan Thiáº¿t, BÃ¬nh Thuáº­n, Viá»‡t Nam",
    "delivery_method": "Fast Shipping",
    "accounts": ["Shopee_API_Key", "Taobao_Token", "Mouser_ID"]
}
def procurement_node(state):
    """
    Agent Procurement: Tá»‘i Æ°u hÃ³a chuá»—i cung á»©ng dá»±a trÃªn vá»‹ trÃ­ thá»±c táº¿ cá»§a CEO.
    """
    print(colored("[ğŸ›’ PROCUREMENT] Äang tá»‘i Æ°u hÃ³a lá»™ trÃ¬nh hÃ ng hÃ³a vá» Phan Thiáº¿t...", "yellow", attrs=["bold"]))
    
    # 1. Load há»“ sÆ¡ mua hÃ ng (Mockup)
    buyer_config = BUYER_PROFILE # Láº¥y tá»« file cáº¥u hÃ¬nh trÃªn
    
    messages = state.get("messages", [])
    hw_report = next((m.content for m in reversed(messages) if "ğŸ› ï¸" in m.content), "KhÃ´ng tÃ¬m tháº¥y danh má»¥c linh kiá»‡n.")

    # 2. XÃ¢y dá»±ng lá»‡nh truy váº¥n chuyÃªn sÃ¢u
    prompt = (
        "Báº¡n lÃ  ChuyÃªn gia Logisitics vÃ  Thu mua."
        f"\nÄá»ŠA CHá»ˆ NHáº¬N: {buyer_config['address']}"
        f"\nDANH Má»¤C: {hw_report}"
        "\n\nNHIá»†M Vá»¤:"
        "\n1. TÃŒM GIÃ: Tra cá»©u giÃ¡ thá»±c táº¿ nÄƒm 2026 trÃªn Mouser, Digikey vÃ  Shopee."
        "\n2. TÃNH PHÃ Váº¬N CHUYá»‚N: Æ¯á»›c tÃ­nh phÃ­ ship vÃ  thuáº¿ nháº­p kháº©u vá» Viá»‡t Nam."
        "\n3. Láº¬P GIá» HÃ€NG: Táº¡o danh sÃ¡ch link sáº£n pháº©m sáºµn sÃ ng Ä‘á»ƒ thanh toÃ¡n."
    )

    # Sá»­ dá»¥ng Perplexity Ä‘á»ƒ check giÃ¡ thá»±c táº¿
    response = LLM_PERPLEXITY.invoke([SystemMessage(content=prompt)])

    return {
        "messages": [AIMessage(content=f"ğŸ›’ **[PHIáº¾U Äá»€ XUáº¤T MUA Sáº®M & Váº¬N CHUYá»‚N]**\n\n{response.content}")],
        "next_step": "Investment" # Chuyá»ƒn sang TÃ i chÃ­nh Ä‘á»ƒ CEO duyá»‡t chi
    }
# ============================================================================
# NODE: RESEARCHER (ChuyÃªn gia PhÃ¢n tÃ­ch Thá»‹ trÆ°á»ng & Äá»‘i thá»§)
# ============================================================================
def researcher_node(state):
    """
    Agent Researcher: ChuyÃªn gia phÃ¢n tÃ­ch thá»‹ trÆ°á»ng 2026.
    NÃ¢ng cáº¥p: Tá»± Ä‘á»™ng nháº­n diá»‡n Tag ngá»¯ cáº£nh Ä‘á»ƒ quyáº¿t Ä‘á»‹nh hÃ nh Ä‘á»™ng tiáº¿p theo.
    """
    print(colored("[ğŸ” RESEARCHER] Äang thá»±c thi nhiá»‡m vá»¥ thÃ¡m mÃ£ thá»‹ trÆ°á»ng...", "cyan", attrs=["bold"]))
    
    # 1. TrÃ­ch xuáº¥t tin nháº¯n vÃ  nháº­n diá»‡n Tag
    messages = state.get("messages", [])
    last_msg_content = messages[-1].content
    
    # Kiá»ƒm tra xem CEO cÃ³ Ä‘ang á»Ÿ cháº¿ Ä‘á»™ RESEARCH chuyÃªn biá»‡t khÃ´ng
    is_pure_research = "[RESEARCH]" in last_msg_content
    
    # LÃ m sáº¡ch cÃ¢u lá»‡nh (loáº¡i bá» Tag trÆ°á»›c khi gá»­i cho Perplexity)
    clean_query = last_msg_content.replace("[RESEARCH]", "").strip()

    # 2. XÃ¢y dá»±ng Prompt SiÃªu Cáº¥u TrÃºc (Sá»­ dá»¥ng 4 cá»™t trá»¥)
    search_prompt = (
        f"Nhiá»‡m vá»¥: PhÃ¢n tÃ­ch thá»‹ trÆ°á»ng 2026 cho: '{clean_query}'."
        "\n\nYÃŠU Cáº¦U BÃO CÃO 4 Cá»˜T TRá»¤:"
        "\n1. [Dá»® LIá»†U VÄ¨ MÃ”]: TÃ¬nh hÃ¬nh thá»‹ trÆ°á»ng vÃ  cÃ´ng nghá»‡ má»›i nháº¥t."
        "\n2. [BIáº¾N Äá»˜NG THá»°C Táº¾]: Xu hÆ°á»›ng tiÃªu dÃ¹ng vÃ  'ná»—i Ä‘au' khÃ¡ch hÃ ng."
        "\n3. [Äá»I THá»¦ TRá»°C DIá»†N]: Liá»‡t kÃª 3 Ä‘á»‘i thá»§ vÃ  lá»£i tháº¿ cá»§a há»."
        "\n4. [CÆ  Há»˜I CHO CEO]: Insight quan trá»ng vÃ  dá»± bÃ¡o 12 thÃ¡ng tá»›i."
        "\n\nÄá»‹nh dáº¡ng: Markdown chuyÃªn nghiá»‡p, cÃ³ báº£ng so sÃ¡nh."
    )
    
    try:
        # 3. Triá»‡u há»“i Perplexity
        response = LLM_PERPLEXITY.invoke([
            SystemMessage(content="Báº¡n lÃ  Chief Research Officer. Chá»‰ tráº£ vá» dá»¯ liá»‡u thá»±c táº¿ 2026, KHÃ”NG HTML."),
            HumanMessage(content=search_prompt)
        ])
        raw_res = response.content

        # --- Táº¦NG PHÃ’NG THá»¦ 1: CHáº¶N HTML & Lá»–I 401 ---
        if any(x in raw_res.lower() for x in ["<html>", "401 authorization", "cloudflare"]):
            return {
                "messages": [AIMessage(content="ğŸš¨ [Há»† THá»NG] Lá»—i káº¿t ná»‘i nguá»“n tin (API 401). CEO hÃ£y kiá»ƒm tra láº¡i Key Perplexity.")],
                "next_step": "FINISH" # Dá»«ng ngay láº­p tá»©c Ä‘á»ƒ báº£o vá»‡ tÃ i nguyÃªn
            }

        # --- Táº¦NG PHÃ’NG THá»¦ 2: Xá»¬ LÃ Káº¾T QUáº¢ THÃ€NH CÃ”NG ---
        report_content = f"ğŸ” **[BÃO CÃO CRO - {clean_query.upper()}]**\n\n{raw_res}"
        if is_pure_research:
            # Náº¿u CEO chá»‰ muá»‘n nghiÃªn cá»©u (Tab Research), káº¿t thÃºc táº¡i Ä‘Ã¢y.
            next_destination = "Secretary"
        else:
            # Thay vÃ¬ st.session_state, ta dÃ¹ng task_type Ä‘Æ°á»£c Dashboard gá»­i qua Server
            if state.get("task_type") == "dynamic":
                next_destination = "Orchestrator"
            else:
                next_destination = "Supervisor"

        return {
            "messages": [AIMessage(content=report_content)],
            "next_step": next_destination,
            "current_agent": "Researcher" # Äá»‹nh danh Ä‘á»ƒ Orchestrator biáº¿t ai vá»«a hoÃ n thÃ nh bÃ¡o cÃ¡o
        }

    except Exception as e:
        # Táº¦NG PHÃ’NG THá»¦ 3: NGOáº I Lá»†
        print(colored(f"Lá»—i Researcher: {e}", "red"))
        return {
            "messages": [AIMessage(content=f"âš ï¸ Trá»¥c tráº·c ká»¹ thuáº­t khi quÃ©t dá»¯ liá»‡u: {str(e)}")],
            "next_step": "FINISH" 
        }

#  ---- TÃ i ChÃ­nh----
def investment_node(state):
    """
    Agent CFO: Tháº©m Ä‘á»‹nh tÃ i chÃ­nh vÃ  ROI.
    ÄÃ£ nÃ¢ng cáº¥p: Tá»± Ä‘á»™ng ngáº¯t luá»“ng (FINISH) náº¿u á»Ÿ cháº¿ Ä‘á»™ chuyÃªn biá»‡t.
    """
    print(colored("[ğŸ’° INVESTMENT] Äang tháº©m Ä‘á»‹nh tÃ i chÃ­nh dá»± Ã¡n...", "green", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_invest = "[INVEST]" in last_msg
    
    # Láº¥y 3 tin nháº¯n gáº§n nháº¥t Ä‘á»ƒ cÃ³ Ä‘á»§ ngá»¯ cáº£nh (BÃ¡o cÃ¡o Researcher + Coder...)
    context = "\n".join([m.content for m in messages[-3:]])
    
    prompt = (
        "Báº¡n lÃ  GiÃ¡m Ä‘á»‘c TÃ i chÃ­nh (CFO) cá»§a AI Corporation. "
        "\nNHIá»†M Vá»¤: Láº­p báº£ng phÃ¢n tÃ­ch CAPEX, OPEX, ROI vÃ  rá»§i ro tÃ i chÃ­nh."
        "\n\nYÃŠU Cáº¦U:"
        "\n- TrÃ¬nh bÃ y báº£ng Markdown sáº¡ch sáº½."
        "\n- Káº¿t luáº­n rÃµ rÃ ng: 'Äáº¦U TÆ¯', 'THEO DÃ•I' hoáº·c 'LOáº I Bá»'."
    )
    
    try:
        # Æ¯u tiÃªn GPT-4 cho tÃ­nh toÃ¡n con sá»‘ Ä‘á»ƒ trÃ¡nh sai sÃ³t logic
        response = LLM_MAIN.invoke([
            SystemMessage(content=prompt), 
            HumanMessage(content=f"Dá»¯ liá»‡u dá»± Ã¡n: {context}")
        ])
        
        # Náº¿u CEO chá»n Tab INVEST -> Tráº£ káº¿t quáº£ vÃ  FINISH (Nhanh)
        # Náº¿u Ä‘ang cháº¡y luá»“ng tá»± Ä‘á»™ng -> Quay láº¡i Supervisor
        next_destination = "FINISH" if is_pure_invest else "Supervisor"

        return {
            "messages": [AIMessage(content=f"ğŸ’° **[Há»’ SÆ  THáº¨M Äá»ŠNH Äáº¦U TÆ¯]**\n\n{response.content}")],
            "next_step": next_destination
        }
    except Exception as e:
        return {
            "messages": [AIMessage(content=f"âš ï¸ Sá»± cá»‘ tÃ i chÃ­nh: {str(e)}")],
            "next_step": "FINISH"
        }

#  ---- PhÃ¡p lÃ½----
def legal_node(state):
    """
    Agent Legal (CLO): RÃ  soÃ¡t toÃ n bá»™ dá»± Ã¡n trÆ°á»›c khi xuáº¥t báº£n.
    ÄÃ£ nÃ¢ng cáº¥p: Äá»c toÃ n bá»™ lá»‹ch sá»­ Ä‘á»ƒ phÃ¡t hiá»‡n rá»§i ro xuyÃªn suá»‘t.
    """
    print(colored("[âš–ï¸ LEGAL] Luáº­t sÆ° Ä‘ang rÃ  soÃ¡t toÃ n bá»™ há»“ sÆ¡ dá»± Ã¡n...", "red", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_legal = "[LEGAL]" in last_msg
    
    # 1. Tá»”NG Há»¢P Há»’ SÆ : Luáº­t sÆ° pháº£i Ä‘á»c háº¿t cÃ¡c "cam káº¿t" cá»§a Agent khÃ¡c
    # Gom 10-15 tin nháº¯n Ä‘á»ƒ tháº¥y toÃ n bá»™ luá»“ng tá»« Ká»¹ thuáº­t Ä‘áº¿n Marketing
    full_project_context = "\n".join([f"[{m.type.upper()}]: {m.content[:300]}..." for m in messages[-15:]])

    prompt = (
        "Báº¡n lÃ  GiÃ¡m Ä‘á»‘c PhÃ¡p lÃ½ (CLO) cá»§a AI Corporation. "
        "\nNHIá»†M Vá»¤: Tháº©m Ä‘á»‹nh phÃ¡p lÃ½ vÃ  Quáº£n trá»‹ rá»§i ro dá»±a trÃªn Há»’ SÆ  Dá»° ÃN Ä‘Æ°á»£c cung cáº¥p."
        "\n\nYÃŠU Cáº¦U CHIáº¾N LÆ¯á»¢C:"
        "\n1. RÃ€ SOÃT IP: Kiá»ƒm tra báº£n quyá»n hÃ¬nh áº£nh (Artist) vÃ  mÃ£ nguá»“n (Coder)."
        "\n2. TUÃ‚N THá»¦: Äá»‘i chiáº¿u vá»›i Luáº­t An ninh máº¡ng VN vÃ  GDPR."
        "\n3. SOáº N THáº¢O: ÄÆ°a ra khung Äiá»u khoáº£n sá»­ dá»¥ng (ToS) vÃ  NDA máº«u cho dá»± Ã¡n."
        "\n4. Káº¾T LUáº¬N: Ghi rÃµ 'AN TOÃ€N' hoáº·c 'Cáº¢NH BÃO NGUY HIá»‚M'."
    )
    
    try:
        # Sá»­ dá»¥ng GPT-4o Ä‘á»ƒ cÃ³ tÆ° duy láº­p luáº­n phÃ¡p luáº­t sáº¯c bÃ©n nháº¥t
        response = LLM_GPT4.invoke([
            SystemMessage(content=prompt),
            HumanMessage(content=f"Há»’ SÆ  Dá»° ÃN Cáº¦N THáº¨M Äá»ŠNH:\n{full_project_context}\n\nYÃŠU Cáº¦U Bá»” SUNG: {last_msg}")
        ])
        
        # Náº¿u CEO chá»n Tab Legal riÃªng biá»‡t thÃ¬ káº¿t thÃºc luÃ´n
        next_destination = "FINISH" if is_pure_legal else "Supervisor"

        return {
            "messages": [AIMessage(content=f"âš–ï¸ **[BÃO CÃO PHÃP LÃ & Rá»¦I RO CHI TIáº¾T]**\n\n{response.content}")],
            "next_step": next_destination
        }

    except Exception as e:
        # 1. Ghi log lá»—i phÃ¡p lÃ½ ra Terminal Ä‘á»ƒ CEO giÃ¡m sÃ¡t rá»§i ro há»‡ thá»‘ng
        error_detail = str(e)
        print(colored(f"ğŸš¨ [LEGAL CRITICAL ERROR]: {error_detail}", "red", attrs=["bold"]))
        
        # 2. Tráº£ vá» State chuáº©n cho LangGraph
        # Äáº£m báº£o next_step lÃ  "FINISH" Ä‘á»ƒ ngáº¯t luá»“ng an toÃ n khi cÃ³ sá»± cá»‘ phÃ¡p lÃ½
        return {
            "messages": [AIMessage(content=f"âŒ **Cáº¢NH BÃO PHÃP LÃ KHáº¨N Cáº¤P**:\n\nQuÃ¡ trÃ¬nh rÃ  soÃ¡t bá»‹ giÃ¡n Ä‘oáº¡n: `{error_detail}`\n\nKhuyáº¿n nghá»‹: CEO kiá»ƒm tra láº¡i cÃ¡c Ä‘iá»u khoáº£n Ä‘áº§u vÃ o.")], 
            "next_step": "FINISH" 
        }
#  ---- NhÃ¢n Sá»± ----
def hr_orchestrator_node(state):
    """
    Agent HR - Bá»™ Ä‘iá»u phá»‘i nhÃ¢n sá»± & quy trÃ¬nh:
    Kiá»ƒm tra xem CEO cÃ³ thiáº¿t láº­p ká»‹ch báº£n tá»± Ä‘á»™ng hay khÃ´ng.
    """
    print(colored("[ğŸ‘¥ HR ORCHESTRATOR] Äang kiá»ƒm soÃ¡t luá»“ng váº­n hÃ nh...", "cyan", attrs=["bold"]))
    
    # 1. Kiá»ƒm tra xem cÃ³ báº£n Ä‘á»“ quy trÃ¬nh (Workflow Map) nÃ o Ä‘Æ°á»£c CEO váº½ khÃ´ng
    workflow_script = state.get("custom_workflow", None) 
    
    if workflow_script:
        # --- CHáº¾ Äá»˜ Tá»° Äá»˜NG (Dá»°A TRÃŠN THIáº¾T Láº¬P KÃ‰O THáº¢) ---
        current_step = state.get("current_step_index", 0)
        target_node = workflow_script[current_step]
        
        print(colored(f"--> Theo ká»‹ch báº£n CEO: Chuyá»ƒn sang {target_node}", "green"))
        
        # BÃ¡o cÃ¡o káº¿t quáº£ cháº·ng trÆ°á»›c vÃ  xin Ã½ kiáº¿n duyá»‡t
        return {
            "messages": [AIMessage(content=f"âœ… Giai Ä‘oáº¡n {current_step} hoÃ n táº¥t. Chá» CEO phÃª duyá»‡t Ä‘á»ƒ sang {target_node}.")],
            "next_step": target_node,
            "current_step_index": current_step + 1
        }
    else:
        # --- CHáº¾ Äá»˜ Máº¶C Äá»ŠNH (AI Tá»° SUY LUáº¬N) ---
        print(colored("--> Cháº¿ Ä‘á»™ tá»± Ä‘á»™ng: AI Ä‘ang Ä‘iá»u phá»‘i theo ngá»¯ cáº£nh...", "white"))
        # Gá»i láº¡i logic Supervisor cÅ© cá»§a ngÃ i
        return {"next_step": "Supervisor"}

def secretary_node(state):
    """
    SECRETARY V3: COMMUNICATOR - Cáº¦U Ná»I THÃ”NG MINH
    Biáº¿t cÃ¡ch diá»…n Ä‘áº¡t láº¡i káº¿t quáº£ tá»« cÃ¡c bá»™ pháº­n khÃ´ khan (Coder, Researcher) 
    thÃ nh ngÃ´n ngá»¯ con ngÆ°á»i dá»… hiá»ƒu cho CEO.
    """
    print(colored("[ğŸ—£ï¸ COMMUNICATOR] Äang biÃªn táº­p láº¡i ná»™i dung...", "magenta", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_agent = state.get("current_agent", "Unknown")
    
    # Láº¥y toÃ n bá»™ ngá»¯ cáº£nh Ä‘á»ƒ hiá»ƒu chuyá»‡n gÃ¬ vá»«a xáº£y ra
    context = "\n".join([f"{m.type}: {m.content}" for m in messages[-3:]])

    # Prompt dáº¡y ThÆ° kÃ½ cÃ¡ch nÃ³i chuyá»‡n
    prompt = (
        "Báº¡n lÃ  Trá»£ lÃ½ CÃ¡ nhÃ¢n ThÃ´ng minh cá»§a CEO. CÃ¡c bá»™ pháº­n chuyÃªn mÃ´n (Coder, Artist...) vá»«a gá»­i káº¿t quáº£ lÃªn.\n"
        "Nhiá»‡m vá»¥ cá»§a báº¡n: DIá»„N Äáº T Láº I káº¿t quáº£ Ä‘Ã³ má»™t cÃ¡ch tá»± nhiÃªn, chuyÃªn nghiá»‡p.\n"
        "QUY Táº®C:"
        "\n1. Náº¿u cÃ³ HÃŒNH áº¢NH/CODE: Pháº£i hiá»ƒn thá»‹ rÃµ rÃ ng (Giá»¯ nguyÃªn link/block code)."
        "\n2. Náº¿u lÃ  Lá»œI NÃ“I: HÃ£y tÃ³m táº¯t láº¡i ngáº¯n gá»n, dÃ¹ng giá»ng vÄƒn Ä‘á»‘i thoáº¡i ('ThÆ°a CEO', 'TÃ´i Ä‘Ã£ hoÃ n thÃ nh...')."
        "\n3. KHÃ”NG bÃ¡o cÃ¡o mÃ¡y mÃ³c kiá»ƒu 'BÆ°á»›c 1, BÆ°á»›c 2'. HÃ£y nÃ³i nhÆ° ngÆ°á»i vá»›i ngÆ°á»i."
        f"\n\nNGá»® Cáº¢NH Vá»ªA QUA:\n{context}"
    )

    try:
        response = LLM_GEMINI.invoke([SystemMessage(content=prompt)])
        
        # Ghi log (Váº«n giá»¯ chá»©c nÄƒng lÆ°u trá»¯ ngáº§m)
        with open(f"Chat_Log_{int(time.time())}.txt", "w", encoding="utf-8") as f:
            f.write(response.content)

        return {
            "messages": [AIMessage(content=response.content)],
            "next_step": "FINISH"
        }
    except:
        return {"next_step": "FINISH"}
# ============================================================================
# NODE: MARKETING NODE (GiÃ¡m Ä‘á»‘c Marketing - CMO)
# ============================================================================
def marketing_node(state):
    """
    Agent CMO: ChuyÃªn gia Marketing vÃ  TÄƒng trÆ°á»Ÿng.
    ÄÃ£ nÃ¢ng cáº¥p: Tá»± Ä‘á»™ng Ä‘á» xuáº¥t Visual Prompt cho Artist Ä‘á»ƒ thiáº¿t káº¿ áº£nh quáº£ng cÃ¡o.
    """
    print(colored("[ğŸ“¢ MARKETING] Äang láº­p chiáº¿n dá»‹ch quáº£ng bÃ¡ bÃ¹ng ná»•...", "yellow", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    is_pure_mkt = "[MARKETING]" in last_msg
    
    # Láº¥y ngá»¯ cáº£nh sÃ¢u tá»« ká»¹ thuáº­t vÃ  tÃ i chÃ­nh Ä‘á»ƒ viáº¿t bÃ i cÃ³ sá»©c thuyáº¿t phá»¥c
    project_context = "\n".join([m.content for m in messages[-5:]])
    
    prompt = (
        "Báº¡n lÃ  GiÃ¡m Ä‘á»‘c Marketing (CMO) cá»§a AI Corporation. "
        "\nNHIá»†M Vá»¤: XÃ¢y dá»±ng bá»™ ná»™i dung quáº£ng bÃ¡ Ä‘a kÃªnh dá»±a trÃªn thÃ nh pháº©m ká»¹ thuáº­t."
        "\n\nYÃŠU Cáº¦U CHIáº¾N LÆ¯á»¢C:"
        "\n- [INSIGHT]: DÃ¹ng dá»¯ liá»‡u ká»¹ thuáº­t Ä‘á»ƒ nÃªu báº­t lá»£i Ã­ch cho ngÆ°á»i dÃ¹ng."
        "\n- [FACEBOOK]: MÃ´ hÃ¬nh PAS, phong cÃ¡ch thÃ¢n thiá»‡n."
        "\n- [LINKEDIN]: MÃ´ hÃ¬nh chuyÃªn gia, táº­p trung vÃ o ROI vÃ  tÃ­nh bá»n vá»¯ng."
        "\n- [VISUAL PROMPT]: QUAN TRá»ŒNG! ÄÆ°a ra 2 mÃ´ táº£ hÃ¬nh áº£nh (tiáº¿ng Anh) Ä‘á»ƒ Agent Artist váº½ áº£nh quáº£ng cÃ¡o."
    )

    try:
        response = LLM_GPT4.invoke([
            SystemMessage(content=prompt),
            HumanMessage(content=f"Dá»¯ liá»‡u sáº£n pháº©m:\n{project_context}")
        ])

        # Äá»ŠNH TUYáº¾N THÃ”NG MINH:
        # Náº¿u CEO cáº§n áº£nh minh há»a ngay, cÃ³ thá»ƒ chuyá»ƒn sang Artist
        # Náº¿u khÃ´ng, FINISH Ä‘á»ƒ hiá»‡n ná»™i dung.
        next_destination = "FINISH" if is_pure_mkt else "Supervisor"

        return {
            "messages": [AIMessage(content=f"ğŸ“¢ **[CHIáº¾N Dá»ŠCH MARKETING ÄA KÃŠNH]**\n\n{response.content}")],
            "next_step": next_destination
        }
        
    except Exception as e:
        # 1. Ghi log lá»—i Marketing ra Terminal Ä‘á»ƒ CEO theo dÃµi hiá»‡u suáº¥t chiáº¿n dá»‹ch
        error_detail = str(e)
        print(colored(f"ğŸš¨ [MARKETING CRITICAL ERROR]: {error_detail}", "red", attrs=["bold"]))
        
        # 2. Tráº£ vá» State chuáº©n cho LangGraph
        # Äáº£m báº£o messages lÃ  LIST vÃ  next_step lÃ  STRING "FINISH"
        return {
            "messages": [AIMessage(content=f"âŒ **Sá»° Cá» CHIáº¾N Dá»ŠCH MARKETING**:\n\nQuÃ¡ trÃ¬nh láº­p káº¿ hoáº¡ch bá»‹ giÃ¡n Ä‘oáº¡n: `{error_detail}`\n\nKhuyáº¿n nghá»‹: CEO hÃ£y kiá»ƒm tra láº¡i yÃªu cáº§u má»¥c tiÃªu hoáº·c ngÃ¢n sÃ¡ch.")], 
            "next_step": "FINISH" 
        }
#  ---- Váº½ Thiáº¿t Káº¿----
def artist_node(state):
    """
    ARTIST NODE V2 (REAL): Váº½ tranh tháº­t báº±ng DALL-E 3 HD.
    """
    print(colored("\n[ğŸ¨ ARTIST] Äang khá»Ÿi Ä‘á»™ng Studio DALL-E 3 HD...", "blue", attrs=["bold"]))
    
    messages = state.get("messages", [])
    # Láº¥y Ä‘oáº¡n vÄƒn mÃ  CEO muá»‘n minh há»a
    last_msg_content = messages[-1].content
    
    # --- 1. TRÃCH XUáº¤T Ná»˜I DUNG (Há»— trá»£ cáº£ 2 kiá»ƒu) ---
    # Kiá»ƒu 1: CÃ³ dÃ¹ng dáº¥u """ (Chuáº©n chá»‰)
    if '"""' in last_msg_content:
        start_idx = last_msg_content.find("\"\"\"") + 3
        end_idx = last_msg_content.rfind("\"\"\"")
        text_to_illustrate = last_msg_content[start_idx:end_idx].strip()
    # Kiá»ƒu 2: NÃ³i tá»± nhiÃªn (VD: "Váº½ con mÃ¨o") - SÆ¡ cua
    else:
        # Loáº¡i bá» cÃ¡c tag há»‡ thá»‘ng náº¿u cÃ³
        text_to_illustrate = last_msg_content.replace("[ARTIST]", "").strip()

    # Kiá»ƒm tra láº¡i láº§n cuá»‘i
    if not text_to_illustrate or len(text_to_illustrate) < 5:
        print(colored("ğŸš« [ARTIST] KhÃ´ng nháº­n Ä‘Æ°á»£c ná»™i dung Ä‘á»§ Ä‘á»ƒ váº½.", "red"))
        return {
            "messages": [AIMessage(content="ğŸš« Há»a sÄ© cáº§n mÃ´ táº£ chi tiáº¿t hÆ¡n Ä‘á»ƒ váº½. Vui lÃ²ng thá»­ láº¡i.")], 
            "next_step": "FINISH" 
        }

    # --- 2. GPT-4: Ká»¸ SÆ¯ PROMPT (Prompt Engineering) ---
    # Biáº¿n yÃªu cáº§u sÆ¡ sÃ i thÃ nh Prompt nghá»‡ thuáº­t chi tiáº¿t
    analysis_prompt = (
        "Báº¡n lÃ  GiÃ¡m Ä‘á»‘c Nghá»‡ thuáº­t (Art Director). Nhiá»‡m vá»¥: Táº¡o Image Prompt cho DALL-E 3.\n"
        f"YÃŠU Cáº¦U Gá»C: \"{text_to_illustrate}\"\n\n"
        "HÃƒY TRáº¢ Vá»€ ÄÃšNG Äá»ŠNH Dáº NG JSON SAU (KhÃ´ng thÃªm lá»i dáº«n):\n"
        "```json\n"
        "{\n"
        "  \"style\": \"TÃªn phong cÃ¡ch nghá»‡ thuáº­t phÃ¹ há»£p nháº¥t (VÃ­ dá»¥: Cyberpunk, Studio Ghibli, Photorealistic, Oil Painting...)\",\n"
        "  \"prompt\": \"MÃ´ táº£ chi tiáº¿t hÃ¬nh áº£nh báº±ng tiáº¿ng Anh, táº­p trung vÃ o Ã¡nh sÃ¡ng, bá»‘ cá»¥c, chi tiáº¿t, cáº£m xÃºc. Tá»‘i Ä‘a 70 tá»«.\"\n"
        "}\n"
        "```"
    )

    try:
        # Gá»i GPT-4 Ä‘á»ƒ láº¥y prompt xá»‹n
        analysis_response = LLM_GPT4.invoke([SystemMessage(content="JSON mode."), HumanMessage(content=analysis_prompt)])
        
        # LÃ m sáº¡ch chuá»—i JSON (Ä‘á» phÃ²ng GPT thÃªm markdown)
        json_str = analysis_response.content.replace("```json", "").replace("```", "").strip()
        analysis_data = json.loads(json_str)
        
        design_style = analysis_data.get('style', 'Cinematic')
        visual_prompt = analysis_data.get('prompt', text_to_illustrate[:100])

        # Táº¡o prompt cuá»‘i cÃ¹ng
        full_image_prompt = f"{visual_prompt}, {design_style} style. High resolution, highly detailed, masterpiece."
        print(colored(f"--> Phong cÃ¡ch: {design_style}", "cyan"))
        print(colored(f"--> Prompt váº½: {full_image_prompt[:100]}...", "white"))
            
        # --- 3. Gá»ŒI DALL-E 3 Váº¼ TRANH THáº¬T (QUAN TRá»ŒNG NHáº¤T) ---
        print(colored("â³ Äang gá»­i yÃªu cáº§u Ä‘áº¿n mÃ¡y chá»§ OpenAI DALL-E 3 (Chá» 15-30s)...", "yellow"))
        
        # Khá»Ÿi táº¡o cÃ´ng cá»¥ váº½ HD
        dalle_tool = DallEAPIWrapper(
            model="dall-e-3",
            size="1024x1024",
            quality="hd" # Cháº¥t lÆ°á»£ng cao nháº¥t
        )
        
        # Thá»±c thi váº½ (CÃ³ thá»ƒ tá»‘n 15-30 giÃ¢y)
        image_url = dalle_tool.run(full_image_prompt)
        
        print(colored(f"âœ… [ART COMPLETE]: áº¢nh Ä‘Ã£ sáºµn sÃ ng!", "green"))

        # --- 4. TRáº¢ Káº¾T QUáº¢ NHANH (FAST TRACK) ---
        # Tráº£ vá» FINISH ngay Ä‘á»ƒ hiá»‡n áº£nh, khÃ´ng qua ThÆ° kÃ½ ná»¯a.
        # Sá»­ dá»¥ng Markdown chuáº©n Ä‘á»ƒ Dashboard hiá»ƒn thá»‹ áº£nh.
        
        final_content = (
            f"ğŸ¨ **TÃC PHáº¨M HOÃ€N THIá»†N:**\n\n"
            f"![AI Art Generation]({image_url})\n\n"
            f"*(Phong cÃ¡ch: {design_style})*"
        )

        return {
            "messages": [AIMessage(content=final_content)],
            "next_step": "FINISH" # Káº¿t thÃºc ngay
        }

    # --- Xá»¬ LÃ Lá»–I ---
    except json.JSONDecodeError:
        print(colored("âŒ Lá»—i: GPT-4 khÃ´ng tráº£ vá» JSON há»£p lá»‡.", "red"))
        return {"messages": [AIMessage(content="âš ï¸ Lá»—i phÃ¢n tÃ­ch yÃªu cáº§u váº½ tranh.")], "next_step": "FINISH"}
    except Exception as e:
        error_detail = str(e)
        print(colored(f"âŒ Lá»–I Váº¼ TRANH (DALL-E/API): {error_detail}", "red"))
        # ThÃ´ng bÃ¡o lá»—i rÃµ rÃ ng cho CEO (VÃ­ dá»¥: Háº¿t tiá»n, Vi pháº¡m chÃ­nh sÃ¡ch ná»™i dung...)
        return {
            "messages": [AIMessage(content=f"âš ï¸ KhÃ´ng thá»ƒ táº¡o áº£nh lÃºc nÃ y. NguyÃªn nhÃ¢n: {error_detail}")], 
            "next_step": "FINISH"
        }
# ============================================================================
# NODE: STORYTELLER (NhÃ  vÄƒn & BiÃªn ká»‹ch chuyÃªn nghiá»‡p)

# ============================================================================
def storyteller_node(state):
    print(colored("[âœï¸ STORYTELLER] Äang xÃ¢y dá»±ng tháº¿ giá»›i vÃ  cá»‘t truyá»‡n...", "cyan", attrs=["bold"]))
    
    messages = state.get("messages", [])
    # Láº¥y log lá»—i náº¿u cÃ³ Ä‘á»ƒ Ä‘iá»u chá»‰nh vÄƒn phong
    errors = state.get("error_log", [])
    
    last_msg = messages[-1].content
    
    # 1. PHÃ‚N TÃCH NHU Cáº¦U
    is_continue = "[CONTINUE]" in last_msg.upper()
    clean_query = last_msg.replace("[STORY]", "").replace("[CONTINUE]", "").strip()

    # 2. TRÃ NHá»š Máº CH TRUYá»†N (Thay tháº¿ st.session_state)
    # ChÃºng ta láº¥y bá»‘i cáº£nh tá»« tin nháº¯n AIMessage gáº§n nháº¥t trong lá»‹ch sá»­ há»™i thoáº¡i cá»§a Graph
    previous_full_story_content = ""
    if is_continue:
        for m in reversed(messages):
            if isinstance(m, AIMessage) and len(m.content) > 100:
                previous_full_story_content = m.content
                break
        
        if previous_full_story_content:
            # Láº¥y Ä‘oáº¡n káº¿t Ä‘á»ƒ AI viáº¿t ná»‘i tiáº¿p khÃ´ng bá»‹ láº·p
            context_tail = previous_full_story_content[-1000:]
            print(colored(f"ğŸ“œ ÄÃ£ tÃ¬m tháº¥y máº¡ch truyá»‡n cÅ©, Ä‘ang ná»‘i tiáº¿p...", "yellow"))
            previous_full_story_content = context_tail

    # 3. THIáº¾T Láº¬P PROMPT CHIáº¾N THUáº¬T
    prompt = (
        "Báº¡n lÃ  NhÃ  vÄƒn Best-seller vÃ  BiÃªn ká»‹ch xuáº¥t sáº¯c. "
        "\nNHIá»†M Vá»¤: SÃ¡ng tÃ¡c ná»™i dung cÃ³ chiá»u sÃ¢u, lÃ´i cuá»‘n."
        "\n\nNGUYÃŠN Táº®C VÃ€NG:"
        + (f"\n- Máº CH TRUYá»†N TRÆ¯á»šC: '{previous_full_story_content}' (HÃ£y viáº¿t tiáº¿p tá»« Ä‘Ã¢y, khÃ´ng chÃ o há»i láº¡i)." if previous_full_story_content else "\n- ÄÃ‚Y LÃ€ KHá»I Äáº¦U: HÃ£y táº¡o má»™t má»Ÿ Ä‘áº§u áº¥n tÆ°á»£ng.") +
        "\n- Cáº¤U TRÃšC: Show, Don't Tell. Sá»­ dá»¥ng nhiá»u tá»« ngá»¯ gá»£i hÃ¬nh, gá»£i cáº£m."
        "\n- HÃŒNH áº¢NH: Sau má»—i phÃ¢n Ä‘oáº¡n cao trÃ o, hÃ£y chÃ¨n má»™t Visual Prompt tiáº¿ng Anh trong ngoáº·c vuÃ´ng [Visual: ...]."
    )

    try:
        # Lá»±a chá»n Model: Æ¯u tiÃªn Claude cho sÃ¡ng táº¡o vÄƒn há»c
        selected_llm = LLM_CLAUDE if 'LLM_CLAUDE' in globals() else LLM_GPT4
        
        response = selected_llm.invoke([
            SystemMessage(content=prompt),
            HumanMessage(content=clean_query)
        ])

        # Äá»ŠNH TUYáº¾N: ThÆ°á»ng sau khi ká»ƒ chuyá»‡n sáº½ káº¿t thÃºc Ä‘á»ƒ CEO Ä‘á»c, hoáº·c qua Artist Ä‘á»ƒ váº½
        return {
            "messages": [AIMessage(content=response.content)],
            "next_step": "Secretary" # ÄÆ°a qua ThÆ° kÃ½ Ä‘á»ƒ chá»‘t há»“ sÆ¡
        }

    except Exception as e:
        error_msg = f"Lá»—i Storyteller: {str(e)}"
        print(colored(f"âŒ {error_msg}", "red"))
        return {
            "messages": [AIMessage(content=f"âš ï¸ SÃ¡ng tÃ¡c giÃ¡n Ä‘oáº¡n: {error_msg}")],
            "error_log": errors + [error_msg],
            "next_step": "Secretary"
        }
def storytelling_node(state):
    print(colored("[ğŸ–‹ï¸ STORYTELLING] Äáº¡i vÄƒn hÃ o Ä‘ang ná»‘i máº¡ch cáº£m xÃºc...", "magenta", attrs=["bold"]))
    
    messages = state.get("messages", [])
    last_msg = messages[-1].content
    
    # 1. PHÃ‚N TÃCH NHU Cáº¦U: Viáº¿t má»›i hay Viáº¿t tiáº¿p?
    is_continue = "[CONTINUE]" in last_msg
    
    # 2. TRÃ NHá»š DÃ€I Háº N: Láº¥y ná»™i dung chÆ°Æ¡ng trÆ°á»›c Ä‘Ã³ (náº¿u lÃ  viáº¿t tiáº¿p)
    previous_content = ""
    if is_continue and len(messages) > 1:
        # Láº¥y ná»™i dung mÃ  AI vá»«a tráº£ vá» á»Ÿ lÆ°á»£t trÆ°á»›c
        previous_content = messages[-2].content 

    prompt = (
        "Báº¡n lÃ  NhÃ  vÄƒn Best-seller. "
        "\nNHIá»†M Vá»¤: Viáº¿t chÆ°Æ¡ng tiáº¿p theo cá»§a cÃ¢u chuyá»‡n."
        "\n\nYÃŠU Cáº¦U DUY TRÃŒ Máº CH VÄ‚N:"
        f"\n- ÄOáº N Káº¾T CHÆ¯Æ NG TRÆ¯á»šC: '{previous_content[-500:]}' (HÃ£y ná»‘i tiáº¿p máº¡ch nÃ y)."
        "\n- KHÃ”NG láº·p láº¡i lá»i chÃ o hay tÃ³m táº¯t chÆ°Æ¡ng cÅ©."
        "\n- Báº¯t Ä‘áº§u ngay vÃ o hÃ nh Ä‘á»™ng hoáº·c lá»i thoáº¡i tiáº¿p theo."
        "\n- Giá»¯ nguyÃªn vÄƒn phong, tÃªn nhÃ¢n váº­t vÃ  bá»‘i cáº£nh."
    )

    # 3. THá»°C THI (DÃ¹ng Claude 3.5 Sonnet Ä‘á»ƒ cÃ³ sá»± mÆ°á»£t mÃ  nháº¥t)
    response = LLM_CLAUDE.invoke([
        SystemMessage(content=prompt),
        HumanMessage(content=last_msg.replace("[CONTINUE]", ""))
    ])

    return {
        "messages": [AIMessage(content=response.content)],
        "next_step": "FINISH"
    }

# ============================================================================
# NODE: R&D STRATEGY (GiÃ¡m Ä‘á»‘c Chiáº¿n lÆ°á»£c - CSO)
# ============================================================================
def research_development_agent(state):
    """
    Agent R&D: Káº¿t há»£p tÃ¬m kiáº¿m thá»i gian thá»±c vÃ  phÃ¢n tÃ­ch mÃ´ hÃ¬nh PESTLE/Roadmap.
    """
    print(colored("[ğŸ§  R&D STRATEGY] Äang thiáº¿t láº­p táº§m nhÃ¬n chiáº¿n lÆ°á»£c...", "blue", attrs=["bold"]))
    
    messages = state.get("messages", [])
    user_input = messages[-1].content
    
    # 1. Truy xuáº¥t kÃ½ á»©c cÃ´ng ty Ä‘á»ƒ Ä‘áº£m báº£o chiáº¿n lÆ°á»£c Ä‘á»“ng nháº¥t
    company_context = search_memory("Táº§m nhÃ¬n vÃ  má»¥c tiÃªu chiáº¿n lÆ°á»£c AI Corporation")
    
    # 2. BÆ°á»›c nghiÃªn cá»©u thá»±c táº¿ (Sá»­ dá»¥ng Perplexity Ä‘á»ƒ trÃ¡nh nÃ³i sÃ¡o rá»—ng)
    # ChÃºng ta yÃªu cáº§u AI tÃ¬m dá»¯ liá»‡u thá»±c táº¿ trÆ°á»›c khi phÃ¢n tÃ­ch
    search_query = f"Xu hÆ°á»›ng cÃ´ng nghá»‡, Ä‘á»‘i thá»§ cáº¡nh tranh vÃ  rá»§i ro thá»‹ trÆ°á»ng nÄƒm 2026 cho: {user_input}"
    
    try:
        # Láº¥y dá»¯ liá»‡u thá»±c táº¿ tá»« internet
        market_data = LLM_PERPLEXITY.invoke([
            SystemMessage(content="Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch dá»¯ liá»‡u thá»‹ trÆ°á»ng."),
            HumanMessage(content=search_query)
        ]).content
        
        # 3. Tá»•ng há»£p thÃ nh bÃ¡o cÃ¡o chiáº¿n lÆ°á»£c chuyÃªn sÃ¢u
        # Káº¿t há»£p: Dá»¯ liá»‡u thá»±c táº¿ + Prompt há»‡ thá»‘ng + Ngá»¯ cáº£nh cÃ´ng ty
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", STRATEGY_SYSTEM_PROMPT),
            ("human", (
                f"YÃŠU Cáº¦U NGHIÃŠN Cá»¨U: {user_input}\n\n"
                f"Dá»® LIá»†U THá»Š TRÆ¯á»œNG THá»°C Táº¾: {market_data}\n\n"
                f"Bá»I Cáº¢NH CÃ”NG TY: {company_context}\n\n"
                "HÃ£y láº­p bÃ¡o cÃ¡o chiáº¿n lÆ°á»£c chi tiáº¿t (PESTLE, Roadmap 2-5 nÄƒm)."
            ))
        ])
        
        # Sá»­ dá»¥ng GPT-4o Ä‘á»ƒ tá»•ng há»£p vÃ¬ kháº£ nÄƒng viáº¿t bÃ¡o cÃ¡o ráº¥t tá»‘t
        chain = prompt_template | LLM_GPT4
        response = chain.invoke({})
        
        return {
            "messages": [AIMessage(content=f"ğŸ§  [BÃO CÃO CHIáº¾N LÆ¯á»¢C R&D]:\n{response.content}")],
            "next_step": "Supervisor"
        }
        
    except Exception as e:
        print(colored(f"Lá»—i R&D Agent: {e}", "red"))
        return {"next_step": "Supervisor", "error_log": [str(e)]}

# ==========================================
# --- 4. THIáº¾T Láº¬P LUá»’NG AGENT (GRAPH) ---
# ==========================================

workflow = StateGraph(AgentState)

# --- 4.1 ÄÄƒng kÃ½ táº¥t cáº£ cÃ¡c Node (Äáº£m báº£o tÃªn khá»›p 100%) ---
nodes_map = {
    "Router": router_node, 
    "Supervisor": supervisor_node, 
    "Coder": coder_node,
    "Tester": tester_node, 
    "Hardware": hardware_node, 
    "Engineering": engineering_node,
    "IoT_Engineer": iot_node, 
    "Procurement": procurement_node, 
    "Investment": investment_node,
    "Researcher": researcher_node, 
    "Strategy_R_and_D": research_development_agent,
    "Legal": legal_node, 
    "Marketing": marketing_node, 
    "Artist": artist_node,
    "Storyteller": storyteller_node, 
    "Orchestrator": dynamic_orchestrator,
    "Publisher": publisher_node, 
    "Secretary": secretary_node
}

for name, func in nodes_map.items():
    workflow.add_node(name, func)

# --- 4.2 Thiáº¿t láº­p Ä‘iá»ƒm vÃ o ---
workflow.set_entry_point("Router")

# --- 4.3 Logic Router ---
# Thay vÃ¬ dÃ¹ng router_node trá»±c tiáº¿p, ta dÃ¹ng lambda Ä‘á»ƒ láº¥y chuá»—i 'next_step'
workflow.add_conditional_edges(
    "Router", 
    lambda x: x.get("next_step", "Supervisor"), 
    {
        "Researcher": "Researcher", 
        "Investment": "Investment", 
        "Storyteller": "Storyteller",
        "Artist": "Artist", 
        "Engineering": "Engineering", 
        "Publisher": "Publisher",
        "Orchestrator": "Orchestrator", 
        "Supervisor": "Supervisor", 
        "Secretary": "Secretary"
    }
)

# --- 4.4 Logic Supervisor ---
workflow.add_conditional_edges(
    "Supervisor", 
    lambda x: x.get("next_step", "Secretary"), 
    {
        "Coder": "Coder", 
        "Hardware": "Hardware", 
        "Engineering": "Engineering",
        "IoT_Engineer": "IoT_Engineer", 
        "Procurement": "Procurement",
        "Investment": "Investment", 
        "Researcher": "Researcher", 
        "Strategy_R_and_D": "Strategy_R_and_D",
        "Legal": "Legal", 
        "Marketing": "Marketing", 
        "Artist": "Artist",
        "Storyteller": "Storyteller", 
        "Secretary": "Secretary", 
        "FINISH": "Secretary"
    }
)

# --- 4.5 NhÃ³m Agent phá»• thÃ´ng (Há»“i quy vá» Supervisor hoáº·c káº¿t thÃºc) ---
# LÆ°u Ã½: KhÃ´ng bao gá»“m Coder, Tester, Hardware, Procurement, Investment, Researcher, Orchestrator
general_agents = [
    "Engineering", "IoT_Engineer", "Strategy_R_and_D", "Legal", 
    "Marketing", "Artist", "Storyteller", "Publisher"
]

for node in general_agents:
    workflow.add_conditional_edges(
        node,
        lambda x: x.get("next_step", "Supervisor") if x.get("next_step") != "FINISH" else "Secretary",
        {
            "Supervisor": "Supervisor", 
            "Secretary": "Secretary",
            "Artist": "Artist",
            "Procurement": "Procurement"
        }
    )

# --- 4.6 Logic chuyÃªn biá»‡t (Pipeline & Äáº·c thÃ¹) ---

# Luá»“ng Researcher -> Orchestrator
workflow.add_conditional_edges(
    "Researcher",
    lambda x: "Orchestrator" if x.get("task_type") == "dynamic" else "Secretary",
    {"Orchestrator": "Orchestrator", "Secretary": "Secretary"}
)

# Luá»“ng Orchestrator tá»a Ä‘i cÃ¡c nhÃ¡nh
workflow.add_conditional_edges(
    "Orchestrator",
    lambda x: x.get("next_step", "Secretary") if x.get("next_step") != "FINISH" else "Secretary",
    {
        "Engineering": "Engineering", 
        "Hardware": "Hardware", 
        "Procurement": "Procurement",
        "IoT_Engineer": "IoT_Engineer", 
        "Supervisor": "Supervisor", 
        "Secretary": "Secretary"
    }
)

# Luá»“ng Ká»¹ thuáº­t: Coder -> Tester
workflow.add_edge("Coder", "Tester")
workflow.add_conditional_edges(
    "Tester", 
    lambda x: x.get("next_step", "Supervisor"), 
    {"Coder": "Coder", "Supervisor": "Supervisor"}
)

# Luá»“ng Váº­t lÃ½ & TÃ i chÃ­nh cá»‘ Ä‘á»‹nh: Hardware -> Procurement -> Investment -> Supervisor/Secretary
workflow.add_edge("Hardware", "Procurement")
workflow.add_edge("Procurement", "Investment")
workflow.add_conditional_edges(
    "Investment",
    lambda x: "Secretary" if x.get("next_step") == "FINISH" else "Supervisor",
    {"Secretary": "Secretary", "Supervisor": "Supervisor"}
)

# --- 4.7 Káº¿t thÃºc há»‡ thá»‘ng ---
workflow.add_edge("Secretary", END)

# --- 4.8 BIÃŠN Dá»ŠCH Há»† THá»NG ---
ai_app = workflow.compile() 
app = ai_app
db = None # Placeholder cho Ä‘á»‘i tÆ°á»£ng Database cá»§a ngÃ i

# ============================================================================
# 5. HÃ€M Váº¬N HÃ€NH CHÃNH (Äáº¶T á» ÄÃ‚Y)
# ============================================================================
async def run_ai_corporation(user_input, thread_id="1"):
    """
    Äiá»ƒm kÃ­ch hoáº¡t há»‡ thá»‘ng: Quáº£n lÃ½ phiÃªn lÃ m viá»‡c vÃ  xá»­ lÃ½ lá»—i táº§ng cao nháº¥t.
    """
    config = {"configurable": {"thread_id": thread_id}, "recursion_limit": 50}
    
    # Khá»Ÿi táº¡o tráº¡ng thÃ¡i ban Ä‘áº§u
    initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "next_step": "Supervisor",
                "current_agent": "User", # ThÃªm dÃ²ng nÃ y Ä‘á»ƒ trÃ¡nh lá»—i NoneType
                "error_log": [],
                "task_type": "general"
            }

    print(colored(f"\nğŸš€ PROJECT START: {user_input[:50]}...", "blue", attrs=["bold"]))

    try:
        # Cháº¡y Graph (Giáº£ sá»­ báº¡n Ä‘Ã£ compile graph thÃ nh app)
        async for event in app.astream(initial_state, config):
            for node, values in event.items():
                if node != "__metadata__":
                    print(colored(f"ğŸ“ Node [{node}] has completed.", "dark_grey"))
        
        print(colored("\nâœ… PROJECT FINISHED SUCCESSFULLY", "green", attrs=["bold"]))

    except Exception as e:
        # Náº¿u Graph sáº­p, kÃ­ch hoáº¡t Fallback ngay láº­p tá»©c
        return ultimate_fallback(initial_state, [str(e)])
    
# ============================================================================
# 6. CHáº Y Há»† THá»NG (ASYNC ENGINE)
# ============================================================================

async def main_loop():
    print(colored("\n" + "="*50, "cyan"))
    print(colored("ğŸš€ AI CORPORATION - Há»† THá»NG ÄIá»€U HÃ€NH Tá»° Äá»˜NG", "cyan", attrs=["bold"]))
    print(colored("Cháº¿ Ä‘á»™: Parallel Coding & AST Testing [ON]", "green"))
    print(colored("="*50 + "\n", "cyan"))
    
    while True:
        try:
            user_input = input(colored("CEO (YÃªu cáº§u): ", "white", attrs=["bold"]))
            if user_input.lower() in ['q', 'exit']: 
                auto_backup_brain() # Tá»± Ä‘á»™ng sao lÆ°u trÆ°á»›c khi táº¯t mÃ¡y
                break
            
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "next_step": "Supervisor",
                "current_agent": "User", 
                "error_log": [],
                "task_type": "general"
            }
            
            # KÃ­ch hoáº¡t Graph cháº¡y (Sá»­ dá»¥ng astream cho cÃ¡c hÃ m async)
            print(colored("\n--- ÄANG Xá»¬ LÃ ---", "white", attrs=["bold"]))
            config = {"configurable": {"thread_id": "ceo_session"}, "recursion_limit": 150}
            async for event in app.astream(initial_state, config=config):
                for node, values in event.items():
                    if node != "__end__":
                        print(colored(f"  [â”] {node} Ä‘Ã£ hoÃ n thÃ nh nhiá»‡m vá»¥.", "dark_grey"))
                        # Náº¿u muá»‘n in ná»™i dung tin nháº¯n cuá»‘i cÃ¹ng cá»§a tá»«ng bÆ°á»›c:
                        # print(values["messages"][-1].content)

            print(colored("\nâœ… ÄÃƒ HOÃ€N Táº¤T QUY TRÃŒNH.", "green", attrs=["bold"]))

        except Exception as e:
            print(colored(f"âŒ Lá»–I Há»† THá»NG: {e}", "red"))


# ============================================================================
# 7. KHá»I CHáº Y THá»°C Táº¾
# ============================================================================
if __name__ == "__main__":
    try:
        # Cháº¡y vÃ²ng láº·p chÃ­nh thÃ´ng qua asyncio
        asyncio.run(main_loop())
    except KeyboardInterrupt:

        print("\nğŸ‘‹ ÄÃ£ thoÃ¡t há»‡ thá»‘ng.")

